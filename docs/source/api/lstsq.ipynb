{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `opinf.lstsq`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    ".. automodule:: opinf.lstsq\n",
    "\n",
    ".. currentmodule:: opinf.lstsq\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: _autosummaries\n",
    "   :nosignatures:\n",
    "\n",
    "   SolverTemplate\n",
    "   PlainSolver\n",
    "   L2Solver\n",
    "   L2DecoupledSolver\n",
    "   TikhonovSolver\n",
    "   TikhonovDecoupledSolver\n",
    "   TotalLeastSquaresSolver\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: EXAMPLE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-squares Operator Inference Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator Inference uses data to learn the entries of an $r \\times d$ *operator matrix* $\\Ohat$ by solving a regression problem, stated generally as\n",
    "\n",
    "::::{margin}\n",
    ":::{admonition} What is $\\Z$?\n",
    "For continuous models (systems of ordinary differential equations), $\\Z$ consists of the time derivatives of the snapshots; for discrete models (discrete dynamical systems), $\\Z$ also contains state snapshots.\n",
    ":::\n",
    "::::\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\text{find}\\quad\\Ohat\\quad\\text{such that}\\quad\n",
    "    \\Z \\approx \\Ohat\\D\\trp\n",
    "    \\quad\\Longleftrightarrow\\quad\n",
    "    \\D\\Ohat\\trp \\approx \\Z\\trp,\n",
    "\\end{aligned}\n",
    "$$ (eq:lstsq:general)\n",
    "\n",
    "where $\\D$ is the $k \\times d$ *data matrix* formed from state and input snapshots and $\\Z$ is the $r \\times k$ matrix of left-hand side data.\n",
    "\n",
    "This module defines classes for solving the least-squares problem {eq}`eq:lstsq:plain`, as well as related problems with regularization terms and/or constraints, given the data matrices $\\D$ and $\\Z$.\n",
    "Solver objects are passed to the constructor of {mod}`opinf.models` classes.\n",
    "The model handles the construction of $\\D$ and $\\Z$ from snapshot data, passes these matrices to the solver's `fit()` method, calls the solver's `predict()` method to produce $\\Ohat$, and interprets $\\Ohat$ in the context of the model structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "::::{admonition} Example\n",
    ":class: tip\n",
    "\n",
    "Suppose we want to construct a linear time-invariant (LTI) system,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\ddt\\qhat(t)\n",
    "    = \\Ahat\\qhat(t) + \\Bhat\\u(t),\n",
    "    \\qquad\n",
    "    \\Ahat\\in\\RR^{r \\times r},\n",
    "    ~\n",
    "    \\Bhat\\in\\RR^{r \\times m}.\n",
    "\\end{align}\n",
    "$$ (eq:lstsq:ltiexample)\n",
    "\n",
    "The operator matrix is $\\Ohat = [~\\Ahat~~\\Bhat~]\\in\\RR^{r \\times d}$ with column dimension $d = r + m$.\n",
    "To learn $\\Ohat$ with Operator Inference, we need data for $\\qhat(t)$, $\\u(t)$, and $\\ddt\\qhat(t)$.\n",
    "For $j = 0, \\ldots, k-1$, let\n",
    "\n",
    "- $\\qhat_{j}\\in\\RR^r$ be a measurement of the (reduced) state at time $t_{j}$,\n",
    "- $\\dot{\\qhat}_{j} = \\ddt\\qhat(t)\\big|_{t=t_{j}} \\in \\RR^r$ be the time derivative of the state at time $t_{j}$, and\n",
    "- $\\u_{j} = \\u(t_j) \\in \\RR^m$ be the input at time $t_{j}$.\n",
    "\n",
    "In this case, the data matrix $\\D$ is given by $\\D = [~\\Qhat\\trp~~\\U\\trp~]\\in\\RR^{k \\times d}$, where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\Qhat = \\left[\\begin{array}{ccc}\n",
    "        & & \\\\\n",
    "        \\qhat_0 & \\cdots & \\qhat_{k-1}\n",
    "        \\\\ & &\n",
    "    \\end{array}\\right]\n",
    "    \\in \\RR^{r\\times k},\n",
    "    \\qquad\n",
    "    \\U = \\left[\\begin{array}{ccc}\n",
    "        & & \\\\\n",
    "        \\u_0 & \\cdots & \\u_{k-1}\n",
    "        \\\\ & &\n",
    "    \\end{array}\\right]\n",
    "    \\in \\RR^{m \\times k}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The left-hand side data is $\\Z = \\dot{\\Qhat} = [~\\dot{\\qhat}_0~~\\cdots~~\\dot{\\qhat}_{k-1}~]\\in\\RR^{r\\times k}$.\n",
    "\n",
    ":::{dropdown} Derivation\n",
    "We seek $\\Ahat$ and $\\Bhat$ such that\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\dot{\\qhat}_{j}\n",
    "    \\approx \\Ahat\\qhat_j + \\Bhat\\u_j,\n",
    "    \\qquad j = 0, \\ldots, k-1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Using the snapshot matrices $\\Qhat$, $\\U$, and $\\dot{\\Qhat}$ defined above, we want\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\dot{\\Qhat}\n",
    "    \\approx \\Ahat\\Qhat + \\Bhat\\U\n",
    "    = [~\\Ahat~~\\Bhat~]\\left[\\begin{array}{c} \\Qhat \\\\ \\U \\end{array}\\right],\n",
    "    \\quad\\text{or}\n",
    "    \\\\\n",
    "    [~\\Qhat\\trp~~\\U\\trp~][~\\Ahat~~\\Bhat~]\\trp \\approx \\dot{\\Qhat}\\trp,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which is $\\D\\Ohat\\trp \\approx \\Z\\trp$.\n",
    "\n",
    "More precisely, a regression problem for $\\Ohat$ with respect to the data triples $(\\qhat_j, \\u_j, \\dot{\\qhat}_j)$ can be written as\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\argmin_{\\Ahat,\\Bhat}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\Ahat\\qhat_j + \\Bhat\\u_j - \\dot{\\qhat}_j\n",
    "    \\right\\|_{2}^{2}\n",
    "    &= \\argmin_{\\Ahat,\\Bhat}\\left\\|\n",
    "        \\Ahat\\Qhat + \\Bhat\\U - \\dot{\\Qhat}\n",
    "    \\right\\|_{F}^{2}\n",
    "    \\\\\n",
    "    &= \\argmin_{\\Ahat,\\Bhat}\\left\\|\n",
    "        [~\\Ahat~~\\Bhat~]\\left[\\begin{array}{c} \\Qhat \\\\ \\U \\end{array}\\right] - \\Z\n",
    "    \\right\\|_{F}^{2}\n",
    "    \\\\\n",
    "    &= \\argmin_{\\Ahat,\\Bhat}\\left\\|\n",
    "        [~\\Qhat\\trp~~\\U\\trp~][~\\Ahat~~\\Bhat~]\\trp - \\Z\\trp\n",
    "    \\right\\|_{F}^{2},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which is $\\argmin_{\\Ohat}\\|\\D\\Ohat\\trp - \\Z\\trp\\|_F^2$.\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most often, we pose {eq}`eq:lstsq:general` as a linear least-squares regression,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\argmin_{\\Ohat} \\|\\D\\Ohat\\trp - \\Z\\trp\\|_F^2.\n",
    "\\end{aligned}\n",
    "$$ (eq:lstsq:plain)\n",
    "\n",
    "Note that the matrix least-squares problem {eq}`eq:lstsq:plain` decouples into $r$ independent vector least-squares problems, i.e.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\argmin_{\\ohat_i} \\|\\D\\ohat_i - \\z_i\\|_2^2,\n",
    "    \\quad i = 1, \\ldots, r,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\ohat_i$ and $\\z_i$ are the $i$-th rows of $\\Ohat$ and $\\Z$, respectively.\n",
    "\n",
    "The {class}`PlainSolver` class solves {eq}`eq:lstsq:plain` without any additional terms.\n",
    "This is the default solver used if another solver is not specified in the constructor of an {mod}`opinf.models` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tikhonov Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is often advantageous to add a *regularization term* $\\mathcal{R}(\\Ohat)$ to penalize the entries of the inferred operators.\n",
    "This prevents over-fitting to data and promotes stability and accuracy in the learned reduced-order model {cite}`mcquarrie2021combustion`.\n",
    "The regression problem then becomes\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\argmin_{\\Ohat}\\|\n",
    "        \\D\\Ohat\\trp - \\Z\\trp\n",
    "    \\|_{F}^{2} + \\mathcal{R}(\\Ohat).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "A [Tikhonov regularization](https://en.wikipedia.org/wiki/Ridge_regression#Tikhonov_regularization) term has the form\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathcal{R}(\\Ohat)\n",
    "    = \\sum_{i=1}^{r}\\|\\bfGamma_i\\ohat_i\\|_2^2,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\ohat_1,\\ldots,\\ohat_r$ are the rows of $\\Ohat$ and each $\\bfGamma_1,\\ldots,\\bfGamma_r$ is a $d \\times d$ symmetric positive-definite matrix.\n",
    "In this case, the decoupled regressions for the rows of $\\Ohat$ are given by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\argmin_{\\ohat_i} \\|\\D\\ohat_i - \\z_i\\|_2^2 + \\|\\bfGamma_i\\ohat_i\\|_2^2,\n",
    "    \\quad i = 1, \\ldots, r.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The following classes solve Tikhonov-regularized least-squares Operator Inference regressions for different choices of the regularization term $\\mathcal{R}(\\Ohat)$.\n",
    "\n",
    "| Solver class                     | Description                                      | Regularization $\\mathcal{R}(\\Ohat)$ |\n",
    "| :------------------------------- | :----------------------------------------------- | :------------------ |\n",
    "| {class}`L2Solver`                | One scalar regularizer for all $\\ohat_i$         | $\\lambda^{2}\\|\\Ohat\\trp\\|_F^2$ |\n",
    "| {class}`L2DecoupledSolver`       | Different scalar regularizers for each $\\ohat_i$ | $\\sum_{i=1}^{r}\\lambda_i^2\\|\\ohat_i\\|_2^2$ |\n",
    "| {class}`TikhonovSolver`          | One matrix regularizer for all $\\ohat_i$         | $\\|\\bfGamma\\Ohat\\trp\\|_F^2$ |\n",
    "| {class}`TikhonovDecoupledSolver` | Different matrix regularizers for each $\\ohat_i$ | $\\sum_{i=1}^{r}\\|\\bfGamma_i\\ohat_i\\|_2^2$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Least-Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear least-squares models for $\\D\\Ohat\\trp \\approx \\Z\\trp$ assume error in $\\Z$ only, i.e.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\D\\Ohat\\trp = \\Z\\trp + \\Delta_{\\Z\\trp}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "for some $\\Delta_{\\Z\\trp} \\in \\RR^{r\\times k}$\n",
    "[Total least-squares](https://en.wikipedia.org/wiki/Total_least_squares) is an alternative approach that assumes possible error in the data matrix $\\D$ as well as in $\\Z$, i.e.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    (\\D + \\Delta_{\\D})\\Ohat\\trp = \\Ztrp + \\Delta_{\\Z\\trp}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "for $\\Delta_{\\D}\\in\\RR^{k \\times d}$ and $\\Delta_{\\Z\\trp}\\in\\RR^{r \\times k}$.\n",
    "\n",
    "The {class}`TotalLeastSquaresSolver` class performs a total least-squares solve for $\\Ohat$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The {class}`SolverTemplate` class defines the API for least-squares solvers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
