{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38c49d8-8aef-46a6-b7fb-fb83f3171878",
   "metadata": {},
   "source": [
    "# What is Operator Inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6356601d",
   "metadata": {},
   "source": [
    "The goal of Operator Inference is to construct a low-dimensional, computationally inexpensive system whose solutions are close to those of some high-dimensional system for which we have 1) training data and 2) some knowledge about the system structure.\n",
    "The main steps are the following.\n",
    "\n",
    "1.  [**Get training data**](subsec-training-data). Gather and [preprocess](../api/pre.ipynb) high-dimensional data to learn a low-dimensional model from. This package has a few common preprocessing tools, but the user must bring the data to the table.\n",
    "2.  [**Compute a low-dimensional representation**](subsec-basis-computation). Approximate the high-dimensional data with only a few degrees of freedom. The simplest approach is to take the SVD of the high-dimensional training data, extract the first few left singular vectors, and use these vectors as a new coordinate basis.\n",
    "3.  [**Set up and solve a low-dimensional regression**](subsec-opinf-regression). Use the low-dimensional representation of the training data to determine a reduced-order model that best fits the data in a minimum-residual sense. This is the core objective of the package.\n",
    "4.  [**Solve the reduced-order model**](subsec-rom-evaluation). Use the learned model to make computationally efficient predictions.\n",
    "\n",
    ":::{figure} ../../images/summary.svg\n",
    "---\n",
    "width: 80 %\n",
    "---\n",
    "The Operator Inference workflow.\n",
    ":::\n",
    "\n",
    "This page gives an overview of Operator Inference by walking through each of these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed68b1d",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde642ba",
   "metadata": {},
   "source": [
    "::::{margin}\n",
    ":::{note}\n",
    "We are most often interested in full-order models that are spatial discretizations of partial differential equations (PDEs), but {eq}`eq:opinf-example-fom` does not necessarily have to be related to a PDE.\n",
    ":::\n",
    "::::\n",
    "\n",
    "Consider a system of ordinary differential equations (ODEs) with state $\\q(t)\\in\\RR^{n}$ and inputs $\\u(t)\\in\\RR^{m}$,\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\q(t)\n",
    "    = \\mathbf{f}(t, \\q(t), \\u(t)).\n",
    "$$ (eq:opinf-example-fom)\n",
    "\n",
    "We call {eq}`eq:opinf-example-fom` the _full-order model_.\n",
    "Given samples of the state $\\q(t)$, Operator Inference learns a surrogate system for {eq}`eq:opinf-example-fom` with the much smaller state $\\qhat(t) \\in \\RR^{r}, r \\ll n,$ and a polynomial structure, for example:\n",
    "\n",
    "::::{margin}\n",
    ":::{note}\n",
    "The $\\otimes$ operator is called the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product).\n",
    ":::\n",
    "::::\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\qhat(t)\n",
    "    = \\chat\n",
    "    + \\Ahat\\qhat(t)\n",
    "    + \\Hhat[\\qhat(t)\\otimes\\qhat(t)]\n",
    "    + \\Bhat\\u(t).\n",
    "$$ (eq:opinf-example-rom)\n",
    "\n",
    "We call {eq}`eq:opinf-example-rom` a _reduced-order model_ for {eq}`eq:opinf-example-fom`.\n",
    "Our goal is to infer the _reduced-order operators_ $\\chat \\in \\RR^{r}$, $\\Ahat\\in\\RR^{r\\times r}$, $\\Hhat\\in\\RR^{r\\times r^{2}}$, and/or $\\Bhat\\in\\RR^{r\\times m}$ using data from {eq}`eq:opinf-example-fom`.\n",
    "The user specifies which terms to include in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a93857",
   "metadata": {},
   "source": [
    "::::{important}\n",
    ":name: projection-preserves-structure\n",
    "\n",
    "The right-hand side of {eq}`eq:opinf-example-rom` is a polynomial with respect to the state $\\qhat(t)$:\n",
    "$\\chat$ are the constant terms, $\\Ahat\\qhat(t)$ are the linear terms, $\\Hhat[\\qhat(t)\\otimes\\qhat(t)]$ are the quadratic terms, with input terms $\\Bhat\\u(t)$.\n",
    "The user must choose which terms to include in the reduced-order model, and this choice should be motivated by the structure of the full-order model {eq}`eq:opinf-example-fom`.\n",
    "For example, if the full-order model can be written as\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\q(t)\n",
    "    = \\A\\q(t) + \\B\\u(t),\n",
    "$$\n",
    "\n",
    "then the reduced-order model should mirror this structure as\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\qhat(t)\n",
    "    = \\Ahat\\qhat(t)\n",
    "    + \\Bhat\\u(t).\n",
    "$$\n",
    "\n",
    ":::{dropdown} Motivation\n",
    "**Projection preserves polynomial structure** {cite}`benner2015pmorsurvey,peherstorfer2016opinf`.\n",
    "The classical (Galerkin) projection-based reduced-order model for the system\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\q(t)\n",
    "    = \\c\n",
    "    + \\A\\q(t)\n",
    "    + \\H[\\q(t)\\otimes\\q(t)]\n",
    "    + \\B\\u(t)\n",
    "$$\n",
    "\n",
    "is obtained by substituting $\\q(t)$ with $\\mathbf{V}\\qhat(t)$ for some orthonormal $\\mathbf{V}\\in\\RR^{n \\times r}$ and $\\qhat(t)\\in \\RR^{r}$, then multiplying both sides by $\\mathbf{V}\\trp$:\n",
    "\n",
    "$$\n",
    "    \\mathbf{V}\\trp\\frac{\\text{d}}{\\text{d}t}\\left[\\mathbf{V}\\qhat(t)\\right]\n",
    "    = \\mathbf{V}\\trp\\left(\\c\n",
    "    + \\A\\mathbf{V}\\qhat(t)\n",
    "    + \\H[(\\mathbf{V}\\qhat(t))\\otimes(\\mathbf{V}\\qhat(t))]\n",
    "    + \\B\\u(t)\\right).\n",
    "$$\n",
    "\n",
    "Since $\\mathbf{V}\\trp\\mathbf{V}$ is the identity and $(\\mathbf{X}\\mathbf{Y})\\otimes(\\mathbf{Z}\\mathbf{W}) = (\\mathbf{X}\\otimes \\mathbf{Z})(\\mathbf{Y}\\otimes\\mathbf{W})$, this simplifies to\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\qhat(t)\n",
    "    =\n",
    "    \\chat\n",
    "    + \\Ahat\\qhat(t)\n",
    "    + \\Hhat[\\qhat(t)\\otimes\\qhat(t)]\n",
    "    + \\Bhat\\u(t),\n",
    "$$\n",
    "\n",
    "where $\\chat = \\mathbf{V}\\trp\\c$, $\\Ahat = \\mathbf{V}\\trp\\A\\mathbf{V}$, $\\Hhat = \\mathbf{V}\\trp\\H\\left(\\mathbf{V}\\otimes\\mathbf{V}\\trp\\right)$, and $\\Bhat = \\mathbf{V}\\trp\\B$.\n",
    "Operator Inference learns $\\chat$, $\\Ahat$, $\\Hhat$, and/or $\\Bhat$ _from data_ and is therefore useful for situations where $\\c$, $\\A$, $\\H$, and/or $\\B$ are not explicitly available for matrix computations.\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11fe06",
   "metadata": {},
   "source": [
    "(subsec-training-data)=\n",
    "## Get Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ab767",
   "metadata": {},
   "source": [
    "Operator Inference learns reduced-order models from full-order state/input data.\n",
    "Start by gathering solution and input data and organizing them columnwise into the _state snapshot matrix_ $\\Q$ and _input matrix_ $\\U$,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\Q\n",
    "    &= \\left[\\begin{array}{cccc}\n",
    "        & & & \\\\\n",
    "        \\q_{1} & \\q_{2} & \\cdots & \\q_{k}\n",
    "        \\\\ & & &\n",
    "    \\end{array}\\right]\n",
    "    \\in \\RR^{n \\times k},\n",
    "    &\n",
    "    \\U\n",
    "    &= \\left[\\begin{array}{cccc}\n",
    "        & & & \\\\\n",
    "        \\u_{1} & \\u_{2} & \\cdots & \\u_{k}\n",
    "        \\\\ & & &\n",
    "    \\end{array}\\right]\n",
    "    \\in \\RR^{m \\times k},\n",
    "\\end{align*}\n",
    "\n",
    "where $n$ is the dimension of the (discretized) state, $m$ is the dimension of the input, $k$ is the number of available data points, and the columns of $\\Q$ and $\\U$ are the solution to the full-order model at some time $t_j$:\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\q\\bigg|_{t = t_j}\n",
    "    = \\mathbf{f}(t_{j}, \\q_{j}, \\u_{j}).\n",
    "$$\n",
    "\n",
    ":::{important}\n",
    "Raw dynamical systems data often needs to be lightly preprocessed before it can be used in Operator Inference.\n",
    "Preprocessing can promote stability in the inference of the reduced-order operators and improve the stability and accuracy of the resulting reduced-order model {eq}`eq:opinf-example-rom`.\n",
    "Common preprocessing steps include\n",
    "1. Variable transformations / lifting to induce a polynomial structure.\n",
    "2. Centering or shifting data to account for boundary conditions.\n",
    "3. Scaling / nondimensionalizing the variables represented in the state.\n",
    "\n",
    "See [`opinf.pre`](../api/pre.ipynb) for details and examples.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace140d",
   "metadata": {},
   "source": [
    "Operator Inference uses a regression problem to compute the reduced-order operators, which requires state data ($\\Q$), input data ($\\U$), _and_ data for the corresponding time derivatives:\n",
    "\n",
    "$$\n",
    "    \\dot{\\Q}\n",
    "    = \\left[\\begin{array}{cccc}\n",
    "        & & & \\\\\n",
    "        \\dot{\\q}_{1} &\n",
    "        \\dot{\\q}_{2} & \\cdots &\n",
    "        \\dot{\\q}_{k}\n",
    "        \\\\ & & &\n",
    "    \\end{array}\\right]\n",
    "    \\in \\RR^{n \\times k},\n",
    "    \\qquad\n",
    "    \\dot{\\q}_{j} = \\frac{\\text{d}}{\\text{d}t}\\q\\bigg|_{t = t_j} \\in \\RR^{n}.\n",
    "$$\n",
    "\n",
    ":::{note}\n",
    "If these time derivatives cannot be computed directly by evaluating $\\mathbf{F}(t_{j}, \\q_{j}, \\u_{j})$, they may be inferred from the state snapshots.\n",
    "The simplest approach is to use [finite differences](https://en.wikipedia.org/wiki/Numerical_differentiation) of the state snapshots, implemented in this package as `opinf.pre.ddt()`.\n",
    ":::\n",
    "\n",
    ":::{warning}\n",
    "If you do any preprocessing on the states, be sure to use the time derivatives of the _processed states_, not of the original states.\n",
    ":::\n",
    "\n",
    "<!-- :::{note}\n",
    "Operator Inference can also be used to learn discrete dynamical systems with polynomial structure, for example,\n",
    "\n",
    "$$\n",
    "    \\q_{j+1}\n",
    "    = \\A\\q_{j}\n",
    "    + \\H(\\q_{j}\\otimes\\q_{j})\n",
    "    + \\B\\u_{j}.\n",
    "$$\n",
    "\n",
    "In this case, the left-hand side data is a simply subset of the state snapshot matrix.\n",
    "::: -->\n",
    "<!-- See TODO for more details. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42493570",
   "metadata": {},
   "source": [
    "(subsec-basis-computation)=\n",
    "## Compute a Low-dimensional Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a570e1",
   "metadata": {},
   "source": [
    "The purpose of learning a reduced-order model is to achieve a computational speedup.\n",
    "This is accomplished by introducing an approximate representation of the $n$-dimensional state using only $r \\ll n$ degrees of freedom.\n",
    "The most common approach is to represent the state as a linear combination of $r$ vectors:\n",
    "\n",
    "$$\n",
    "    \\q(t)\n",
    "    \\approx \\Vr \\qhat(t)\n",
    "    = \\sum_{i=1}^{r}\\v_{i}\\hat{q}_{i}(t),\n",
    "$$ (eq-opinf-basis-def)\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    \\Vr\n",
    "    = \\left[\\begin{array}{ccc}\n",
    "        & & \\\\\n",
    "        \\v_{1} & \\cdots & \\v_{r}\n",
    "        \\\\ & &\n",
    "    \\end{array}\\right] \\in \\RR^{n \\times r},\n",
    "    \\qquad\n",
    "    \\qhat\n",
    "    = \\left[\\begin{array}{c}\n",
    "        \\hat{q}_{1}(t) \\\\ \\vdots \\\\ \\hat{q}_{r}(t)\n",
    "    \\end{array}\\right] \\in \\RR^{r}.\n",
    "$$\n",
    "\n",
    "We call $\\Vr \\in \\RR^{n \\times r}$ the _basis matrix_ and typically require that it have orthonormal columns.\n",
    "The basis matrix is the link between the high-dimensional state space of the full-order model {eq}`eq:opinf-example-fom` and the low-dimensional state space of the reduced-order model {eq}`eq:opinf-example-rom`.\n",
    "\n",
    ":::{image} ../../images/basis-projection.svg\n",
    ":align: center\n",
    ":width: 80 %\n",
    ":::\n",
    "\n",
    "See {mod}`opinf.basis` for tools to compute the basis $\\Vr\\in\\RR^{n \\times r}$ and select an appropriate dimension $r$.\n",
    "\n",
    "<!-- :::{tip}\n",
    "In the case of finite differences, the time derivative estimation can be done after the data is projected to the low-dimensional subspace defined by the basis (the column space of $\\Vr$).\n",
    "Instead of feeding the data matrix $\\Q$ to `opinf.pre.ddt()`, consider computing $\\widehat{\\Q} = \\Vr\\trp\\Q$ first and using that as the input to `opinf.pre.ddt()`.\n",
    "You can also use $\\widehat{\\Q}$ as the input when you fit the reduced-order model object.\n",
    "::: -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec64565",
   "metadata": {},
   "source": [
    "(subsec-opinf-regression)=\n",
    "## Set up and Solve a Low-dimensional Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10879433",
   "metadata": {},
   "source": [
    "Operator Inference determines the operators $\\chat$, $\\Ahat$, $\\Hhat$, and/or $\\Bhat$ by solving the following data-driven regression:\n",
    "\n",
    "$$\n",
    "\\min_{\\chat,\\Ahat,\\Hhat,\\Bhat}\\sum_{j=0}^{k-1}\\left\\|\n",
    "    \\chat\n",
    "    + \\Ahat\\qhat_{j}\n",
    "    + \\Hhat[\\qhat_{j} \\otimes \\qhat_{j}]\n",
    "    + \\Bhat\\u_{j}\n",
    "    - \\dot{\\qhat}_{j}\n",
    "\\right\\|_{2}^{2}\n",
    "\n",
    "+ \\mathcal{R}(\\chat,\\Ahat,\\Hhat,\\Bhat),\n",
    "\n",
    "$$ (eq:opinf-lstsq-residual)\n",
    "\n",
    "where\n",
    "+ $\\qhat_{j} = \\Vr\\trp\\q(t_{j})$ is the state at time $t_{j}$ represented in the coordinates of the basis,\n",
    "+ $\\dot{\\qhat}_{j} = \\ddt\\Vr\\trp\\q\\big|_{t=t_{j}}$ is the time derivative of the state at time $t_{j}$ in the coordinates of the basis,\n",
    "+ $\\u_{j} = \\u(t_j)$ is the input at time $t_{j}$, and\n",
    "+ $\\mathcal{R}$ is a _regularization term_ that penalizes the entries of the learned operators.\n",
    "\n",
    "The least-squares minimization {eq}`eq:opinf-lstsq-residual` can be written in the more standard form\n",
    "\n",
    "$$\n",
    "\\min_{\\Ohat}\\left\\|\n",
    "    \\D\\Ohat\\trp - \\mathbf{Y}\\trp\n",
    "\\right\\|_{F}^{2} + \\mathcal{R}(\\Ohat),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "::::{margin}\n",
    ":::{note}\n",
    "The $\\odot$ operator is called the [Khatri-Rao product](https://en.wikipedia.org/wiki/Khatri%E2%80%93Rao_product#Column-wise_Kronecker_product) and indicates taking the Kronecker product column by column.\n",
    "<!-- $$\n",
    "\\left[\\begin{array}{cccc}\n",
    "    \\mathbf{z}_{0} & \\mathbf{z}_{1} & \\cdots & \\mathbf{z}_{k-1}\n",
    "\\end{array}\\right]\n",
    "\\odot\n",
    "\\left[\\begin{array}{cccc}\n",
    "    \\mathbf{w}_{0} & \\mathbf{w}_{1} & \\cdots & \\mathbf{w}_{k-1}\n",
    "\\end{array}\\right]\n",
    "= \\left[\\begin{array}{cccc}\n",
    "    \\mathbf{z}_{0}\\otimes\\mathbf{w}_{0} & \\mathbf{z}_{1}\\otimes\\mathbf{w}_{1} & \\cdots & \\mathbf{z}_{k-1}\\otimes\\mathbf{w}_{k-1}\n",
    "\\end{array}\\right].\n",
    "$$ -->\n",
    ":::\n",
    "::::\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\Ohat\n",
    "    &= \\left[~\\chat~~\\Ahat~~\\Hhat~~\\Bhat~\\right]\\in\\RR^{r\\times d(r,m)},\n",
    "    &\\text{(unknown operators)}\n",
    "    \\\\\n",
    "    \\D\n",
    "    &= \\left[~\\mathbf{1}_{k}~~\\widehat{\\Q}\\trp~~(\\widehat{\\Q}\\odot\\widehat{\\Q})\\trp~~\\U\\trp~\\right]\\in\\RR^{k\\times d(r,m)},\n",
    "    &\\text{(known data)}\n",
    "    \\\\\n",
    "    \\widehat{\\Q}\n",
    "    &= \\left[~\\qhat_0~~\\qhat_1~~\\cdots~~\\qhat_{k-1}~\\right]\\in\\RR^{r\\times k}\n",
    "    &\\text{(snapshots)}\n",
    "    \\\\\n",
    "    \\mathbf{Y}\n",
    "    &= \\left[~\\dot{\\qhat}_0~~\\dot{\\qhat}_1~~\\cdots~~\\dot{\\qhat}_{k-1}~\\right]\\in\\RR^{r\\times k},\n",
    "    &\\text{(time derivatives)}\n",
    "    \\\\\n",
    "    \\U\n",
    "    &= \\left[~\\u_0~\\u_1~\\cdots~\\u_{k-1}~\\right]\\in\\RR^{m\\times k},\n",
    "    &\\text{(inputs)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "in which $d(r,m) = 1 + r + r(r+1)/2 + m$ and $\\mathbf{1}_{k}\\in\\RR^{k}$ is a vector of ones.\n",
    "\n",
    ":::{dropdown} Derivation\n",
    "The Frobenius norm of a matrix is the square root of the sum of the squared entries.\n",
    "If $\\mathbf{Z}$ has entries $z_{ij}$, then\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\|\\mathbf{Z}\\|_{F}\n",
    "    = \\sqrt{\\text{trace}(\\mathbf{Z}\\trp\\mathbf{Z})}\n",
    "    = \\sqrt{\\sum_{i,j}z_{ij}^{2}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Writing $\\mathbf{Z}$ in terms of its columns,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbf{Z}\n",
    "    = \\left[\\begin{array}{c|c|c|c}\n",
    "        &&& \\\\\n",
    "        \\mathbf{z}_0 & \\mathbf{z}_1 & \\cdots & \\mathbf{z}_{k-1} \\\\\n",
    "        &&&\n",
    "    \\end{array}\\right],\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\|\\mathbf{Z}\\|_F^2 = \\sum_{j=0}^{k-1}\\|\\mathbf{z}_j\\|_2^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Furthermore, $\\|\\mathbf{Z}\\|_{F} = \\|\\mathbf{Z}\\trp\\|_{F}$.\n",
    "Using these two properties, we can rewrite the least-squares residual as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\chat\n",
    "        + \\Ahat\\qhat_{j}\n",
    "        + \\Hhat[\\qhat_{j} \\otimes \\qhat_{j}]\n",
    "        + \\Bhat\\u_{j}\n",
    "        - \\dot{\\qhat}_{j}\n",
    "    \\right\\|_{2}^{2}\n",
    "    &= \\left\\|\n",
    "        \\chat\\mathbf{1}\\trp\n",
    "        + \\Ahat\\widehat{\\Q}\n",
    "        + \\Hhat[\\widehat{\\Q} \\odot \\widehat{\\Q}]\n",
    "        + \\Bhat\\U\n",
    "        - \\dot{\\widehat{\\Q}}\n",
    "    \\right\\|_{F}^{2}\n",
    "    \\\\\n",
    "    &= \\left\\|\n",
    "        \\left[\\begin{array}{cccc}\n",
    "            \\chat & \\Ahat & \\Hhat & \\Bhat\n",
    "        \\end{array}\\right]\n",
    "        \\left[\\begin{array}{c}\n",
    "            \\mathbf{1}\\trp\n",
    "            \\\\ \\widehat{\\Q}\n",
    "            \\\\ \\widehat{\\Q} \\odot \\widehat{\\Q}\n",
    "            \\\\ \\U\n",
    "        \\end{array}\\right]\n",
    "        - \\dot{\\widehat{\\Q}}\n",
    "    \\right\\|_{F}^{2}\n",
    "    \\\\\n",
    "    &= \\left\\|\n",
    "        \\left[\\begin{array}{c}\n",
    "            \\mathbf{1}\\trp\n",
    "            \\\\ \\widehat{\\Q}\n",
    "            \\\\ \\widehat{\\Q} \\odot \\widehat{\\Q}\n",
    "            \\\\ \\U\n",
    "        \\end{array}\\right]\\trp\n",
    "        \\left[\\begin{array}{cccc}\n",
    "            \\chat & \\Ahat & \\Hhat & \\Bhat\n",
    "        \\end{array}\\right]\\trp\n",
    "        - \\dot{\\widehat{\\Q}}\\trp\n",
    "    \\right\\|_{F}^{2}\n",
    "    \\\\\n",
    "    &= \\left\\|\n",
    "        \\left[\\begin{array}{cccc}\n",
    "            \\mathbf{1}\n",
    "            & \\widehat{\\Q}\\trp\n",
    "            & [\\widehat{\\Q} \\odot \\widehat{\\Q}]\\trp\n",
    "            & \\U\\trp\n",
    "        \\end{array}\\right]\n",
    "        \\left[\\begin{array}{c}\n",
    "            \\chat\\trp\n",
    "            \\\\ \\Ahat\\trp\n",
    "            \\\\ \\Hhat\\trp\n",
    "            \\\\ \\Bhat\\trp\n",
    "        \\end{array}\\right]\n",
    "        - \\dot{\\widehat{\\Q}}\\trp\n",
    "    \\right\\|_{F}^{2},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which is the standard form given above.\n",
    ":::\n",
    "\n",
    ":::{important}\n",
    "Writing the problem in standard form reveals an important fact:\n",
    "for the most common choices of $\\mathcal{R}$, the Operator Inference learning problem {eq}`eq:opinf-lstsq-residual` has a unique solution if and only if $\\D$ has full column rank.\n",
    "A necessary condition for this to happen is $k \\ge d(r,m)$, that is, the number of training snapshots $k$ should exceed the number of reduced-order operator entries to be learned for each system mode.\n",
    "If you are experiencing poor performance with Operator Inference reduced models, try decreasing $r$, increasing $k$, or adding a regularization term to improve the conditioning of the learning problem.\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "Let $\\ohat_{1},\\ldots,\\ohat_{r}\\in\\RR^{d(r,m)}$ be the rows of $\\Ohat$.\n",
    "If the regularization can be written as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathcal{R}(\\Ohat)\n",
    "    = \\sum_{i=1}^{r}\\mathcal{R}_{i}(\\ohat_{i}),\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "then the Operator Inference regression decouples along the rows of $\\Ohat$ into $r$ independent least-squares problems:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\Ohat}\\left\\{\\left\\|\n",
    "        \\D\\Ohat\\trp - \\mathbf{Y}\\trp\n",
    "    \\right\\|_{F}^{2} + \\mathcal{R}(\\Ohat)\\right\\}\n",
    "    =\n",
    "    \\sum_{i=1}^{r}\\min_{\\ohat_{i}}\\left\\{\\left\\|\n",
    "        \\D\\ohat_{i} - \\mathbf{y}_{i}\n",
    "    \\right\\|_{2}^{2} + \\mathcal{R}_{i}(\\ohat_{i})\\right\\},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{y}_{i},\\ldots,\\mathbf{y}_{r}$ are the rows of $\\mathbf{Y}$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff334934",
   "metadata": {},
   "source": [
    "(subsec-rom-evaluation)=\n",
    "## Solve the Reduced-order Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2475c9",
   "metadata": {},
   "source": [
    "\n",
    "Once the reduced-order operators have been determined, the corresponding reduced-order model {eq}`eq:opinf-example-rom` can be solved rapidly to make predictions.\n",
    "The computational cost of solving the reduced-order model scales with $r$, the number of degrees of freedom in the low-dimensional representation of the state.\n",
    "\n",
    "For example, we may use the reduced-order model to obtain approximate solutions of the full-order model {eq}`eq:opinf-example-fom` with\n",
    "\n",
    "+ new initial conditions $\\q_{0}$,\n",
    "+ a different input function $\\u(t)$,\n",
    "+ a longer time horizon than the training data,\n",
    "+ different system parameters.\n",
    "\n",
    ":::{important}\n",
    "The accuracy of any data-driven model depends on how well the training data represents the full-order system.\n",
    "We should not expect a reduced-order model to perform well under conditions that are wildly different than the training data.\n",
    "The [**Getting Started**](../tutorials/basics.ipynb) tutorial demonstrates this concept in the case of prediction for new initial conditions.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7e4af",
   "metadata": {},
   "source": [
    "## Brief Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292f65f",
   "metadata": {},
   "source": [
    "Suppose we have the following variables.\n",
    "\n",
    "| Variable | Symbol | Description |\n",
    "| :------- | :----- | :---------- |\n",
    "| `Q` | $\\Q\\in\\RR^{n\\times k}$ | State snapshot matrix |\n",
    "| `U` | $\\U\\in\\RR^{m}$ | Input matrix |\n",
    "| `t` | $t$ | Time domain for snapshot data |\n",
    "\n",
    "That is, `Q[:, j]` and `U[:, j]` are the state and input, respectively, corresponding to time `t[j]`.\n",
    "Then the following code learns a reduced-order model of the form\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\qhat(t)\n",
    "    = \\Ahat\\qhat(t)\n",
    "    + \\Hhat(\\qhat(t)\\otimes\\qhat(t))\n",
    "    + \\Bhat\\widehat{\\u}(t)\n",
    "$$\n",
    "\n",
    "from the training data, uses the reduced-order model to reconstruct the training data, and computes the error of the reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783e6cc",
   "metadata": {},
   "source": [
    "```python\n",
    "import opinf\n",
    "\n",
    "# Compute a rank-10 basis (POD) from the state data.\n",
    "basis = opinf.basis.PODBasis(num_vectors=10).fit(Q)\n",
    "\n",
    "# Compress the state data to a low-dimensional subspace.\n",
    "Q_compressed = basis.compress(Q)\n",
    "\n",
    "# Estimate time derivatives of the compressed states with finite differences.\n",
    "Qdot_compressed = opinf.ddt.ddt(Q_compressed, t)\n",
    "\n",
    "# Define an ODE model with the structure indicated above.\n",
    "rom = opinf.models.ContinuousModel(\"AHB\")\n",
    "\n",
    "# Select a least-squares solver with a small amount of regularization.\n",
    "solver = opinf.lstsq.L2Solver(regularizer=1e-6)\n",
    "\n",
    "# Fit the model, i.e., construct and solve a linear regression.\n",
    "rom.fit(states=Q_compressed, ddts=Qdot_compressed, inputs=U, solver=solver)\n",
    "\n",
    "# Simulate the learned model over the time domain.\n",
    "Q_rom_compressed = rom.predict(Q_compressed[:, 0], t, input_func=U)\n",
    "\n",
    "# Map the reduced-order solutions back to the full state space.\n",
    "Q_rom = basis.decompress(Q_rom_compressed)\n",
    "\n",
    "# Compute the error of the ROM prediction.\n",
    "absolute_error, relative_error = opinf.post.Lp_error(Q, Q_rom, t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3c6ba",
   "metadata": {},
   "source": [
    "See [**Getting Started**](../tutorials/basics.ipynb) for an introductory tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opinf3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
