{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# External Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "The fundamental goal of model reduction is to efficiently make physics-based predictions. Given synthetic or experimental data that was generated or collected under a certain set of conditions, we aim to construct a cost-effective model that produces accurate solutions under new sets of conditions. The first tutorial showed an example of evaluating a reduced-order model (ROM) for various initial conditions. This tutorial focuses on problems with external time-dependent inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-nb-collapsed": true
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a problem with external inputs that are parameterized by a scalar-valued function $u:\\RR\\to\\RR.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Governing Equations\n",
    ":class: info\n",
    "\n",
    "Let $\\Omega = [0,L]\\subset \\mathbb{R}$ be the spatial domain indicated by the variable $x$, and let $[0,T]\\subset\\mathbb{R}$ be the time domain with variable $t$. We consider the one-dimensional heat equation with time-dependent Dirichlet boundary conditions,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    &\\frac{\\partial}{\\partial t} q(x,t) = \\frac{\\partial^2}{\\partial x^2}q(x,t)\n",
    "    & x &\\in\\Omega,\\quad t\\in[0,T],\n",
    "    \\\\\n",
    "    &q(0,t) = q(L,t) = u(t)\n",
    "    & t &\\in[0,T],\n",
    "    \\\\\n",
    "    &q(x,0) = \\big(e^{\\alpha(x - 1)} + e^{-\\alpha x} - e^{-\\alpha}\\big)u(0)\n",
    "    & x &\\in \\Omega,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\alpha>0$ is constant and $q(x,t)$ is the unknown state variable. This is a model for a one-dimensional rod conducting heat with a fixed initial heat profile. The temperature at the ends of the rod are governed by the input function $u(t)$, but heat is allowed to diffuse through the rod and flow out at the ends of the domain.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Objective\n",
    ":class: info\n",
    "\n",
    "Construct a reduced-order model (ROM) which can be solved rapidly to produce approximate solutions $q(x, t)$ to the partial differential equation given above for various choices of the input function $u(t)$.\n",
    "In addition, we will only observe data over a limited time interval $t \\in [0, T']$ with $T' < T$, then use the ROM to predict the solution for the entire time domain $[0, T]$.\n",
    "Hence, the ROM will be **predictive in time** and **predictive in the inputs**.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import opinf\n",
    "\n",
    "opinf.utils.mpl_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Training Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section a ROM is trained using data collected for a single choice of the input function $u(t).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-order Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the last tutorial, we use a centered finite difference approximation for the spatial derivative to arrive at a system of $n$ ordinary differential equations.\n",
    "This time, due to the nonzero boundary conditions, the system takes the form\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\ddt\\q(t) = \\A\\q(t) + \\B u(t),\n",
    "    \\qquad\n",
    "    \\q(0) = \\q_0,\n",
    "\\end{aligned}\n",
    "$$ (eq_inputs_fom)\n",
    "\n",
    "where $\\q:\\RR\\to\\RR^n$, $\\A\\in\\RR^{n\\times n}$, and $\\B\\in\\RR^{n}$.\n",
    "The system {eq}`eq_inputs_fom` is the _full-order model_ (FOM), which we will use to generate training data for the time domain $[0, T'] \\subset [0, T]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Discretization details\n",
    "\n",
    "We take an equidistant grid $\\{x_i\\}_{i=0}^{n+1} \\subset \\Omega$,\n",
    "\n",
    "\\begin{align*}\n",
    "    0 &= x_0 < x_1 < \\cdots < x_n < x_{n+1} = L\n",
    "    &\n",
    "    &\\text{and}\n",
    "    &\n",
    "    \\delta x &= \\frac{L}{n+1} = x_{i+1} - x_{i},\\quad i=1,\\ldots,n-1.\n",
    "\\end{align*}\n",
    "\n",
    "The boundary conditions prescribe $q(x_0,t) = q(x_{n+1},t) = u(t)$.\n",
    "Our goal is to compute $q(x,t)$ at the interior spatial points $x_{1},x_{2},\\ldots,x_{n}$ for various $t\\in[0,T]$, so we consider the state vector $\\q(t) = [~q(x_{1}, t)~\\cdots~q(x_{n}, t)~]\\trp\\in\\RR^n$ and derive a system governing the evolution of $\\q(t)$ in time.\n",
    "\n",
    "Approximating the spatial derivative with a central finite difference approximation,\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial^2}{\\partial x^2}q(x,t)\n",
    "    \\approx \\frac{q(x-\\delta x,t) - 2q(x,t) + q(x+\\delta x,t)}{(\\delta x)^2},\n",
    "$$\n",
    "\n",
    "and using the boundary conditions $q(0,t) = q(L,t) = u(t)$, we arrive at the following matrices for the FOM.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\A(\\mu) &= \\frac{1}{(\\delta x)^2}\\left[\\begin{array}{ccccc}\n",
    "        -2 & 1 & & & \\\\\n",
    "        1 & -2 & 1 & & \\\\\n",
    "        & \\ddots & \\ddots & \\ddots & \\\\\n",
    "        & & 1 & -2 & 1 \\\\\n",
    "        & & & 1 & -2 \\\\\n",
    "    \\end{array}\\right] \\in\\RR^{n\\times n},\n",
    "    &\n",
    "    \\B(\\mu) &= \\frac{1}{(\\delta x)^2}\\left[\\begin{array}{c}\n",
    "        1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 1\n",
    "    \\end{array}\\right]\\in\\RR^{n}.\n",
    "\\end{aligned}\n",
    "$$\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $L = 1$, $T = 1$, and set $\\alpha = 100$.\n",
    "We begin by solving the FOM described above, recording the solution every $\\delta t = 10^{-3}$ time units for a single choice of the input function $u(t)$, yielding $10^3 + 1 = 1001$ total time steps (1000 steps past the initial condition).\n",
    "We will assume that we can only observe the first $k = 200$ time steps and use the ROM to predict the remaining $801$ steps.\n",
    "Our training input function is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    u_\\text{train}(t) = 1 + \\frac{1}{4}\\sin(4\\pi t).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_input(tt):\n",
    "    return np.ones_like(tt) + np.sin(4 * np.pi * tt) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Construct the spatial domain.\n",
    "L = 1\n",
    "n = 2**10 - 1\n",
    "x_all = np.linspace(0, L, n + 2)\n",
    "x = x_all[1:-1]\n",
    "dx = x[1] - x[0]\n",
    "\n",
    "# Construct the temporal domain.\n",
    "T = 1\n",
    "K = 10**3 + 1\n",
    "t_all = np.linspace(0, T, K)\n",
    "dt = t_all[1] - t_all[0]\n",
    "\n",
    "# Construct the full-order state matrix A.\n",
    "dx2inv = 1 / dx**2\n",
    "diags = np.array([1, -2, 1]) * dx2inv\n",
    "A = scipy.sparse.diags(diags, [-1, 0, 1], (n, n))\n",
    "\n",
    "# Construct the full-order input matrix B.\n",
    "B = np.zeros_like(x)\n",
    "B[0], B[-1] = dx2inv, dx2inv\n",
    "\n",
    "# Define the full-order model with an opinf.models class.\n",
    "fom = opinf.models.ContinuousModel(\n",
    "    operators=[\n",
    "        opinf.operators.LinearOperator(A),\n",
    "        opinf.operators.InputOperator(B),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the part of the initial condition not dependent on u(t).\n",
    "alpha = 100\n",
    "q0 = np.exp(alpha * (x - 1)) + np.exp(-alpha * x) - np.exp(-alpha)\n",
    "\n",
    "\n",
    "def full_order_solve(time_domain, u):\n",
    "    \"\"\"Solve the full-order model with SciPy.\n",
    "    Here, u is a callable function.\n",
    "    \"\"\"\n",
    "    return fom.predict(q0 * u(0), time_domain, u, method=\"BDF\")\n",
    "\n",
    "\n",
    "# Solve the full-order model with the training input.\n",
    "with opinf.utils.TimedBlock(\"Full-order solve\"):\n",
    "    Q_all = full_order_solve(t_all, training_input)\n",
    "\n",
    "# Retain only the first k snapshots/inputs for training the ROM.\n",
    "k = 200\n",
    "t = t_all[:k]\n",
    "Q = Q_all[:, :k]\n",
    "\n",
    "print(f\"\\nSpatial domain:\\t\\t{x.shape=}\")\n",
    "print(f\"Spatial step size:\\t{dx=:.10f}\")\n",
    "print(f\"\\nFull time domain:\\t{t_all.shape=}\")\n",
    "print(f\"Training time domain:\\t{t.shape=}\")\n",
    "print(f\"Temporal step size:\\t{dt=:f}\")\n",
    "print(f\"\\nFull-order matrix A:\\t{A.shape=}\")\n",
    "print(f\"Full-order vector B:\\t{B.shape=}\")\n",
    "print(f\"\\nInitial condition:\\t{q0.shape=}\")\n",
    "print(f\"\\nAll FOM solutions:\\t{Q_all.shape=}\")\n",
    "print(f\"Training snapshots:\\t{Q.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code visualizes the training data and the full FOM solution set by plotting a few snapshots over the spatial domain and the time evolution of the snapshots at a few spatial locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_data_space(Z, u, title, ax=None):\n",
    "    \"\"\"Plot state data over space at multiple instances in time.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Plot a few snapshots over the spatial domain.\n",
    "    sample_columns = [0] + [2**d for d in range(10)]\n",
    "    color = iter(plt.cm.viridis_r(np.linspace(0.05, 1, len(sample_columns))))\n",
    "    while sample_columns[-1] > Z.shape[1] - 1:\n",
    "        sample_columns = sample_columns[:-1]\n",
    "    for j in sample_columns:\n",
    "        leftBC, rightBC = [u(t_all[j])], [u(t_all[j])]\n",
    "        q_all = np.concatenate([leftBC, Z[:, j], rightBC])\n",
    "        c = next(color)\n",
    "        ax.plot(x_all, q_all, lw=1, color=c, label=rf\"$q(x,t_{{{j}}})$\")\n",
    "\n",
    "    ax.set_xlim(x_all[0], x_all[-1])\n",
    "    ax.set_xlabel(r\"$x$\")\n",
    "    ax.set_ylabel(r\"$q(x,t)$\")\n",
    "    ax.legend(loc=(1.05, 0.05))\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "def plot_data_time(Z, title, ax=None):\n",
    "    \"\"\"Plot state in time at multiple spatial locations.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Plot a few snapshots over the spatial domain.\n",
    "    sample_rows = np.linspace(0, Z.shape[0] - 1, 11)\n",
    "    sample_rows = sample_rows[:-1] + (sample_rows[1] - sample_rows[0]) / 4\n",
    "    sample_rows = sample_rows.astype(int)\n",
    "    color = iter(plt.cm.inferno(np.linspace(0, 0.8, len(sample_rows))))\n",
    "    tt = t_all[: Z.shape[1]]\n",
    "    for i in sample_rows:\n",
    "        ax.plot(tt, Z[i], lw=1, color=next(color), label=rf\"$q(x_{{{i}}},t)$\")\n",
    "\n",
    "    ax.set_xlim(t_all[0], t_all[-1])\n",
    "    ax.set_xlabel(r\"$t$\")\n",
    "    ax.set_ylabel(r\"$q(x,t)$\")\n",
    "    ax.legend(loc=(1.05, 0.05))\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "def plot_two_datasets(Z1, Z2, u, title1=\"\", title2=\"\", cutoff=None):\n",
    "    \"\"\"Plot two datasets side by side with space and time plots.\"\"\"\n",
    "    _, [ax1, ax2] = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "    plot_data_space(Z1, u, title1, ax1)\n",
    "    plot_data_space(Z2, u, title2, ax2)\n",
    "    ax1.legend([])\n",
    "\n",
    "    fig, [ax1, ax2] = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "    plot_data_time(Z1, title1, ax1)\n",
    "    plot_data_time(Z2, title2, ax2)\n",
    "    ax1.legend([])\n",
    "    ax1.set_xlabel(\"\")\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    if cutoff is not None:\n",
    "        ax1.axvline(cutoff, color=\"gray\", linewidth=1, linestyle=\"--\")\n",
    "        ax1.text(cutoff - 10 * dt, 0, \"training\", ha=\"right\", color=\"gray\")\n",
    "        ax1.text(cutoff + 10 * dt, 0, \"prediction\", ha=\"left\", color=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_datasets(\n",
    "    Q,\n",
    "    Q_all,\n",
    "    training_input,\n",
    "    \"Snapshot data for training\",\n",
    "    \"Full-order model solution\",\n",
    "    cutoff=t[-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROM Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have snapshot data $\\Q \\in \\RR^{n \\times k}$, but to learn a model with external inputs, we need training data for the inputs as well as for the snapshots.\n",
    "Define the vector\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\U = \\left[\\begin{array}{cccc}\n",
    "        u_\\text{train}(t_0) & u_\\text{train}(t_1) & \\cdots & u_\\text{train}(t_{k-1})\n",
    "    \\end{array}\\right]\n",
    "    \\in\\RR^{k},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which collects the values of the training input function at the same times as the training snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = training_input(t)\n",
    "\n",
    "print(f\"Training snapshots:\\t{Q.shape=}\")\n",
    "print(f\"Training inputs:\\t{U.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a {class}`opinf.basis.PODBasis` to reduce the dimension of the snapshot training data, which approximates the discretized state vector as $\\q(t) \\approx \\Vr\\qhat(t)$ for some $\\Vr\\in\\RR^{n\\times r}$ with orthonormal columns and $\\qhat(t)\\in\\RR^{r}$, with and $r\\ll n$.\n",
    "Input training data are *not* typically compressed with dimensionality reduction or subjected to other pre-processing routines.\n",
    "Because the FOM {eq}`eq_inputs_fom` has the linear-time invariant form $\\ddt\\q(t) = \\A\\q(t) + \\B u(t)$, we seek a ROM with the same structure, i.e.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\ddt\\qhat(t) = \\Ahat\\qhat(t) + \\Bhat u(t),\n",
    "    \\qquad\n",
    "    \\qhat(0) = \\Vr\\trp\\q_0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Data for the time derivative $\\ddt\\qhat(t)$ are estimated in this example with sixth-order finite differences using {class}`opinf.ddt.UniformFiniteDifferencer`.\n",
    "The underlying least-squares problem to determine $\\Ahat$ and $\\Bhat$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{\\Ahat,\\Bhat}\n",
    "    \\sum_{j=0]^{k-1}\\left\\|\n",
    "        \\Ahat\\qhat_{j} + \\Bhat\\u_j - \\dot{\\qhat}_j\n",
    "    \\right\\|_{2}^{2},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\qhat_j = \\qhat(t_j)\\in\\RR^{r}$ and $u_j = u(t_j)\\in\\RR$ are the state snapshots and input data, respectively, and $\\dot{\\qhat}_j \\approx \\ddt\\qhat(t)|_{t=t_j}\\in\\RR^{r}$ are the estimated time derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Why Use the Same Structure?\n",
    "\n",
    "An OpInf ROM should have the same structure as an intrusive Galerkin ROM.\n",
    "The Galerkin ROM for {eq}`eq_inputs_fom` is derived by substituting in the approximation $\\q(t)\\approx\\Vr\\qhat(t)$, yielding\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\ddt\\Vr\\qhat(t) = \\A\\Vr\\qhat(t) + \\B u(t),\n",
    "    \\qquad\n",
    "    \\Vr\\qhat(0) = \\q_0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Next, left multiply by $\\Vr\\trp$ and use the fact that $\\Vr\\trp\\Vr = \\I$ to get the following:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\ddt\\qhat(t) = \\tilde{\\A}\\qhat(t) + \\tilde{\\B}u(t),\n",
    "    \\qquad\n",
    "    \\qhat(0) = \\Vr\\trp\\q_0,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\tilde{\\A} = \\Vr\\trp\\A\\Vr \\in \\RR^{r\\times r}$ and $\\tilde{\\B} = \\Vr\\trp\\B\\in\\RR^{r}$.\n",
    "Note that this ROM has the same input function $u(t)$ as the FOM.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training input data are passed to {meth}`opinf.rom.ROM.fit()` as the `inputs` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom = opinf.ROM(\n",
    "    basis=opinf.basis.PODBasis(residual_energy=1e-6),\n",
    "    ddt_estimator=opinf.ddt.UniformFiniteDifferencer(t, \"ord6\"),\n",
    "    model=opinf.models.ContinuousModel(\"AB\"),\n",
    ")\n",
    "\n",
    "with opinf.utils.TimedBlock(\"Fitting OpInf ROM\"):\n",
    "    rom.fit(Q, inputs=U)\n",
    "\n",
    "with opinf.utils.TimedBlock(\"Reduced-order solve\"):\n",
    "    Q_ROM = rom.predict(q0, t_all, input_func=training_input, method=\"BDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_datasets(\n",
    "    Q_ROM,\n",
    "    Q_all,\n",
    "    training_input,\n",
    "    \"Reduced-order model solution\",\n",
    "    \"Full-order model solution\",\n",
    "    cutoff=t[-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a closer look at the difference between the FOM and ROM solutions, we compute the relative $\\ell_2$-norm error of the ROM solution as a function of time using {func}`opinf.post.lp_error()` and the relative Forbenius-norm error using {func}`opinf.post.frobenius_error()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_errors_over_time(\n",
    "    Ztrue, basis, Z1, label1, Z2=None, label2=None, cutoff=None\n",
    "):\n",
    "    \"\"\"Plot normalized absolute projection error and ROM error(s)\n",
    "    as a function of time.\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    projection_err = opinf.post.lp_error(Ztrue, basis.project(Ztrue))[1]\n",
    "    ax.semilogy(t_all, projection_err, \"C3-\", lw=1, label=\"Projection Error\")\n",
    "\n",
    "    relative_error = opinf.post.lp_error(Ztrue, Z1)[1]\n",
    "    ax.semilogy(t_all, relative_error, \"C0--\", lw=1, label=label1)\n",
    "\n",
    "    if Z2 is not None:\n",
    "        relative_error = opinf.post.lp_error(Ztrue, Z2)[1]\n",
    "        ax.semilogy(t_all, relative_error, \"C5-.\", lw=1, label=label2)\n",
    "\n",
    "    if cutoff is not None:\n",
    "        ax.axvline(cutoff, color=\"gray\", linewidth=1, linestyle=\"--\")\n",
    "        ymin = projection_err.min() / 4\n",
    "        ax.text(cutoff - 10 * dt, ymin, \"training\", ha=\"right\", color=\"gray\")\n",
    "        ax.text(cutoff + 10 * dt, ymin, \"prediction\", ha=\"left\", color=\"gray\")\n",
    "        ax.set_ylim(bottom=ymin / 2)\n",
    "\n",
    "    ax.set_xlim(t_all[0], t_all[-1])\n",
    "    ax.set_xlabel(r\"$t$\")\n",
    "    ax.set_ylabel(\"Relative error\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors_over_time(Q_all, rom.basis, Q_ROM, \"OpInf ROM error\", cutoff=t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_opinf = opinf.post.frobenius_error(Q_all, Q_ROM)[1]\n",
    "print(f\"OpInf ROM error:\\t{error_opinf:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to the Intrusive Galerkin ROM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical intrusive Galerkin ROM for this problem is given by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\ddt\\qhat(t) = \\tilde{\\A}\\qhat(t) + \\tilde{\\B}u(t),\n",
    "    \\qquad\n",
    "    \\qhat(0) = \\Vr\\trp\\q_0,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\tilde{\\A} = \\Vr\\trp\\A\\Vr \\in \\RR^{r\\times r}$ and $\\tilde{\\B} = \\Vr\\trp\\B\\in\\RR^{r}$.\n",
    "Here, we form this ROM explicitly (using the same basis matrix $\\Vr$ as before) and compare it to our existing OpInf ROM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom_intrusive = opinf.ROM(\n",
    "    basis=rom.basis,\n",
    "    model=fom.galerkin(rom.basis.entries),  # Explicitly project FOM operators.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with opinf.utils.TimedBlock(\"Reduced-order model solve (intrusive)\"):\n",
    "    Q_ROM_intrusive = rom_intrusive.predict(\n",
    "        q0, t_all, input_func=training_input, method=\"BDF\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors_over_time(\n",
    "    Q_all,\n",
    "    rom.basis,\n",
    "    Q_ROM,\n",
    "    \"OpInf ROM error\",\n",
    "    Q_ROM_intrusive,\n",
    "    \"Intrusive ROM error\",\n",
    "    cutoff=t[-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_intrusive = opinf.post.frobenius_error(Q_all, Q_ROM_intrusive)[1]\n",
    "error_projection = rom.basis.projection_error(Q_all, relative=True)\n",
    "\n",
    "print(\n",
    "    \"Relative Frobenius-norm errors\",\n",
    "    \"-\" * 33,\n",
    "    f\"Projection error:\\t{error_projection:%}\",\n",
    "    f\"OpInf ROM error:\\t{error_opinf:%}\",\n",
    "    f\"Intrusive ROM error:\\t{error_intrusive:%}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, the OpInf ROM and the corresponding intrusive ROM have comparable error, even though the OpInf ROM is calibrated without intrusive access to the FOM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization to New Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous experiment uses a single choice of $u(t)$ for the training and for the prediction in time.\n",
    "Now, we define a new choice of input function $u(t)$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    u_\\text{test}(t)\n",
    "    = 1 + t(1 - t),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and evaluate the FOM and ROM for this new input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input(t):\n",
    "    return 1 + t * (1 - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with opinf.utils.TimedBlock(\"Full-order solve\"):\n",
    "    Qtest_FOM = full_order_solve(t_all, test_input)\n",
    "\n",
    "with opinf.utils.TimedBlock(\"Reduced-order solve (OpInf)\"):\n",
    "    Qtest_ROM = rom.predict(q0, t_all, test_input, method=\"BDF\")\n",
    "\n",
    "with opinf.utils.TimedBlock(\"Reduced-order solve (intrusive)\"):\n",
    "    Qtest_ROM_intrusive = rom_intrusive.predict(\n",
    "        q0, t_all, test_input, method=\"BDF\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_datasets(\n",
    "    Qtest_ROM,\n",
    "    Qtest_FOM,\n",
    "    test_input,\n",
    "    \"OpInf Reduced-order model solution\",\n",
    "    \"Full-order model solution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors_over_time(\n",
    "    Qtest_FOM,\n",
    "    rom.basis,\n",
    "    Qtest_ROM,\n",
    "    \"OpInf ROM error\",\n",
    "    Qtest_ROM_intrusive,\n",
    "    \"Intrusive ROM error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ROMs perform well with a new input function, but the intrusive ROM performs slightly better than the OpInf ROM.\n",
    "This is typical; intrusive ROMs are often more robust and generalizable than standard OpInf ROMs, but OpInf ROMs tend to reproduce training data better than intrusive ROMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Training Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data corresponding to several choices of the input function $u(t)$ are available for training, we collect a list of snapshot matrices and a list of corresponding inputs to pass to `fit()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we solve the PDE using the three input functions for training data:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    &u_\\text{train}^{(1)}(t) = e^{-t},\n",
    "    &&&\n",
    "    &u_\\text{train}^{(2)}(t) = 1 + \\frac{1}{2}t^2,\n",
    "    &&&\n",
    "    &u_\\text{train}^{(3)}(t) = 1 - \\frac{1}{2}\\sin(\\pi t).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The following input functions are used for testing.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    &u_\\text{test}^{(1)}(t) = 1 - \\frac{1}{2}\\sin(3\\pi t),\n",
    "    &&&\n",
    "    &u_\\text{test}^{(2)}(t) = 1 + 25 (t (t - 1))^3,\n",
    "    &&&\n",
    "    &u_\\text{test}^{(3)}(t) = 1 + e^{-2t}\\sin(\\pi t).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = [\n",
    "    lambda t: np.exp(-t),\n",
    "    lambda t: 1 + t**2 / 2,\n",
    "    lambda t: 1 - np.sin(np.pi * t) / 2,\n",
    "]\n",
    "\n",
    "testing_inputs = [\n",
    "    lambda t: 1 - np.sin(3 * np.pi * t) / 3,\n",
    "    lambda t: 1 + 25 * (t * (t - 1)) ** 3,\n",
    "    lambda t: 1 + np.exp(-2 * t) * np.sin(np.pi * t),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the input functions.\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, sharex=True)\n",
    "c = 0\n",
    "for input_func in training_inputs:\n",
    "    ax1.plot(t_all, input_func(t_all), color=f\"C{c}\", lw=1)\n",
    "    c += 1\n",
    "for input_func in testing_inputs:\n",
    "    ax2.plot(t_all, input_func(t_all), color=f\"C{c}\", lw=1)\n",
    "    c += 1\n",
    "\n",
    "ax1.set_title(\"Training inputs\")\n",
    "ax2.set_title(\"Testing inputs\")\n",
    "# ax1.axvline(t[-1], color=\"k\", lw=1)\n",
    "ax1.axvline(t[-1], color=\"gray\", linewidth=1, linestyle=\"--\")\n",
    "ax1.text(t[-1] - 10 * dt, 1.4, \"training\", ha=\"right\", color=\"gray\")\n",
    "ax1.text(t[-1] + 10 * dt, 1.4, \"prediction\", ha=\"left\", color=\"gray\")\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_xlim(t_all[0], t_all[-1])\n",
    "    ax.set_xlabel(r\"$t$\")\n",
    "    ax.set_ylabel(r\"$u(t)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the full-order model for each training input and collect results.\n",
    "Qs = []  # State snapshots.\n",
    "Us = []  # Corresponding inputs.\n",
    "\n",
    "for u in training_inputs:\n",
    "    Qs.append(full_order_solve(t, u))\n",
    "    Us.append(u(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom = opinf.ROM(\n",
    "    basis=opinf.basis.PODBasis(residual_energy=1e-6),\n",
    "    ddt_estimator=opinf.ddt.UniformFiniteDifferencer(t, \"ord6\"),\n",
    "    model=opinf.models.ContinuousModel(\"AB\"),\n",
    ")\n",
    "\n",
    "with opinf.utils.TimedBlock(\"Fitting OpInf ROM\"):\n",
    "    rom.fit(Qs, inputs=Us)\n",
    "\n",
    "rom_intrusive = opinf.ROM(\n",
    "    basis=rom.basis,\n",
    "    model=fom.galerkin(rom.basis.entries),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, u in enumerate(testing_inputs):\n",
    "    print(f\"Test input function {i+1:d}\")\n",
    "\n",
    "    with opinf.utils.TimedBlock(\"Full-order solve\"):\n",
    "        Q_FOM = full_order_solve(t_all, u)\n",
    "\n",
    "    with opinf.utils.TimedBlock(\"Reduced-order solve (OpInf)\"):\n",
    "        Q_ROM = rom.predict(q0, t_all, u, method=\"BDF\")\n",
    "\n",
    "    with opinf.utils.TimedBlock(\"Reduced-order solve (intrusive)\"):\n",
    "        Q_ROM_intrusive = rom_intrusive.predict(q0, t_all, u, method=\"BDF\")\n",
    "\n",
    "    plot_two_datasets(\n",
    "        Q_ROM,\n",
    "        Q_FOM,\n",
    "        u,\n",
    "        \"Reduced-order model solution (OpInf)\",\n",
    "        \"Full-order model solution\",\n",
    "    )\n",
    "\n",
    "    plot_errors_over_time(\n",
    "        Q_FOM,\n",
    "        rom.basis,\n",
    "        Q_ROM,\n",
    "        \"OpInf ROM error\",\n",
    "        Q_ROM_intrusive,\n",
    "        \"Intrusive ROM error\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Multi-dimensional Inputs\n",
    ":class: tip\n",
    "\n",
    "The examples in this tutorial use a scalar-valued input function $u:\\RR\\to\\RR$.\n",
    "For models with vector inputs $\\u:\\RR\\to\\RR^m$ with $m > 1$, training inputs are collected into a matrix with $m$ rows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\U = \\left[\\begin{array}{cccc}\n",
    "        \\u(t_0) & \\u(t_1) & \\cdots & \\u_(t_{k-1})\n",
    "    \\end{array}\\right]\n",
    "    \\in \\RR^{m \\times k}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is the matrix used for the `inputs` argument of `fit()`.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
