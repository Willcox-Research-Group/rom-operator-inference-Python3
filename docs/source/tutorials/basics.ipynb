{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": false
   },
   "source": [
    "(sec-tutorial)=\n",
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "The `opinf` package constructs reduced-order models for large dynamical systems.\n",
    "Such systems often arise from the numerical solution of partial differentials equations.\n",
    "In this introductory tutorial, we use operator inference to learn a reduced-order model for a simple heat equation.\n",
    "This is a simplified version of the first numerical example in {cite}`peherstorfer2016opinf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Governing Equations\n",
    ":class: attention\n",
    "\n",
    "For the spatial domain $\\Omega = [0,L]\\subset \\mathbb{R}$ and the time domain $[t_0,t_f]\\subset\\mathbb{R}$, consider the one-dimensional heat equation with homogeneous Dirichlet boundary conditions:\n",
    "\n",
    "\\begin{align*}\n",
    "    &\\frac{\\partial}{\\partial t} q(x,t) = \\frac{\\partial^2}{\\partial x^2}q(x,t)\n",
    "    & x &\\in\\Omega,\\quad t\\in(t_0,t_f],\n",
    "    \\\\\n",
    "    &q(0,t) = q(L,t) = 0\n",
    "    & t &\\in [t_0,t_f],\n",
    "    \\\\\n",
    "    &q(x,t_0) = q_{0}(x)\n",
    "    & x &\\in \\Omega.\n",
    "\\end{align*}\n",
    "\n",
    "This is a model for a one-dimensional rod that conducts heat.\n",
    "The unknown state variable $q(x,t)$ represents the temperature of the rod at location $x$ and time $t$; the temperature at the ends of the rod are fixed at $0$ and heat is allowed to flow out of the rod at the ends.\n",
    ":::\n",
    "\n",
    ":::{admonition} Objective\n",
    ":class: attention\n",
    "\n",
    "Construct a low-dimensional system of ordinary differential equations, called the _reduced-order model_ (ROM), which can be solved rapidly to produce approximate solutions $q(x, t)$ to the partial differential equation given above. We will use operator inference (OpInf) to learn the ROM from high-fidelity data for one choice of initial condition $q_0(x)$ and test its performance on new initial conditions.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Full-order Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem numerically, let $\\{x\\}_{i=0}^{n+1}$ be an equidistant grid of $n+2$ points on $\\Omega$, i.e.,\n",
    "\n",
    "\\begin{align*}\n",
    "    0 &= x_0 < x_1 < \\cdots < x_n < x_{n+1} = L\n",
    "    &\n",
    "    &\\text{and}\n",
    "    &\n",
    "    \\delta x &= \\frac{L}{n+1} = x_{i+1} - x_{i},\\quad i=1,\\ldots,n-1.\n",
    "\\end{align*}\n",
    "\n",
    "The boundary conditions prescribe $q(x_0,t) = q(x_{n+1},t) = 0$.\n",
    "Our goal is to compute $q(x, t)$ at the interior spatial points $x_{1}, x_{2}, \\ldots, x_{n}$ for various $t = [0,T]$. we wish to compute the state vector\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{q}(t)\n",
    "    = \\left[\\begin{array}{c}\n",
    "        q(x_1,t) \\\\ \\vdots \\\\ q(x_n,t)\n",
    "    \\end{array}\\right]\\in\\mathbb{R}^n\n",
    "\\end{align*}\n",
    "\n",
    "for $t\\in[t_0,t_f]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing a central finite difference approximation for the spatial derivative,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial^2}{\\partial x^2}q(x,t) &\\approx \\frac{q(x-\\delta x,t) - 2q(x,t) + q(x+\\delta x,t)}{(\\delta x)^2},\n",
    "\\end{align*}\n",
    "\n",
    "yields the semi-discrete linear system\n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t) = \\mathbf{A}\\mathbf{q}(t),\n",
    "\\qquad\n",
    "\\mathbf{q}(0) = \\mathbf{q}_0,\n",
    "$$ (eq_basics_fom)\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{A} &= \\frac{1}{(\\delta x)^2}\\left[\\begin{array}{ccccc}\n",
    "        -2 & 1 & & & \\\\\n",
    "        1 & -2 & 1 & & \\\\\n",
    "        & \\ddots & \\ddots & \\ddots & \\\\\n",
    "        & & 1 & -2 & 1 \\\\\n",
    "        & & & 1 & -2 \\\\\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n\\times n},\n",
    "    &\n",
    "    \\mathbf{q}_0 &= \\left[\\begin{array}{c}\n",
    "    q_{0}(x_{1}) \\\\ q_{0}(x_{2}) \\\\ \\vdots \\\\ q_{0}(x_{n-1}) \\\\ q_{0}(x_{n})\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n}.\n",
    "\\end{align*}\n",
    "\n",
    "Equation {eq}`eq_basics_fom` is called the _full-order model_ (FOM) or the _high-fidelity model_. The computational complexity of solving {eq}`eq_basics_fom` depends on the dimension $n$, which must often be large in order for $\\mathbf{q}(t)$ to approximate $q(x,t)$ well over the spatial grid. Our goal is to construct a ROM that approximates the FOM, but whose computational complexity only depends on some smaller dimension $r \\ll n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "One key advantage of OpInf is that, because it learns a ROM from data alone, direct access to the high-fidelity solver (the matrix $\\mathbf{A}$ in this case) is not required. In this tutorial, we explicitly construct the high-fidelity solver, but in practice, we only need the following:\n",
    "1. Solution outputs of a high-fidelity solver to learn from, and\n",
    "2. Some knowledge of the structure of the governing equations.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Solve the Full-order Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "For this demo, we'll use $t_0 = 0$ and $L = t_f = 1$.\n",
    "We begin by simulating the full-order system described above with the initial condition\n",
    "\n",
    "$$\n",
    "    q_{0}(x) = x(1 - x),\n",
    "$$\n",
    "\n",
    "using a maximal time step size $\\delta t = 10^{-3}$.\n",
    "This results in $k = 10^3 + 1 = 1001$ state snapshots (1000 time steps after the initial condition), which are organized as the _snapshot matrix_ $\\mathbf{Q}\\in\\mathbb{R}^{n\\times k}$, where the $j$th column is the solution trajectory at time $t_j$:\n",
    "\n",
    "$$\n",
    "    \\mathbf{Q} = \\left[\\begin{array}{ccc}\n",
    "        && \\\\\n",
    "        \\mathbf{q}_{0} & \\cdots & \\mathbf{q}_{k-1}\n",
    "        \\\\ &&\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n\\times k},\n",
    "    \\qquad\n",
    "    \\mathbf{q}_{j} := \\mathbf{q}(t_j) \\in\\mathbb{R}^{n},\\quad j = 0, \\ldots, k-1.\n",
    "$$\n",
    "\n",
    "Note that the initial condition $\\mathbf{q}_{0}$ is included as a column in the snapshot matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Matplotlib customizations.\n",
    "plt.rc(\"axes.spines\", right=False, top=False)\n",
    "plt.rc(\"figure\", dpi=300, figsize=(9, 3))\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"legend\", edgecolor=\"none\", frameon=False)\n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "# Pandas display options.\n",
    "pd.options.display.float_format = \"{:.4%}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the spatial domain.\n",
    "L = 1                           # Spatial domain length.\n",
    "n = 2**7 - 1                    # Spatial grid size.\n",
    "x_all = np.linspace(0, L, n+2)  # Full spatial grid.\n",
    "x = x_all[1:-1]                 # Interior spatial grid (where q is unknown).\n",
    "dx = x[1] - x[0]                # Spatial resolution.\n",
    "\n",
    "# Construct the temporal domain.\n",
    "t0, tf = 0, 1                   # Initial and final time.\n",
    "k = tf*1000 + 1                 # Temporal grid size.\n",
    "t = np.linspace(t0, tf, k)      # Temporal grid.\n",
    "dt = t[1] - t[0]                # Temporal resolution.\n",
    "\n",
    "print(f\"Spatial step size δx = {dx}\")\n",
    "print(f\"Temporal step size δt = {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full-order state matrix A.\n",
    "diags = np.array([1,-2,1]) / (dx**2)\n",
    "A = sparse.diags(diags, [-1,0,1], (n,n))\n",
    "\n",
    "# Define the full-order model dx/dt = f(t,x),  x(0) = x0.\n",
    "def fom(t, x):\n",
    "    return A @ x\n",
    "\n",
    "# Construct the initial condition for the training data.\n",
    "q0 = x * (1 - x)\n",
    "\n",
    "print(f\"shape of A:\\t{A.shape}\")\n",
    "print(f\"shape of q0:\\t{q0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute snapshots by solving the full-order model with SciPy.\n",
    "Q = solve_ivp(fom, [t0,tf], q0, t_eval=t, method=\"BDF\", max_step=dt).y\n",
    "\n",
    "print(f\"shape of Q: {Q.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{caution}\n",
    "It is often better to use your own ODE solver instead of integration packages such as [**scipy.integrate**](https://docs.scipy.org/doc/scipy/tutorial/integrate.html). If the integration strategy of the FOM is known (e.g., Backward Euler), try using that strategy with the ROM.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualize the snapshots to get a sense of how the solution looks qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_heat_data(Z, title, ax=None):\n",
    "    \"\"\"Visualize temperature data in space and time.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Plot a few snapshots over the spatial domain.\n",
    "    sample_columns = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "    color = iter(plt.cm.viridis_r(np.linspace(.05, 1, len(sample_columns))))\n",
    "\n",
    "    leftBC, rightBC = [0], [0]\n",
    "    for j in sample_columns:\n",
    "        q_all = np.concatenate([leftBC, Z[:,j], rightBC])\n",
    "        ax.plot(x_all, q_all, color=next(color), label=fr\"$q(x,t_{{{j}}})$\")\n",
    "\n",
    "    ax.set_xlim(x_all[0], x_all[-1])\n",
    "    ax.set_xlabel(r\"$x$\")\n",
    "    ax.set_ylabel(r\"$q(x,t)$\")\n",
    "    ax.legend(loc=(1.05, .05))\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_data(Q, \"Snapshot data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches our intuition: initially there is more heat toward the center of the rod, which then diffuses out of the ends of the rod. In the figure, earlier times are lighter colors and later times are darker colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have gathered some training data by simulating the FOM.\n",
    "We also have an initial condition and space and time domains.\n",
    "\n",
    "| Name | Symbol | Code Variable |\n",
    "| :--- | :----: | :------------ |\n",
    "| State snapshots | $\\mathbf{Q}$ | `Q` |\n",
    "| Initial state | $\\mathbf{q}_0$ | `q0` |\n",
    "| Spatial variable | $\\Omega$ | `x` |\n",
    "| Time domain | $[t_0,t_f]$ | `t` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operator Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FOM has the form {eq}`eq_basics_fom`,\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)\n",
    "    = \\mathbf{A}\\mathbf{q}(t),\\qquad\\mathbf{q}(0)\n",
    "    = \\mathbf{q}_0,\n",
    "$$\n",
    "\n",
    "with $\\mathbf{q}(t)\\in\\mathbb{R}^{n}$ and $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$.\n",
    "Because Galerkin projection preserves the linear structure of the equations, we seek a ROM with a linear structure,\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\hat{\\mathbf{q}}(t)\n",
    "    = \\hat{\\mathbf{A}}\\hat{\\mathbf{q}}(t),\\qquad\\hat{\\mathbf{q}}(0)\n",
    "    = \\hat{\\mathbf{q}}_0,\n",
    "$$ (eq_basics_rom)\n",
    "\n",
    "but with $\\hat{\\mathbf{q}}(t)\\in \\mathbb{R}^{r}$ and $\\hat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}$ for some $r\\ll n$.\n",
    "The high-dimensional and low-dimensional states are related by $\\mathbf{q}(t) \\approx \\mathbf{V}_{\\!r}\\hat{\\mathbf{q}}(t)$, where $\\mathbf{V}_{\\!r}\\in\\mathbb{R}^{n \\times r}$ is called the [basis matrix](sec-guide-dimensionality).\n",
    "Operator inference constructs {eq}`eq_basics_rom` by solving a low-dimensional data-driven minimization for $\\hat{\\mathbf{A}}$,\n",
    "\n",
    "$$\n",
    "    \\min_{\\hat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\hat{\\mathbf{A}}\\mathbf{V}_{\\!r}^{\\mathsf{T}}\\mathbf{q}_{j} - \\mathbf{V}_{\\!r}^{\\mathsf{T}}\\dot{\\mathbf{q}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    + \\mathcal{R}(\\hat{\\mathbf{A}}),\n",
    "$$ (eq_basics_opinf)\n",
    "\n",
    "where $\\dot{\\mathbf{q}}_{j} := \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)\\big|_{t = t_j}$ is a measurement of the time derivative of $\\mathbf{q}(t)$ at time $t = t_{j}$, and $\\mathcal{R}(\\hat{\\mathbf{A}})$ is a [regularization term](subsec-tutorial-regularization) to stabilize the learning problem.\n",
    "We often abbreviate this problem as\n",
    "\n",
    "$$\n",
    "    \\min_{\\hat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\hat{\\mathbf{A}}\\hat{\\mathbf{q}}_{j} - \\hat{\\dot{\\mathbf{q}}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    + \\mathcal{R}(\\hat{\\mathbf{A}}),\n",
    "$$\n",
    "\n",
    "where $\\hat{\\mathbf{q}}_{j} = \\mathbf{V}_{\\!r}^{\\mathsf{T}}\\mathbf{q}_{j}$ and $\\dot{\\hat{\\mathbf{q}}}_{j} = \\mathbf{V}_{\\!r}^{\\mathsf{T}}\\dot{\\mathbf{q}}_{j}$ for $j=0,\\ldots,k-1$.\n",
    "\n",
    "We have several tasks to consider:\n",
    "1. Choosing the dimension $r$ of the ROM,\n",
    "2. Constructing a low-dimensional subspace (computing $\\mathbf{V}_{\\!r}$),\n",
    "3. Compressing the state data to the low-dimensional subspace (computing $\\mathbf{V}_{\\!r}^{\\mathsf{T}}\\mathbf{q}_{j}$, $j=0,\\ldots,k-1$),\n",
    "4. Estimating the time derivatives of the state data (computing $\\mathbf{V}_{\\!r}^{\\mathsf{T}}\\dot{\\mathbf{q}}_{j}$, $j=0,\\ldots,k-1$),\n",
    "5. Constructing the ROM {eq}`eq_basics_rom` via OpInf {eq}`eq_basics_opinf`,\n",
    "6. Simulating the ROM, and\n",
    "7. Evaluating the performance of the ROM.\n",
    "\n",
    "We will do this all at once, then show each step in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opinf\n",
    "\n",
    "Vr, svdvals = opinf.basis.pod_basis(Q, r=2)              # Construct the low-dimensional basis.\n",
    "Q_ = Vr.T @ Q                                            # Compress the state data to the low-dimensional subspace.\n",
    "Qdot_ = opinf.ddt.ddt(Q_, dt, order=6)                   # Estimate the time derivatives of the compressed states.\n",
    "rom = opinf.models.ContinuousModel(\"A\")                  # Define the structure of the reduced-order model equations.\n",
    "solver = opinf.lstsq.L2Solver(regularizer=1e-2)          # Select a least-squares solver with regularization.\n",
    "rom.fit(Q_, Qdot_, solver=solver)                        # Use operator inference to calibrate the reduced-order model.\n",
    "q0_ = Vr.T @ q0                                          # Compress the initial conditions to the low-dimensional subspace.\n",
    "Q_ROM_ = rom.predict(q0_, t, method=\"BDF\", max_step=dt)  # Solve the reduced-order model equations by integrating.\n",
    "Q_ROM = Vr @ Q_ROM_                                      # Map the compressed solution back to the original state space.\n",
    "opinf.post.frobenius_error(Q, Q_ROM)[1]                  # Compute the relative error of the ROM simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dimension of the ROM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integer $r$, which defines the dimension of the ROM to be constructed, is usually determined by how quickly the singular values $\\{\\sigma_j\\}_{j=1}^{n}$ of the snapshot matrix $\\mathbf{Q}$ decay.\n",
    "Fast singular value decay is a good sign that a ROM may be successful with this kind of data; if the singular values do not decay quickly, then we may need a large $r$ to capture the behavior of the system.\n",
    "\n",
    "The function {func}`opinf.basis.pod_basis` uses [**scipy.linalg.svdvals()**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svdvals.html) to calculate the singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output",
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "import opinf\n",
    "\n",
    "V, svdvals = opinf.basis.pod_basis(Q)\n",
    "svdvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function {func}`opinf.basis.svdval_decay` determines the number of (normalized) singular values that are greater than a given tolerance. It can also be used to plot the singular value decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opinf\n",
    "\n",
    "tolerance = 1e-6\n",
    "r = opinf.basis.svdval_decay(svdvals, tol=tolerance, normalize=True, plot=True)\n",
    "plt.xlim(right=60)\n",
    "plt.show()\n",
    "print(f\"{r:d} normalized singular values are greater than 10^({int(np.log10(tolerance)):d})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the relative contribution of the singular values, i.e., choose $r$ such that the cumulative energy\n",
    "\n",
    "$$\n",
    "    \\mathcal{E}_{r}(\\mathbf{Q}) = \\frac{\\sum_{j=1}^r \\sigma_j^2}{\\sum_{j=1}^n \\sigma_j^2}\n",
    "$$\n",
    "\n",
    "is greater than a given value (usually something very close to 1).\n",
    "This can be calculated with {func}`opinf.basis.cumulative_energy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = .999999\n",
    "r = opinf.basis.cumulative_energy(svdvals, kappa, plot=False)\n",
    "print(f\"r = {r:d} singular values exceed {kappa:.4%} energy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that we can capture 99.9999% of the behavior of the full-order state snapshots with only 2 modes.\n",
    "So for now, we'll fix $r = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Low-dimensional Subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a basis matrix $\\mathbf{V}_{r}\\in\\mathbb{R}^{n \\times r}$ to define the linear subspace to which the ROM states will be confined.\n",
    "One of the most standard strategies, which aligns with our analysis of the singular values of $\\mathbf{Q}$, is the _POD basis of rank $r$_ corresponding to $\\mathbf{Q}$.\n",
    "If $\\mathbf{Q}$ has the singular value decomposition\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = \\boldsymbol{\\Phi} \\boldsymbol{\\Sigma} \\boldsymbol{\\Psi}^{\\top},\n",
    "$$\n",
    "\n",
    "then the POD basis of rank $r$ consists of the first $r$ columns of $\\boldsymbol{\\Phi}$, i.e., the dominant $r$ left singular vectors of $\\mathbf{Q}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{V}_{r} := \\boldsymbol{\\Phi}_{:,:r}.\n",
    "$$\n",
    "\n",
    "The matrix $\\mathbf{V}_{r}$ is the first return value of {func}`opinf.basis.pod_basis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 2\n",
    "\n",
    "# Extract the first r singular vectors from the matrix computed earlier.\n",
    "Vr = V[:, :r]\n",
    "\n",
    "# Or, compute the basis from scratch.\n",
    "Vr, svdvals = opinf.basis.pod_basis(Q, r, mode=\"dense\")\n",
    "print(f\"Shape of Vr: {Vr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the kinds of solutions we may see, we plot the columns of $\\mathbf{V}_r$.\n",
    "All solutions of the resulting ROM can only be linear combinations of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(Vr.shape[1]):\n",
    "    plt.plot(x_all, np.concatenate(([0], Vr[:,j], [0])), label=f\"POD mode {j+1}\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tip}\n",
    "The {class}`opinf.basis.PODBasis` class conveniently combines basis construction and dimension selection. The {meth}`opinf.basis.PODBasis.fit` method receives the state matrix $\\mathbf{Q}$ and either the desired reduced dimension $r$ or a threshold value for selecting $r$ based on the cumulative or residual energy.\n",
    "\n",
    "The next tutorial uses {class}`opinf.basis.PODBasis` instead of {func}`opinf.basis.pod_basis`.\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Time Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator inference constructs a ROM by solving a least-squares regression problem.\n",
    "In this case, the ROM has the form $\\frac{\\text{d}}{\\text{d}t}\\hat{\\mathbf{q}}(t) = \\hat{\\mathbf{A}}\\hat{\\mathbf{q}}(t)$.\n",
    "The snapshot matrix $\\mathbf{Q} \\in \\mathbb{R}^{n \\times k}$ contains data for $\\mathbf{q}(t)$, which can be compressed as $\\hat{\\mathbf{Q}} = \\mathbf{V}_{\\!r}^{\\mathsf{T}}\\mathbf{Q} \\in \\mathbb{R}^{r \\times k}$ to get data for $\\hat{\\mathbf{q}}(t)$, but we also need data for $\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)$.\n",
    "In this simple example, we can directly compute the _snapshot time derivative matrix_ $\\dot{\\mathbf{Q}}\\in\\mathbb{R}^{n\\times k}$ that corresponds to the snapshots by setting $\\dot{\\mathbf{Q}} = \\mathbf{A} \\mathbf{Q}$, then compute the compression $\\dot{\\hat{\\mathbf{Q}}} = \\mathbf{V}_{\\!r}^{\\mathsf{T}}\\dot{\\mathbf{Q}} \\in \\mathbb{R}^{r \\times k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdot = A @ Q\n",
    "\n",
    "print(f\"Shape of Q:\\t{Q.shape}\")\n",
    "print(f\"Shape of Qdot:\\t{Qdot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the matrix $\\mathbf{A}$ is unknown or computationally unavailable, the time derivative matrix can be estimated through finite differences of the snapshots.\n",
    "The {mod}`opinf.ddt` submodule has some convenience tools for this.\n",
    "Since our time domain is uniformly spaced, we use {func}`opinf.ddt.ddt_uniform`; for snapshots that are not uniformly spaced in time, see {func}`opinf.ddt.ddt_nonuniform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdot2 = opinf.ddt.ddt_uniform(Q, dt, order=6)\n",
    "\n",
    "# Check that the estimate is close to the true time derivatives.\n",
    "la.norm(Qdot - Qdot2, ord=np.inf) / la.norm(Qdot, ord=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress the time derivative data to the low-dimensional subspace.\n",
    "Qdot_ = Vr.T @ Qdot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The finite difference approximation for $\\dot{\\mathbf{Q}}$ commutes with the encoding in a low-dimensional subspace, that is, $\\mathbf{V}_{r}^\\top\\frac{\\text{d}}{\\text{d}t}\\left[\\mathbf{Q}\\right] = \\frac{\\text{d}}{\\text{d}t}\\left[\\mathbf{V}_{r}^{\\top}\\mathbf{Q}\\right]$.\n",
    "To save memory, the snapshot matrix may be compressed first, and the time derivatives can be calculated from the compressed snapshots.\n",
    "The ROM classes in the next section accept both full-order ($n \\times k$) or reduced-order ($r\\times k$) snapshot and time derivative matrices as training data.\n",
    "\n",
    "```python\n",
    ">>> Q_ = Vr.T @ Q                                       # Compress the state snapshots.\n",
    ">>> Qdot_ = opinf.ddt.ddt_uniform(Q_, dt, order=6)      # Estimate time derivatives of compressed states.\n",
    ">>> np.allclose(Vr.T @ Qdot2, Qdot_)                    # Same as compressing the full-order time derivatives.\n",
    "True\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Reduced-order Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have training data and a linear basis for a low-dimensional subspace.\n",
    "\n",
    "| Name | Symbol | Code Variable |\n",
    "| :--- | :----: | :------------ |\n",
    "| State snapshots | $\\mathbf{Q}$ | `Q` |\n",
    "| Time derivatives | $\\dot{\\mathbf{Q}}$ | `Qdot` |\n",
    "| POD basis | $\\mathbf{V}_{r}$ | `Vr` |\n",
    "| Initial state | $\\mathbf{q}_0$ | `q0` |\n",
    "| | |\n",
    "| Spatial domain | $\\Omega$ | `x` |\n",
    "| Time domain | $[t_0,t_f]$ | `t` |\n",
    "\n",
    "Next, we initialize a model and fit it to the data.\n",
    "Since the problem is continuous (time-dependent), we use the model class {class}`opinf.models.ContinuousModel`.\n",
    "The constructor receives a list of operators that define the structure of the right-hand side of the model.\n",
    "For the model {eq}`eq_basics_rom`, we use an {class}`opinf.operators.LinearOperator` to represent the term $\\hat{\\mathbf{A}}\\hat{\\mathbf{q}}(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom = opinf.models.ContinuousModel(operators=[opinf.operators.LinearOperator()])\n",
    "print(rom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit the model to the data by solving the least-squares problem {eq}`eq_basics_opinf`.\n",
    "Without regularization ($\\mathcal{R} \\equiv 0$), this can be written as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\min_{\\hat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\hat{\\mathbf{A}}\\mathbf{V}^{\\top}\\mathbf{q}_{j} - \\mathbf{V}^{\\top}\\dot{\\mathbf{q}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    =\n",
    "    \\min_{\\hat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\hat{\\mathbf{A}}\\hat{\\mathbf{q}}_{j} - \\dot{\\hat{\\mathbf{q}}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    = \\min_{\\hat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\left\\|\n",
    "        \\hat{\\mathbf{A}}\\hat{\\mathbf{Q}} - \\dot{\\hat{\\mathbf{Q}}}\n",
    "    \\right\\|_{F}^2,\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{\\mathbf{Q}} &= \\mathbf{V}_r^{\\top}\\mathbf{Q},\n",
    "    &\n",
    "    \\dot{\\hat{\\mathbf{Q}}} &= \\mathbf{V}_r^{\\top}\\dot{\\mathbf{Q}}.\n",
    "\\end{align*}\n",
    "\n",
    "This is all done in the {meth}`opinf.models.ContinuousModel.fit` method, given $\\hat{\\mathbf{Q}}$ and $\\dot{\\hat{\\mathbf{Q}}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom.fit(states=Q_, ddts=Qdot_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, we can directly examine the inferred operators of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom.operators[0].entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The first {class}`opinf.operators.LinearOperator` object in the list of model `operators` is accessible via the shortcut `A_`.\n",
    "\n",
    "```python\n",
    ">>> rom.operators[0] is rom.A_\n",
    "True\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is such a simple problem, OpInf recovers the exact same operator $\\hat{\\mathbf{A}}$ as intrusive projection, i.e., $\\widetilde{\\mathbf{A}} = \\mathbf{V}_r^{\\top} \\mathbf{A} \\mathbf{V}_r$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_intrusive = Vr.T @ A @ Vr\n",
    "A_intrusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(rom.A_.entries, A_intrusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(subsec-tutorial-regularization)=\n",
    "#### Regularization: Stabilizing the Inference Problem\n",
    "\n",
    "Solving {eq}`eq_basics_opinf` numerically can be challenging due to ill-conditioning in the data, errors in the estimation of the time derivatives, or overfitting.\n",
    "The inference problem therefore often requires a _regularization_ strategy to obtain a solution that respects both the training data and the physics of the problem.\n",
    "One common option, implemented by this package, is [Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization), which sets $\\mathcal{R}(\\hat{\\mathbf{A}}) = \\|\\lambda\\hat{\\mathbf{A}}\\|_{F}^{2}$ in {eq}`eq_basics_opinf` to penalize the entries of the learned operators.\n",
    "The scalar $\\lambda$ can be included as the `solver` keyword argument to {meth}`opinf.models.ContinuousModel.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom.fit(Q_, Qdot_, solver=opinf.lstsq.L2Solver(regularizer=1e-2))\n",
    "rom.A_.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(rom.A_.entries, A_intrusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "With $\\lambda = 10^{-2}$, OpInf differs from the intrusive operator $\\widetilde{\\mathbf{A}}$. However, we will see in the next section that the ROM produced by OpInf is highly accurate. In fact, it is sometimes the case that OpInf outperforms intrusive projection.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "Regularization is important in all but the simplest OpInf problems.\n",
    "If OpInf produces an unstable ROM, try different values for the `regularizer`.\n",
    "See {cite}`mcquarrie2021combustion` for an example of a principled choice of regularization for a combustion problem.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate the Learned ROM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is fit, we may simulate the ROM with the {meth}`opinf.models.ContinuousModel.predict`, which wraps [**scipy.integrate.solve_ivp()**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html).\n",
    "This method takes an initial condition for the model $\\hat{\\mathbf{q}}_0 = \\mathbf{V}_{\\!r}^{\\mathsf{T}}\\mathbf{q}_0$, the time domain over which to record the solution, and any additional arguments for the integator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_ = Vr.T @ q0                           # Compress the initial conditions.\n",
    "\n",
    "Q_ROM_ = rom.predict(q0_, t, method=\"BDF\", max_step=dt)\n",
    "Q_ROM_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is still in the low-dimensional space; it can be mapped to the original state space by applying $\\mathbf{V}_{\\!r}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ROM = Vr @ Q_ROM_\n",
    "Q_ROM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "{meth}`opinf.models.ContinuousModel.predict` is convenient, but [**scipy.integrate.solve_ivp()**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html) implements relatively few time integration schemes.\n",
    "However, the ROM can be simulated by **any** ODE solver scheme by extracting the inferred operator $\\hat{\\mathbf{A}}$. \n",
    "If `solver(A, q0)` were a solver for systems of the form $\\frac{\\text{d}}{\\text{d}t}\\hat{\\mathbf{q}} = \\hat{\\mathbf{A}}\\hat{\\mathbf{q}}(t),\\ \\hat{\\mathbf{q}}(0) = \\hat{\\mathbf{q}}_0$, we could simulate the ROM with the following code.\n",
    "\n",
    "```python\n",
    "q0_ = Vr.T @ q0                           # Compress the initial conditions.\n",
    "Q_ROM_ = solver(rom.A_.entries, q0_)      # Solve the ROM in the reduced space.\n",
    "Q_ROM = Vr @ Q_ROM_                       # Decompress the ROM solutions.\n",
    "```\n",
    "\n",
    "More generally, the method {meth}`opinf.models.ContinuousModel.rhs` represents the right-hand side of the model, the $\\hat{\\mathbf{f}}$ of $\\frac{\\text{d}}{\\text{d}t}\\hat{\\mathbf{q}}(t) = \\hat{\\mathbf{f}}(t, \\hat{\\mathbf{q}}(t))$.\n",
    "All-purpose integrators can therefore be applied to the function {meth}`opinf.models.ContinuousModel.rhs`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ROM Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the ROM does, we begin by visualizing the simulation output `Q_ROM`.\n",
    "It should look similar to the plot of the snapshot data `Q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "plot_heat_data(Q, \"Snapshot data\", ax1)\n",
    "plot_heat_data(Q_ROM, \"ROM state output\", ax2)\n",
    "ax1.legend([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detail, we evaluate the $\\ell^2$ error of the ROM output in time, comparing it to the snapshot set via {func}`opinf.post.lp_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_l2err, rel_l2err = opinf.post.lp_error(Q, Q_ROM)\n",
    "plt.semilogy(t, abs_l2err)\n",
    "plt.title(r\"Absolute $\\ell^{2}$ error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, the error decreases with time (as solutions get quickly pushed to zero), but this is not the kind of error behavior that should be expected for less trivial systems.\n",
    "\n",
    "We can also get a scalar error measurement by calculating the relative Frobenius norm error with {func}`opinf.post.frobenius_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_froerr, rel_froerr = opinf.post.frobenius_error(Q, Q_ROM)\n",
    "print(f\"Relative Frobenius-norm error: {rel_froerr:%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the ROM simulation is within 0.1% of the snapshot data.\n",
    "Note that this value is very close to the projection error that we calculated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction: New Initial Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The ROM was trained using only data corresponding to the initial condition $q_0(x) = x(1 - x).$ We'll now test the ROM on the following new initial conditions and compare the results to the corresponding FOM solution:\n",
    "\n",
    "\\begin{align*}\n",
    "    q_0(x) &= 10x (1 - x),\n",
    "    &\n",
    "    q_0(x) &= x^{2}(1 - x)^{2},\n",
    "    \\\\\n",
    "    q_0(x) &= x^{4}(1 - x)^{4},\n",
    "    &\n",
    "    q_0(x) &= \\sqrt{x(1 - x)},\n",
    "    \\\\\n",
    "    q_0(x) &= \\sqrt[4]{x(1 - x)},\n",
    "    &\n",
    "    q_0(x) &= \\sin(\\pi x) + \\tfrac{1}{5}\\sin(5\\pi x).\n",
    "\\end{align*}\n",
    "\n",
    "Before we compute the ROM error, we also compute the _projection error_ of the new initial condition,\n",
    "\n",
    "$$\n",
    "    \\frac{||\\mathbf{q}_{0} - \\mathbf{V}_r \\mathbf{V}_r^{\\top}\\mathbf{q}_{0}||_{2}}{||\\mathbf{q}_{0}||_{2}}.\n",
    "$$\n",
    "\n",
    "If this projection error is large, then the new initial condition cannot be represented well within the range of $\\mathbf{V}_{r}$. This will be apparent in the ROM solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_new_initial_condition(q0, Vr, rom, label=None):\n",
    "    \"\"\"Compare full-order model and reduced-order model solutions for a given\n",
    "    inititial condition.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q0 : (n,) ndarray\n",
    "        Heat equation initial conditions q0(x) to be tested.\n",
    "    Vr : (n, r) ndarray\n",
    "        Basis matrix.\n",
    "    rom : opinf.models.ContinuousModel\n",
    "        Trained reduced-order model object.\n",
    "    label : str\n",
    "        LaTeX description of the initial condition being tested.\n",
    "    \"\"\"\n",
    "    # Calculate the projection error of the new initial condition.\n",
    "    rel_projerr = opinf.basis.projection_error(q0, Vr)[1]\n",
    "\n",
    "    # Solve the full-order model (FOM) and the reduced-order model (ROM).\n",
    "    Q_FOM = solve_ivp(fom, [t0,tf], q0, t_eval=t, method=\"BDF\", max_step=dt).y\n",
    "    Q_ROM = Vr @ rom.predict(Vr.T @ q0, t, method=\"BDF\", max_step=dt)\n",
    "\n",
    "    # Plot the FOM and ROM solutions side by side.\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "    plot_heat_data(Q_FOM, \"Full-order model solution\", ax1)\n",
    "    plot_heat_data(Q_ROM, \"Reduced-order model solution\", ax2)\n",
    "    ax1.legend([])\n",
    "    if label:\n",
    "        fig.suptitle(label, y=1)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Calculate the ROM error in the Frobenius norm.\n",
    "    abs_froerr, rel_froerr = opinf.post.frobenius_error(Q_FOM, Q_ROM)\n",
    "\n",
    "    # Report results.\n",
    "    plt.show()\n",
    "    print(f\"Relative projection error of initial condition: {rel_projerr:.2%}\",\n",
    "          f\"Relative Frobenius-norm ROM error: {rel_froerr:.2%}\", sep='\\n')\n",
    "    return rel_projerr, rel_froerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "q0_new = [\n",
    "    10 * x * (1 - x),\n",
    "    x**2 * (1 - x)**2,\n",
    "    x**4 * (1 - x)**4,\n",
    "    np.sqrt(x * (1 - x)),\n",
    "    np.sqrt(np.sqrt(x * (1 - x))),\n",
    "    np.sin(np.pi * x) + np.sin(5 * np.pi * x) / 5,\n",
    "]\n",
    "\n",
    "q0_titles = [\n",
    "    r\"$q_{0}(x) = 10 x (1 - x)$\",\n",
    "    r\"$q_{0}(x) = x^{2} (1 - x)^{2}$\",\n",
    "    r\"$q_{0}(x) = x^{4} (1 - x)^{4}$\",\n",
    "    r\"$q_{0}(x) = \\sqrt{x (1 - x)}$\",\n",
    "    r\"$q_{0}(x) = \\sqrt[4]{x (1 - x)}$\",\n",
    "    r\"$q_{0}(x) = \\sin(\\pi x) + \\frac{1}{5}\\sin(5\\pi x)$\",\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for i, [q00, title] in enumerate(zip(q0_new, q0_titles)):\n",
    "    results[f\"Experiment {i+1:d}\"] = test_new_initial_condition(q00, Vr, rom, f\"Experiment {i+1}: {title}\")\n",
    "\n",
    "labels = [\n",
    "    \"Relative projection error of initial condition\",\n",
    "    \"Relative Frobenius-norm ROM error\"\n",
    "]\n",
    "pd.DataFrame(results, index=labels).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Attempt: a Better Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROM performs well for $q_{0}(x) = 10x(1 - x)$, which is unsurprising because this new initial condition is a scalar multiple of the initial condition used to generate the training data. In other cases, the ROM is less successful because the new initial condition cannot be represented well in the range of the basis $\\mathbf{V}_{\\!r}$. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "for j, ax in zip([4, 5], axes):\n",
    "    ax.plot(x_all, np.concatenate(([0], q0_new[j], [0])),\n",
    "            label=r\"True initial condition ($\\mathbf{q}_{0}$)\")\n",
    "    ax.plot(x_all, np.concatenate(([0], Vr @ (Vr.T @ q0_new[j]), [0])), \"--\",\n",
    "            label=r\"Basis approximation of initial condition ($\\mathbf{V}_{r}\\mathbf{V}_{r}^{\\mathsf{T}}\\mathbf{q}_{0}$)\")\n",
    "    ax.set_title(f\"Experiment {j+1:d}\")\n",
    "    \n",
    "fig.tight_layout(rect=[0, .15, 1, 1])\n",
    "axes[0].legend(loc=\"lower center\", fontsize=\"large\",\n",
    "               bbox_to_anchor=(.5, -.05), bbox_transform=fig.transFigure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the ROM performace _without getting new data from the FOM_, we will enrich the basis by\n",
    "1. Including the new initial conditions in the basis computation, and \n",
    "2. Using a few more basis vectors (we currently have $r = 2$, let's use $r = 5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new, slightly larger POD basis and include the new initial conditions.\n",
    "r = 5\n",
    "Q_and_new_q0s = np.column_stack((Q, *q0_new))\n",
    "Vr_new, svdvals_new = opinf.basis.pod_basis(Q_and_new_q0s, r, mode=\"dense\")\n",
    "\n",
    "# Plot the singular value decay and the first few basis vectors.\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "opinf.basis.svdval_decay(svdvals_new, 1e-4, plot=True, ax=ax1)\n",
    "ax1.set_xlim(right=40)\n",
    "for j in range(Vr_new.shape[1]):\n",
    "    ax2.plot(x, Vr_new[:,j], label=f\"POD mode {j+1}\")\n",
    "ax2.legend(ncol=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the training data and solve the corresponding inference problem\n",
    "# (but only using snapshot data from one initial condition).\n",
    "rom.fit(Vr_new.T @ Q, Vr_new.T @ Qdot)\n",
    "\n",
    "# Repeat the experiments.\n",
    "results_new = {}\n",
    "for i, [q00, title] in enumerate(zip(q0_new, q0_titles)):\n",
    "    results_new[f\"Experiment {i+1:d}\"] = test_new_initial_condition(q00, Vr_new, rom, f\"Experiment {i+1}: {title}\")\n",
    "\n",
    "# Display results summary.\n",
    "pd.DataFrame(results_new, index=labels).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a more expressive basis, we are now capturing the true solutions with the ROM to within 1% error in the Frobenius norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Takeaway\n",
    ":class: attention\n",
    "This example illustrates an fundamental principle of model reduction: the accuracy of the ROM is limited by the accuracy of the underlying low-dimensional approximation, which in this case is $\\mathbf{q}(t) \\approx \\mathbf{V}_{r}\\hat{\\mathbf{q}}(t)$. In other words, a good $\\mathbf{V}_{r}$ is critical in order for the ROM to be accurate and predictive.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
