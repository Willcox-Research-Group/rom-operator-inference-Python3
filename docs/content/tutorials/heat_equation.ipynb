{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Heat Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "The fundamental goal of model reduction is to efficiently make physics-based predictions. Given synthetic or experimental data that was generated or collected under a certain set of conditions, we aim to construct a cost-effective model that produces accurate solutions under new sets of conditions. This tutorial explores the following prediction problems for the heat equation example of {cite}`PW2016OperatorInference`:\n",
    "1. Predicting **forward in time**.\n",
    "2. Using new time-dependent **boundary conditions**.\n",
    "3. Changing the **system parameters** (e.g., coefficients in the governing equation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-nb-collapsed": true
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Governing Equations\n",
    ":class: attention\n",
    "\n",
    "Let $\\Omega = [0,L]\\subset \\mathbb{R}$ be the spatial domain indicated by the variable $x$, and let $[0,T]\\subset\\mathbb{R}$ be the time domain with variable $t$. We consider the one-dimensional heat equation with non-homogeneous Dirichlet boundary conditions,\n",
    "\n",
    "\\begin{align*}\n",
    "    &\\frac{\\partial}{\\partial t} q(x,t;\\mu) = \\mu\\frac{\\partial^2}{\\partial x^2}q(x,t;\\mu)\n",
    "    & x &\\in\\Omega,\\quad t\\in[0,T],\n",
    "    \\\\\n",
    "    &q(0,t;\\mu) = q(L,t;\\mu) = u(t)\n",
    "    & t &\\in[0,T],\n",
    "    \\\\\n",
    "    &q(x,0;\\mu) = \\big(e^{\\alpha(x - 1)} + e^{-\\alpha x} - e^{-\\alpha}\\big)u(0)\n",
    "    & x &\\in \\Omega,\n",
    "\\end{align*}\n",
    "\n",
    "where the constant $\\mu > 0$ is the thermal diffusivity and where $q(x,t;\\mu)$ is the unknown state variable. This is a model for a one-dimensional rod conducting heat with a fixed initial heat profile. The temperature at the ends of the rod are governed by the input function $u(t)$, but  heat is allowed to diffuse through the rod and flow out at the ends of the domain. We aim to numerically solve for $q(x,t;\\mu)$ efficiently for all $t \\in [0,T]$ and/or for various choices of $u(t)$ and $\\mu$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "This problem can be solved with a straightforward discretization of the spatial domain $\\Omega$ without little computational effort, so using model reduction to speed up the computation is not highly beneficial. However, the way that the user interacts with the package for this problem is highly similar for more complex problems.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction in Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first objective is to get solutions in time beyond a set of available training data.\n",
    "\n",
    ":::{image} ../../images/summary.svg\n",
    ":align: center\n",
    ":width: 80 %\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Objective\n",
    ":class: attention\n",
    "\n",
    "Construct a reduced-order model (ROM) of the heat equation that is **predictive in time**. In other words, we will observe data for $t \\in [0, T']$ with $T' < T$, use that data to construct the ROM, and use the ROM to predict the solution for the entire time domain $[0,T]$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-order Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the last tutorial, we use a centered finite difference approximation for the spatial derivative to arrive at a first-order system, this time of the form\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t;\\mu)\n",
    "    = \\mathbf{A}(\\mu)\\mathbf{q}(t;\\mu) + \\mathbf{B}(\\mu)u(t),\n",
    "    \\qquad\n",
    "    \\mathbf{q}(0;\\mu)\n",
    "    = \\mathbf{q}_0.\n",
    "$$ (eq_heat_fom_parametric)\n",
    "\n",
    ":::{dropdown} Discretization details\n",
    "\n",
    "We take an equidistant grid $\\{x_i\\}_{i=0}^{n+1} \\subset \\Omega$,\n",
    "\n",
    "\\begin{align*}\n",
    "    0 &= x_0 < x_1 < \\cdots < x_n < x_{n+1} = L\n",
    "    &\n",
    "    &\\text{and}\n",
    "    &\n",
    "    \\delta x &= \\frac{L}{n+1} = x_{i+1} - x_{i},\\quad i=1,\\ldots,n-1.\n",
    "\\end{align*}\n",
    "\n",
    "The boundary conditions prescribe $q(x_0,t) = q(x_{n+1},t) = u(t)$. Our goal is to compute $q(x,t)$ at the interior spatial points $x_{1},x_{2},\\ldots,x_{n}$ for various $t\\in[0,T]$, so we consider the state vector $\\mathbf{q}(t) = [~q(x_{1}, t)~\\cdots~q(x_{n}, t)~]^{\\top}\\in\\mathbb{R}^n$ and derive a system governing the evolution of $\\mathbf{q}(t)$ in time.\n",
    "\n",
    "Approximating the spatial derivative with a central finite difference approximation,\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial^2}{\\partial x^2}q(x,t)\n",
    "    \\approx \\frac{q(x-\\delta x,t) - 2q(x,t) + q(x+\\delta x,t)}{(\\delta x)^2},\n",
    "$$\n",
    "\n",
    "we arrive at the following matrices for the full-order model.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{A}(\\mu) &= \\frac{\\mu}{(\\delta x)^2}\\left[\\begin{array}{ccccc}\n",
    "        -2 & 1 & & & \\\\\n",
    "        1 & -2 & 1 & & \\\\\n",
    "        & \\ddots & \\ddots & \\ddots & \\\\\n",
    "        & & 1 & -2 & 1 \\\\\n",
    "        & & & 1 & -2 \\\\\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n\\times n},\n",
    "    &\n",
    "    \\mathbf{B}(\\mu) &= \\frac{\\mu}{(\\delta x)^2}\\left[\\begin{array}{c}\n",
    "        1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 1\n",
    "    \\end{array}\\right]\\in\\mathbb{R}^{n}.\n",
    "\\end{align*}\n",
    ":::\n",
    "\n",
    "The state $\\mathbf{q}(t;\\mu)$ implicity depends on the parameter $\\mu$ because the operators $\\mathbf{A}(\\mu)$ and $\\mathbf{B}(\\mu)$ are parameterized by $\\mu$.\n",
    "For now, we set $\\mu = 1$ and simply write\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)\n",
    "    = \\mathbf{A}\\mathbf{q}(t) + \\mathbf{B}u(t),\n",
    "    \\qquad\n",
    "    \\mathbf{q}(0)\n",
    "    = \\mathbf{q}_0.\n",
    "$$\n",
    "\n",
    "This is the _full-order model_ (FOM), which we will use to generate training data for the time domain $[0, T'] \\subset [0, T]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $L = T = \\mu = 1$, $\\alpha = 100$, and suppose for now that the boundary conditions are given by the constant input function $u(t) \\equiv 1$.\n",
    "We begin by simulating the full-order system described above with a uniform time step $\\delta t = 10^{-3}$, yielding $10^3 + 1 = 1001$ total time steps (1000 steps past the initial condition).\n",
    "We will assume that we can only observe the first $k = 100$ time steps and use the ROM to predict the remaining $901$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rom_operator_inference as opinf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Matplotlib customizations.\n",
    "plt.rc(\"axes.spines\", right=False, top=False)\n",
    "plt.rc(\"figure\", dpi=300, figsize=(9, 3))\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"legend\", edgecolor=\"none\", frameon=True)\n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "# Pandas display options.\n",
    "pd.options.display.float_format = \"{:.4%}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the spatial domain.\n",
    "L = 1                           # Spatial domain length.\n",
    "n = 2**7 - 1                    # Spatial grid size.\n",
    "x_all = np.linspace(0, L, n+2)  # Full spatial grid.\n",
    "x = x_all[1:-1]                 # Interior spatial grid (where q is unknown).\n",
    "dx = x[1] - x[0]                # Spatial resolution.\n",
    "\n",
    "# Construct the temporal domain.\n",
    "T = 1                           # Temporal domain length (final simulation time).\n",
    "K = T*10**3 + 1                 # Temporal grid size.\n",
    "t = np.linspace(0, T, K)        # Temporal grid.\n",
    "dt = t[1] - t[0]                # Temporal resolution.\n",
    "\n",
    "print(f\"Spatial step size δx = {dx}\")\n",
    "print(f\"Temporal step size δt = {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Construct the full-order state matrix A.\n",
    "dx2inv = 1 / dx**2\n",
    "diags = np.array([1, -2, 1]) * dx2inv\n",
    "A = sparse.diags(diags, [-1, 0, 1], (n, n))\n",
    "\n",
    "# Construct the full-order input matrix B.\n",
    "B = np.zeros_like(x)\n",
    "B[0], B[-1] = dx2inv, dx2inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs.\n",
    "input_func = np.ones_like       # Constant input function u(t) = 1.\n",
    "U_all = input_func(t)           # Inputs over the time domain.\n",
    "\n",
    "# Construct the initial condition.\n",
    "alpha = 100\n",
    "q0 = np.exp(alpha*(x-1)) + np.exp(-alpha*x) - np.exp(-alpha)\n",
    "\n",
    "print(f\"shape of A:\\t{A.shape}\")\n",
    "print(f\"shape of B:\\t{B.shape}\")\n",
    "print(f\"shape of q0:\\t{q0.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a diffusive problem, we will use the implicit (backward) Euler method for solving the ODEs.\n",
    "For the problem $\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t) = \\mathbf{F}(t, \\mathbf{q}(t), \\mathbf{u}(t))$, implicit Euler is defined by the rule\n",
    "\n",
    "$$\n",
    "    \\mathbf{q}_{j+1} = \\mathbf{q}_{j} + \\delta t \\mathbf{F}(t_{j+1},\\mathbf{q}_{j+1},u_{j+1}),\n",
    "$$\n",
    "\n",
    "where $\\mathbf{q}_{j} := \\mathbf{q}(t_{j})$ and $u_{j} := u(t_{j})$.\n",
    "With the form $\\mathbf{F}(t,\\mathbf{q}(t),u(t)) = \\mathbf{A}\\mathbf{q}(t) + \\mathbf{B}u(t)$, this becomes\n",
    "\n",
    "$$\n",
    "    \\mathbf{q}_{j+1} = (\\mathbf{I} - \\delta t \\mathbf{A})^{-1}\\left(\\mathbf{q}_{j} + \\delta t \\mathbf{B} u_{j+1}\\right),\n",
    "$$\n",
    "\n",
    "where $\\mathbf{I}$ is the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def implicit_euler(t, q0, A, B, U):\n",
    "    \"\"\"Solve the system\n",
    "\n",
    "        dq / dt = Aq(t) + Bu(t),    q(0) = q0,\n",
    "\n",
    "    over a uniform time domain via the implicit Euler method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : (k,) ndarray\n",
    "        Uniform time array over which to solve the ODE.\n",
    "    q0 : (n,) ndarray\n",
    "        Initial condition.\n",
    "    A : (n, n) ndarray\n",
    "        State matrix.\n",
    "    B : (n,) or (n, 1) ndarray\n",
    "        Input matrix.\n",
    "    U : (k,) ndarray\n",
    "        Inputs over the time array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    q : (n, k) ndarray\n",
    "        Solution to the ODE at time t; that is, q[:,j] is the\n",
    "        computed solution corresponding to time t[j].\n",
    "    \"\"\"\n",
    "    # Check and store dimensions.\n",
    "    k = len(t)\n",
    "    n = len(q0)\n",
    "    B = np.ravel(B)\n",
    "    assert A.shape == (n, n)\n",
    "    assert B.shape == (n,)\n",
    "    assert U.shape == (k,)\n",
    "    I = np.eye(n)\n",
    "\n",
    "    # Check that the time step is uniform.\n",
    "    dt = t[1] - t[0]\n",
    "    assert np.allclose(np.diff(t), dt)\n",
    "\n",
    "    # Factor I - dt*A for quick solving at each time step.\n",
    "    factored = la.lu_factor(I - dt*A)\n",
    "\n",
    "    # Solve the problem at each time step.\n",
    "    q = np.empty((n, k))\n",
    "    q[:,0] = q0.copy()\n",
    "    for j in range(1, k):\n",
    "        q[:, j] = la.lu_solve(factored, q[:, j-1] + dt*B*U[j])\n",
    "\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute snapshots by solving the equation with implicit_euler().\n",
    "Q_all = implicit_euler(t, q0, A, B, U_all)\n",
    "\n",
    "# Retain only the first k snapshots/inputs for training the ROM.\n",
    "k = 100                         # Number of training snapshots.\n",
    "t_train = t[:k]                 # Temporal domain for training snapshots.\n",
    "Q = Q_all[:, :k]                # Training snapshots.\n",
    "U = U_all[:k]                   # Inputs corresponding to the training snapshots.\n",
    "\n",
    "# Also compute time derivatives (dq/dt) at each training snapshot.\n",
    "Qdot = A @ Q + B.reshape((-1,1))*U\n",
    "\n",
    "print(f\"shape of Q:\\t{Q.shape}\")\n",
    "print(f\"shape of Qdot:\\t{Qdot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the snapshots to get a sense of how the solution looks qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_heat_data(Z, title, ax=None):\n",
    "    \"\"\"Visualize temperature data in space and time.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Plot a few snapshots over the spatial domain.\n",
    "    sample_columns = [0, 10, 20, 40, 80, 160, 320, 640]\n",
    "    sample_columns = [0] + [2**d for d in range(10)]\n",
    "    color = iter(plt.cm.viridis_r(np.linspace(.05, 1, len(sample_columns))))\n",
    "    while sample_columns[-1] > Z.shape[1]:\n",
    "        sample_columns.pop()\n",
    "    leftBC, rightBC = [input_func(x_all[0])], [input_func(x_all[-1])]\n",
    "    for j in sample_columns:\n",
    "        q_all = np.concatenate([leftBC, Z[:,j], rightBC])\n",
    "        ax.plot(x_all, q_all, color=next(color), label=fr\"$q(x,t_{{{j}}})$\")\n",
    "\n",
    "    ax.set_xlim(x_all[0], x_all[-1])\n",
    "    ax.set_xlabel(r\"$x$\")\n",
    "    ax.set_ylabel(r\"$q(x,t)$\")\n",
    "    ax.legend(loc=(1.05, .05))\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "plot_heat_data(Q, \"Snapshot data for training\", ax1)\n",
    "plot_heat_data(Q_all, \"Full-order model solution\", ax2)\n",
    "ax1.legend([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROM Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have snapshot data $\\mathbf{Q} \\in \\mathbb{R}^{n \\times k}$, we can construct [a basis](sec-basis-computation) $\\mathbf{V}_r \\in \\mathbb{R}^{n \\times r}$ to use in the construction of the ROM. For operator inference (OpInf), we often use the [proper orthogonal decomposition](subsec-pod) (POD) basis. The integer $r$, which defines the dimension of the reduced-order model to be constructed, is usually determined by how quickly the singular values of $\\mathbf{Q}$ decay. In this example, we choose the minimal $r$ such that the [residual energy](subsec-basis-size) is less than a given tolerance $\\varepsilon$, i.e.,\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{j=r + 1}^{k}\\sigma_{j}^{2}}{\\sum_{j=1}^{k}\\sigma_{j}^{2}} = \\frac{||\\mathbf{Q} - \\mathbf{V}_r \\mathbf{V}_r^{\\top}\\mathbf{Q}||_{F}^{2}}{||\\mathbf{Q}||_{F}^{2}} < \\varepsilon.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the largest possible basis and all singular values.\n",
    "V, svdvals = opinf.pre.pod_basis(Q)\n",
    "\n",
    "# Check the decay of the residual energy based on the singular values.\n",
    "r = opinf.pre.residual_energy(svdvals, tol=1e-10, plot=True)\n",
    "plt.xlim(0, 25)\n",
    "\n",
    "Vr = V[:, :r]\n",
    "print(f\"r = {r:d} singular values required so residual energy < 1e-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{margin}\n",
    ":::{note}\n",
    "In this case, since $u(t) \\equiv 1$ is constant, we could equivalently set `modelform=\"cA\"` to learn a ROM of the form $\\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{q}}(t) = \\widehat{\\mathbf{c}} + \\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}(t)$, where $\\widehat{\\mathbf{c}}$ is a constant term.\n",
    "There is no difference between the two models, i.e., $\\widehat{\\mathbf{c}} = \\widehat{\\mathbf{B}}u(t) = \\widehat{\\mathbf{B}}$, except that `modelform=\"AB\"` allows us to use different inputs for $u(t)$ later on.\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can learn the reduced model with OpInf.\n",
    "Because the full-order model is of the form $\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t) = \\mathbf{A}\\mathbf{q}(t) + \\mathbf{B}u(t)$, we set the form of the ROM to $\\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{q}}(t) = \\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}(t) + \\widehat{\\mathbf{B}}u(t)$ by specifying `modelform=\"AB\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "rom = opinf.ContinuousOpInfROM(modelform=\"AB\")\n",
    "rom.fit(basis=Vr, states=Q, ddts=Qdot, inputs=U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROM Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the FOM, we integrate the learned ROM using the implicit Euler method, using the reduced-order operators $\\widehat{\\mathbf{A}}$ and $\\widehat{\\mathbf{B}}$ and the projected initial condition $\\widehat{\\mathbf{q}}_{0} = \\mathbf{V}^{\\mathsf{T}}\\mathbf{q}_{0}$.\n",
    "The resulting low-dimensional state vectors are translated back to the full-dimensional space via $\\mathbf{q}(t) = \\mathbf{V}_{r}\\widehat{\\mathbf{q}}(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_ = Vr.T @ q0                                     # Project the initial condition.\n",
    "Q_ROM = Vr @ implicit_euler(t, q0_, rom.A_.entries, rom.B_.entries, U_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "plot_heat_data(Q_ROM, \"Reduced-order model solution\", ax1)\n",
    "plot_heat_data(Q_all, \"Full-order model solution\", ax2)\n",
    "ax1.legend([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify the accuracy of the ROM, we evaluate the ROM solution error in the Frobenius norm and compare it to the projection error,\n",
    "\n",
    "$$\n",
    "    \\text{err}_{\\text{ROM}}\n",
    "    = \\frac{||\\mathbf{Q}_{\\text{all}} - \\mathbf{Q}_{\\text{ROM}}||_F}{||\\mathbf{Q}_{\\text{all}}||_F},\n",
    "    \\qquad\n",
    "    \\text{err}_{\\text{proj}}\n",
    "    = \\frac{||\\mathbf{Q}_{\\text{all}} - \\mathbf{V}_{r}\\mathbf{V}_{r}^{\\top}\\mathbf{Q}_{\\text{all}}||_F}{||\\mathbf{Q}_{\\text{all}}||_F},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{Q}_{\\text{all}}$ is the full-order model solution over the entire time domain and $\\mathbf{Q}_{\\text{ROM}}$ is the reduced-order model solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_froerr_projection = opinf.post.projection_error(Q_all, rom.basis)[1]\n",
    "rel_froerr_opinf = opinf.post.frobenius_error(Q_all, Q_ROM)[1]\n",
    "\n",
    "print(\"Relative Frobenius-norm errors\", '-'*33,\n",
    "      f\"projection error:\\t{rel_froerr_projection:%}\",\n",
    "      f\"OpInf ROM error:\\t{rel_froerr_opinf:%}\",\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROM error cannot be better than the projection error, but it is pretty close to it. We also compare the ROM error with the projection error as a function of time, i.e.,\n",
    "\n",
    "$$\n",
    "    \\text{err}_{\\text{ROM}}(t)\n",
    "    = \\frac{\\|\\mathbf{q}(t) - \\mathbf{q}_{\\text{ROM}}(t)\\|_{2}}{\\|\\mathbf{q}(t)\\|_{2}},\n",
    "    \\qquad\n",
    "    \\text{err}_{\\text{proj}}(t)\n",
    "    = \\frac{\\|\\mathbf{q}(t) - \\mathbf{V}_{r}\\mathbf{V}_{r}^{\\mathsf{T}}\\mathbf{q}(t)\\|_{2}}{\\|\\mathbf{q}(t)\\|_{2}},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{q}(t)$ is the full-order solution and $\\mathbf{q}_{\\text{ROM}}(t)$ is the ROM solution at time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "In this problem, $\\mathbf{q}(t) \\to \\mathbf{0}$ as $t$ increases, so a relative error may not be appropriate since $\\|\\mathbf{q}(t)\\|_{2}$ appears in the denominator.\n",
    "In situations like this, consider using the _normalized absolute error_ by replacing the denominator with $\\max_{\\tau\\in[0,T]}\\|\\mathbf{q}(t)\\|$, for example:\n",
    "$$\n",
    "    \\text{err}_{\\text{ROM}}(t)\n",
    "    = \\frac{\\|\\mathbf{q}(t) - \\mathbf{q}_{\\text{ROM}}(t)\\|_{2}}{\\max_{\\tau\\in[0,T]}\\|\\mathbf{q}(\\tau)\\|_{2}}.\n",
    "$$\n",
    "\n",
    "Use `normalize=True` in `opinf.post.lp_error()` to use this error measure instead of the relative error.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projerr_in_time = opinf.post.lp_error(Q_all,\n",
    "                                      Vr @ (Vr.T @ Q_all),\n",
    "                                      normalize=True)[1]\n",
    "\n",
    "def plot_errors_over_time(Zlist, labels):\n",
    "    \"\"\"Plot normalized absolute projection error and ROM errors\n",
    "    as a function of time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Zlist : list((n, k) ndarrays)\n",
    "        List of reduced-order model solutions.\n",
    "    labels : list(str)\n",
    "        Labels for each of the reduced-order models.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    \n",
    "    ax.semilogy(t, projerr_in_time, \"C3\", label=\"Projection Error\")\n",
    "    colors = [\"C0\", \"C5\"]\n",
    "    for Z, label, c in zip(Zlist, labels, colors[:len(Zlist)]):\n",
    "        rel_err = opinf.post.lp_error(Q_all, Z, normalize=True)[1]\n",
    "        plt.semilogy(t, rel_err, c, label=label)\n",
    "\n",
    "    ax.set_xlabel(r\"$t$\")\n",
    "    ax.set_ylabel(\"Normalized absolute error\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors_over_time([Q_ROM], [\"ROM Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Intrusive Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under some idealized assumptions, as the amount of training data $k$ and the dimension $r$ increases, the reduced operators $\\widehat{\\mathbf{A}}$ and $\\widehat{\\mathbf{B}}$ learned through OpInf converge to the corresponding operators obtained through _intrusive projection_,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\widetilde{\\mathbf{A}} &= \\mathbf{V}_{r}^{\\mathsf{T}} \\mathbf{A} \\mathbf{V}_{r},\n",
    "    &\n",
    "    \\widetilde{\\mathbf{B}} &= \\mathbf{V}_{r}^{\\mathsf{T}}\\mathbf{B}.\n",
    "\\end{align*}\n",
    "\n",
    "The operation is called \"intrusive\" because it requires explicit access to the full-order operators $\\mathbf{A}$ and $\\mathbf{B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atilde = Vr.T @ A @ Vr\n",
    "Btilde = Vr.T @ B\n",
    "Q_ROM_intrusive = Vr @ implicit_euler(t, q0_, Atilde, Btilde, U_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The OpInf ROM classes, such as `ContinuousOpInfROM`, learn reduced-order model operators intrusively whenever the full-order operators are provided through the `known_operators` argument of `fit()`.\n",
    "This argument should be a dictionary mapping the modelform key to the full-order operator.\n",
    "If every full-order operator is provided, then the `states` and `ddts` arguments of `fit()` may be set to `None`, since there is no data-driven learning in this case.\n",
    "\n",
    "```python\n",
    ">>> rom_intrusive = opinf.ContinuousOpInfROM(\"AB\")\n",
    ">>> rom_intrusive.fit(Vr, None, None, known_operators={\"A\": A, \"B\": B})\n",
    ">>> np.all(rom_intrusive.A_.entries == Atilde)\n",
    "False\n",
    ">>> np.all(rom_intrusive.B_.entries == Btilde)\n",
    "True\n",
    "\n",
    ">>> Q_ROM_intrusive = Vr @ implicit_euler(t, q0_, rom_intrusive.A_.entries, rom_intrusive.B_.entries, U_all)\n",
    "```\n",
    "\n",
    "If, for example, only the full-order operator $\\mathbf{B}$ were known (but not $\\mathbf{A}$), we can learn $\\widehat{\\mathbf{A}}$ through OpInf and $\\widehat{\\mathbf{B}}$ through intrusive projection:\n",
    "\n",
    "```python\n",
    ">>> rom_partially_intrusive = opinf.ContinuousOpInfROM(\"AB\")\n",
    ">>> rom_partially_intrusive.fit(Vr, Q, Qdot, known_operators={\"B\": B})\n",
    ">>> np.all(rom_partially_intrusive.A_.entries == Atilde)\n",
    "False\n",
    ">>> np.all(rom_partially_intrusive.B_.entries == Btilde)\n",
    "True\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "plot_heat_data(Q_ROM, \"OpInf ROM solution\", ax1)\n",
    "plot_heat_data(Q_ROM_intrusive, \"Intrusive ROM solution\", ax2)\n",
    "ax1.legend([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_froerr_intrusive = opinf.post.frobenius_error(Q_all, Q_ROM_intrusive)[1]\n",
    "\n",
    "print(\"Relative Frobenius-norm errors\", '-'*33,\n",
    "      f\"projection error:\\t{rel_froerr_projection:%}\",\n",
    "      f\"OpInf ROM error:\\t{rel_froerr_opinf:%}\",\n",
    "      f\"intrusive ROM error:\\t{rel_froerr_intrusive:%}\",\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors_over_time([Q_ROM, Q_ROM_intrusive],\n",
    "                      [\"OpInf ROM Error\", \"Intrusive ROM Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the experiment with different choices of $r$ to see how the size of the ROM affects its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, _ = opinf.pre.pod_basis(Q)\n",
    "\n",
    "def run_trial(r):\n",
    "    \"\"\"Do OpInf / intrusive ROM prediction with r basis vectors.\"\"\"\n",
    "    Vr = V[:,:r]\n",
    "    q0_ = Vr.T @ q0\n",
    "\n",
    "    # Construct and simulate the intrusive ROM.\n",
    "    rom_intrusive = opinf.ContinuousOpInfROM(\"AB\").fit(Vr, None, None,\n",
    "                                                       known_operators={\"A\":A, \"B\":B})\n",
    "    Q_ROM_intrusive = Vr @ implicit_euler(t, q0_,\n",
    "                                          rom_intrusive.A_.entries,\n",
    "                                          rom_intrusive.B_.entries, U_all)\n",
    "\n",
    "    # Construct and simulate the inferred ROM.\n",
    "    rom_opinf = opinf.ContinuousOpInfROM(\"AB\").fit(Vr, Q, Qdot, U)\n",
    "    Q_ROM_opinf = Vr @ implicit_euler(t, q0_,\n",
    "                                      rom_opinf.A_.entries,\n",
    "                                      rom_opinf.B_.entries, U_all)\n",
    "\n",
    "    # Calculate errors.\n",
    "    projection_error = opinf.pre.projection_error(Q_all, Vr)[1]\n",
    "    intrusive_error = opinf.post.frobenius_error(Q_all, Q_ROM_intrusive)[1]\n",
    "    opinf_error = opinf.post.frobenius_error(Q_all, Q_ROM_opinf)[1]\n",
    "\n",
    "    return projection_error, intrusive_error, opinf_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_state_error(rmax, runner, ylabel):\n",
    "    \"\"\"Run the experiment for r = 1, ..., rmax and plot results.\"\"\"\n",
    "    rs = np.arange(1, rmax+1)\n",
    "    err_projection, err_intrusive, err_opinf = zip(*[runner(r) for r in rs])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.semilogy(rs, err_projection, 'C3-',\n",
    "                label=\"projection error\", lw=1)\n",
    "    ax.semilogy(rs, err_opinf, 'C0o-',\n",
    "                label=\"OpInf ROM error\", lw=1, mfc=\"none\", mec=\"C0\", mew=1.5)\n",
    "    ax.semilogy(rs, err_intrusive, 'C5+-',\n",
    "                label=\"intrusive ROM error\", lw=1, mew=2)\n",
    "\n",
    "    ax.set_xlim(rs.min(), rs.max())\n",
    "    ax.set_xticks(rs, [str(int(r)) for r in rs])\n",
    "    ax.set_xlabel(r\"Reduced dimension $r$\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend(loc=\"upper right\", fontsize=14, framealpha=1)\n",
    "    ax.grid(ls=':')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state_error(20, run_trial, \"Relative Frobenius-norm error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Takeaway\n",
    ":class: attention\n",
    "In this case, the inferred and projected ROMs give essentially the same result.\n",
    "However, the inferred ROM successfully emulates the FOM **without explicit knowledge of the operators** $\\mathbf{A}$ **and** $\\mathbf{B}$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New BC functions to try:\n",
    "\n",
    "\\begin{align*}\n",
    "    u(t) &= 1 - \\frac{1}{2}\\sin(\\pi t)\n",
    "    &\n",
    "    u(t) &= 1 - \\frac{1}{2}\\sin(3\\pi t)\n",
    "    \\\\\n",
    "    u(t) &= 1 - \\frac{1}{2}\\sin(7 \\pi t)\n",
    "    &\n",
    "    u(t) &= 1 + \\frac{1}{2}t(t - 1)\n",
    "    \\\\\n",
    "    u(t) &= 1 + 25 (t (t - 1))^{3}\n",
    "    &\n",
    "    u(t) &= 1 + 500 (t (t - 1))^{5}\n",
    "    \\\\\n",
    "    u(t) &= 1 + 1000 (t (t - 1))^{7}\n",
    "    &\n",
    "    u(t) &= 1 + 10000 (t (t - 1))^{9}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction in Parameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the governing equation,\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial}{\\partial t} q(x,t;{\\color{teal}\\mu})\n",
    "    = {\\color{teal}\\mu}\\frac{\\partial^2}{\\partial x^2}q(x,t;{\\color{teal}\\mu}).\n",
    "$$\n",
    "\n",
    "In this section we examine the role of the constant $\\mu > 0$, the heat diffusivity parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Objective\n",
    ":class: attention\n",
    "\n",
    "Construct a ROM of the heat equation that can be solved for different choices of the diffusivity parameter $\\mu > 0$.\n",
    "We will observe data for a few values of $\\mu$ and use the ROM to predict the solution for new values of $\\mu$. As before, we also aim to be predictive in time.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-order Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solved this problem earlier for fixed $\\mu = 1$.\n",
    "For variable $\\mu$, {eq}`eq_heat_fom_parametric` defines the full-order model:\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t;\\mu)\n",
    "    = \\mathbf{A}(\\mu)\\mathbf{q}(t;\\mu) + \\mathbf{B}(\\mu)u(t),\n",
    "    \\qquad\n",
    "    \\mathbf{q}(0;\\mu)\n",
    "    = \\mathbf{q}_0.\n",
    "$$\n",
    "\n",
    "Note that $\\mathbf{A}(\\mu) = \\mu \\mathbf{A}(1)$ and $\\mathbf{B}(\\mu) = \\mu \\mathbf{B}(1)$, and that $\\mathbf{A}(1)$ and $\\mathbf{B}(1)$ are the full-order operators we constructed previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the parameter domain $\\mathcal{D} = [.1, 10] \\subset \\mathbb{R}$.\n",
    "Taking $s$ logarithmically spaced samples $\\{\\mu_i\\}_{i=1}^{s}\\subset\\mathcal{D}$, we solve the full-order model over $[0, T']$ for each parameter sample.\n",
    "For each parameter $\\mu_{i}$, the resulting snapshots matrix is denoted as $\\mathbf{Q}(\\mu_{i})\\in \\mathbb{R}^{n \\times k}$.\n",
    "We choose $s = 10$ training parameters in the following experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 10                          # Number of parameter samples.\n",
    "params = np.logspace(-1, 1, s)  # Get s logarithmically spaced values of µ from D = [.1, 10].\n",
    "\n",
    "# Retain only the first k snapshots/inputs for training the ROM.\n",
    "k = 500                         # Number of training snapshots.\n",
    "t_train = t[:k]                 # Temporal domain for training snapshots.\n",
    "U = U_all[:k]                   # Inputs corresponding to the training snapshots.\n",
    "\n",
    "# Solve the full-order model at each of the parameter samples.\n",
    "Qs, Qdots, Us = [], [], []\n",
    "for µ in params:\n",
    "    Aµ, Bµ = µ * A, µ * B\n",
    "    Qµ = implicit_euler(t_train, q0, Aµ, Bµ, U)  # implicit_euler(t_train, q0, Aµ, Bµ, U_all)\n",
    "    Qdotµ = Aµ @ Qµ + Bµ.reshape((-1,1)) * U  # U_all\n",
    "    Qs.append(Qµ)\n",
    "    Qdots.append(Qdotµ)\n",
    "    Us.append(U)  # U_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROM Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A (global) POD basis can be constructed from the concatenation of the individual snapshot matrices,\n",
    "\n",
    "$$\n",
    "    \\mathbf{Q}\n",
    "    = \\left[~\\mathbf{Q}(\\mu_1)~\\cdots~\\mathbf{Q}(\\mu_s)~\\right]\n",
    "    \\in\\mathbb{R}^{n \\times sk}.\n",
    "$$\n",
    "\n",
    "We can select the reduced dimension $r$ as before by examining the residual energy of the singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, svdvals = opinf.pre.pod_basis(np.hstack(Qs))\n",
    "opinf.pre.residual_energy(svdvals, tol=1e-10, plot=True)\n",
    "plt.xlim(right=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could choose $r$ so that the average relative projection error,\n",
    "\n",
    "$$\n",
    "    \\text{avgerr}_\\text{proj} = \\frac{1}{s}\\sum_{i=1}^{s}\\frac{||\\mathbf{Q}(\\mu_i) - \\mathbf{V}_r \\mathbf{V}_r^{\\top}\\mathbf{Q}(\\mu_i)||_F}{||\\mathbf{Q}(\\mu_i)||_F},\n",
    "$$\n",
    "\n",
    "is below a certain threshold, say $10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_relative_projection_error(r):\n",
    "    \"\"\"Compute the average relative projection error with r basis vectors.\"\"\"\n",
    "    Vr = V[:, :r]\n",
    "    return np.mean([opinf.pre.projection_error(Q, Vr)[1] for Q in Qs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "rs = np.arange(1, 21)\n",
    "ax.axhline(1e-5, color=\"gray\", lw=1)\n",
    "ax.axvline(11, color=\"gray\", lw=1)\n",
    "ax.semilogy(rs, [average_relative_projection_error(r) for r in rs],\n",
    "            \"C3.-\", ms=10)\n",
    "ax.set_xticks(rs[::2])\n",
    "ax.set_xlabel(r\"$r$\")\n",
    "ax.set_ylabel(\"Average relative\\nprojection error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these criteria, we choose $r = 11$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 9\n",
    "Vr = V[:, :r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolatory Operator Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several strategies to account for the parameter $\\mu$. The reduced-order operators obtained through projection are given by\n",
    "\n",
    "$$\n",
    "    \\widetilde{\\mathbf{A}}(\\mu)\n",
    "    = \\mathbf{V}_{r}^{\\mathsf{T}} \\mathbf{A}(\\mu) \\mathbf{V}_{r},\n",
    "    \\qquad\n",
    "    \\widetilde{\\mathbf{B}}(\\mu)\n",
    "    = \\mathbf{V}_{r}^{\\mathsf{T}} \\mathbf{B}(\\mu).\n",
    "$$\n",
    "\n",
    "Here, we perform interpolation on the entries of the reduced-order operators learned for each parameter sample. This means we learn a separate ROM for each $\\mu_i$, $i=1, \\ldots, s$, obtaining reduced-order operators $\\widehat{\\mathbf{A}}(\\mu_{i})$ and $\\widehat{\\mathbf{B}}(\\mu_{i})$.\n",
    "Then, for a new parameter value $\\bar{\\mu}\\in\\mathcal{D}$, we interpolate the entries of the learned reduced model operators to create a new reduced model corresponding to $\\bar{\\mu}\\in\\mathcal{D}$.\n",
    "<!-- \n",
    "$$\n",
    "    \\widehat{\\mathbf{A}}(\\bar{\\mu})_{i,j}\n",
    "    = \\text{interpolate}\\left(\\mathbf{A}(\\mu_{1})_{i,j}, \\ldots, \\mathbf{A}(\\mu_{s})_{i,j}; \\bar{\\mu}\\right)\n",
    "$$\n",
    " -->\n",
    "The `InterpolatedContinuousOpInfROM` class encapsulates this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn reduced models for each parameter value.\n",
    "rom = opinf.InterpolatedContinuousOpInfROM(\"AB\")\n",
    "rom.fit(basis=Vr, parameters=params, states=Qs, ddts=Qdots, inputs=Us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{tip}\n",
    "**TODO**: we can learn an interpolatory intrusive model this way.\n",
    "\n",
    "```python\n",
    ">>> rom_intrusive = opinf.InterpolatedContinuousOpInfROM(\"AB\")\n",
    ">>>rom_intrusive.fit(Vr, params, None, None,\n",
    "                      known_operators={\"A\": [µ * A for µ in params],\n",
    "                                       \"B\": [µ * B for µ in params]})\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROM Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the ROM, we take $s$ logarithmically distributed random samples in $\\mathcal{D}$ and compute the average relative state error,\n",
    "\n",
    "$$\n",
    "    \\text{avgerr}_\\text{ROM} = \\frac{1}{s}\\sum_{i=1}^{s}\\frac{||\\mathbf{Q}(\\mu_i) - \\mathbf{Q}_{\\text{ROM}}(\\mu_i)||_F}{||\\mathbf{Q}(\\mu_i)||_F},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{Q}_{\\text{ROM}}(\\mu_{i})$ is the ROM solution at parameter $\\mu_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test = np.sort(10**np.random.uniform(-1, 1, s))\n",
    "params_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial_parametric(r):\n",
    "    \"\"\"Do OpInf / intrusive ROM prediction with r basis vectors.\"\"\"\n",
    "    Vr = V[:,:r]\n",
    "    q0_ = Vr.T @ q0\n",
    "\n",
    "    # Learn an OpInf ROMs from the training data.\n",
    "    rom_opinf = opinf.InterpolatedContinuousOpInfROM(\"AB\")\n",
    "    rom_opinf.fit(basis=Vr, parameters=params, states=Qs, ddts=Qdots, inputs=Us)\n",
    "\n",
    "    # Test the \n",
    "    projection_error, intrusive_error, opinf_error = 0, 0, 0\n",
    "    for µ in params_test:\n",
    "\n",
    "        # Solve the FOM at this parameter value.\n",
    "        Aµ = µ * A\n",
    "        Bµ = µ * B\n",
    "        Q_FOM = implicit_euler(t, q0, Aµ, Bµ, U_all)\n",
    "\n",
    "        # Simulate the intrusive ROM at this parameter value.\n",
    "        Q_ROM_intrusive = Vr @ implicit_euler(t, q0_, Vr.T @ Aµ @ Vr, Vr.T @ Bµ, U_all)\n",
    "\n",
    "        # Simulate the interpolating OpInf ROM at this parameter value.\n",
    "        romµ = rom_opinf(µ)\n",
    "        Q_ROM_opinf = Vr @ implicit_euler(t, q0_, romµ.A_.entries, romµ.B_.entries, U_all)\n",
    "\n",
    "        # Calculate errors.\n",
    "        projection_error += opinf.pre.projection_error(Q_FOM, Vr)[1]\n",
    "        intrusive_error += opinf.post.frobenius_error(Q_FOM, Q_ROM_intrusive)[1]\n",
    "        opinf_error += opinf.post.frobenius_error(Q_FOM, Q_ROM_opinf)[1]\n",
    "\n",
    "    # Average the relative errors.\n",
    "    projection_error /= len(params_test)\n",
    "    intrusive_error /= len(params_test)\n",
    "    opinf_error /= len(params_test)\n",
    "\n",
    "    return projection_error, intrusive_error, opinf_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state_error(20, run_trial_parametric, \"Average relative\\nFrobenius-norm error\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
