{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": false
   },
   "source": [
    "(sec-tutorial)=\n",
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "The `rom_operator_inference` package constructs reduced-order models for large dynamical systems.\n",
    "Such systems often arise from the numerical solution of partial differentials equations.\n",
    "In this introductory tutorial, we use operator inference to learn a reduced-order model for a simple heat equation.\n",
    "This is a simplified version of the first numerical example in {cite}`peherstorfer2016opinf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Governing Equations\n",
    ":class: attention\n",
    "\n",
    "For the spatial domain $\\Omega = [0,L]\\subset \\mathbb{R}$ and the time domain $[t_0,t_f]\\subset\\mathbb{R}$, consider the one-dimensional heat equation with homogeneous Dirichlet boundary conditions:\n",
    "\n",
    "\\begin{align*}\n",
    "    &\\frac{\\partial}{\\partial t} q(x,t) = \\frac{\\partial^2}{\\partial x^2}q(x,t)\n",
    "    & x &\\in\\Omega,\\quad t\\in(t_0,t_f],\n",
    "    \\\\\n",
    "    &q(0,t) = q(L,t) = 0\n",
    "    & t &\\in [t_0,t_f],\n",
    "    \\\\\n",
    "    &q(x,t_0) = q_{0}(x)\n",
    "    & x &\\in \\Omega.\n",
    "\\end{align*}\n",
    "\n",
    "This is a model for a one-dimensional rod that conducts heat.\n",
    "The unknown state variable $q(x,t)$ represents the temperature of the rod at location $x$ and time $t$; the temperature at the ends of the rod are fixed at $0$ and heat is allowed to flow out of the rod at the ends.\n",
    ":::\n",
    "\n",
    ":::{admonition} Objective\n",
    ":class: attention\n",
    "\n",
    "Construct a low-dimensional system of ordinary differential equations, called the _reduced-order model_ (ROM), which can be solved rapidly to produce approximate solutions $q(x, t)$ to the partial differential equation given above. We will use operator inference (OpInf) to learn the ROM from high-fidelity data for one choice of initial condition $q_0(x)$ and test its performance on new initial conditions.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Full-order Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem numerically, let $\\{x\\}_{i=0}^{n+1}$ be an equidistant grid of $n+2$ points on $\\Omega$, i.e.,\n",
    "\n",
    "\\begin{align*}\n",
    "    0 &= x_0 < x_1 < \\cdots < x_n < x_{n+1} = L\n",
    "    &\n",
    "    &\\text{and}\n",
    "    &\n",
    "    \\delta x &= \\frac{L}{n+1} = x_{i+1} - x_{i},\\quad i=1,\\ldots,n-1.\n",
    "\\end{align*}\n",
    "\n",
    "The boundary conditions prescribe $q(x_0,t) = q(x_{n+1},t) = 0$.\n",
    "Our goal is to compute $q(x, t)$ at the interior spatial points $x_{1}, x_{2}, \\ldots, x_{n}$ for various $t = [0,T]$. we wish to compute the state vector\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{q}(t)\n",
    "    = \\left[\\begin{array}{c}\n",
    "        q(x_1,t) \\\\ \\vdots \\\\ q(x_n,t)\n",
    "    \\end{array}\\right]\\in\\mathbb{R}^n\n",
    "\\end{align*}\n",
    "\n",
    "for $t\\in[t_0,t_f]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing a central finite difference approximation for the spatial derivative,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial^2}{\\partial x^2}q(x,t) &\\approx \\frac{q(x-\\delta x,t) - 2q(x,t) + q(x+\\delta x,t)}{(\\delta x)^2},\n",
    "\\end{align*}\n",
    "\n",
    "yields the semi-discrete linear system\n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t) = \\mathbf{A}\\mathbf{q}(t),\n",
    "\\qquad\n",
    "\\mathbf{q}(0) = \\mathbf{q}_0,\n",
    "$$ (eq_basics_fom)\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{A} &= \\frac{1}{(\\delta x)^2}\\left[\\begin{array}{ccccc}\n",
    "        -2 & 1 & & & \\\\\n",
    "        1 & -2 & 1 & & \\\\\n",
    "        & \\ddots & \\ddots & \\ddots & \\\\\n",
    "        & & 1 & -2 & 1 \\\\\n",
    "        & & & 1 & -2 \\\\\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n\\times n},\n",
    "    &\n",
    "    \\mathbf{q}_0 &= \\left[\\begin{array}{c}\n",
    "    q_{0}(x_{1}) \\\\ q_{0}(x_{2}) \\\\ \\vdots \\\\ q_{0}(x_{n-1}) \\\\ q_{0}(x_{n})\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n}.\n",
    "\\end{align*}\n",
    "\n",
    "Equation {eq}`eq_basics_fom` is called the _full-order model_ (FOM) or the _high-fidelity model_. The computational complexity of solving {eq}`eq_basics_fom` depends on the dimension $n$, which must often be large in order for $\\mathbf{q}(t)$ to approximate $q(x,t)$ well over the spatial grid. Our goal is to construct a ROM that approximates the FOM, but whose computational complexity only depends on some smaller dimension $r \\ll n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "One key advantage of OpInf is that, because it learns a ROM from data alone, direct access to the high-fidelity solver (the matrix $\\mathbf{A}$ in this case) is not required. In this tutorial, we explicitly construct the high-fidelity solver, but in practice, we only need the following:\n",
    "1. Solution outputs of a high-fidelity solver to learn from, and\n",
    "2. Some knowledge of the structure of the governing equations.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Solve the Full-order Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "For this demo, we'll use $t_0 = 0$ and $L = t_f = 1$.\n",
    "We begin by simulating the full-order system described above with the initial condition\n",
    "\n",
    "$$\n",
    "    q_{0}(x) = x(1 - x),\n",
    "$$\n",
    "\n",
    "using a maximal time step size $\\delta t = 10^{-3}$.\n",
    "This results in $k = 10^3 + 1 = 1001$ state snapshots (1000 time steps after the initial condition), which are organized as the _snapshot matrix_ $\\mathbf{Q}\\in\\mathbb{R}^{n\\times k}$, where the $j$th column is the solution trajectory at time $t_j$:\n",
    "\n",
    "$$\n",
    "    \\mathbf{Q} = \\left[\\begin{array}{ccc}\n",
    "        && \\\\\n",
    "        \\mathbf{q}_{0} & \\cdots & \\mathbf{q}_{k-1}\n",
    "        \\\\ &&\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n\\times k},\n",
    "    \\qquad\n",
    "    \\mathbf{q}_{j} := \\mathbf{q}(t_j) \\in\\mathbb{R}^{n},\\quad j = 0, \\ldots, k-1.\n",
    "$$\n",
    "\n",
    "Note that the initial condition $\\mathbf{q}_{0}$ is included as a column in the snapshot matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Matplotlib customizations.\n",
    "plt.rc(\"axes.spines\", right=False, top=False)\n",
    "plt.rc(\"figure\", dpi=300, figsize=(9, 3))\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"legend\", edgecolor=\"none\", frameon=False)\n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "# Pandas display options.\n",
    "pd.options.display.float_format = \"{:.4%}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the spatial domain.\n",
    "L = 1                           # Spatial domain length.\n",
    "n = 2**7 - 1                    # Spatial grid size.\n",
    "x_all = np.linspace(0, L, n+2)  # Full spatial grid.\n",
    "x = x_all[1:-1]                 # Interior spatial grid (where q is unknown).\n",
    "dx = x[1] - x[0]                # Spatial resolution.\n",
    "\n",
    "# Construct the temporal domain.\n",
    "t0, tf = 0, 1                   # Initial and final time.\n",
    "k = tf*1000 + 1                 # Temporal grid size.\n",
    "t = np.linspace(t0, tf, k)      # Temporal grid.\n",
    "dt = t[1] - t[0]                # Temporal resolution.\n",
    "\n",
    "print(f\"Spatial step size δx = {dx}\")\n",
    "print(f\"Temporal step size δt = {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full-order state matrix A.\n",
    "diags = np.array([1,-2,1]) / (dx**2)\n",
    "A = sparse.diags(diags, [-1,0,1], (n,n))\n",
    "\n",
    "# Define the full-order model dx/dt = f(t,x),  x(0) = x0.\n",
    "def fom(t, x):\n",
    "    return A @ x\n",
    "\n",
    "# Construct the initial condition for the training data.\n",
    "q0 = x * (1 - x)\n",
    "\n",
    "print(f\"shape of A:\\t{A.shape}\")\n",
    "print(f\"shape of q0:\\t{q0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute snapshots by solving the full-order model with SciPy.\n",
    "Q = solve_ivp(fom, [t0,tf], q0, t_eval=t, method=\"BDF\", max_step=dt).y\n",
    "\n",
    "print(f\"shape of Q: {Q.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{caution}\n",
    "It is often better to use your own ODE solver instead of integration packages such as `scipy.integrate`. If the integration strategy of the FOM is known (e.g., Backward Euler), try using that strategy with the ROM.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualize the snapshots to get a sense of how the solution looks qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_heat_data(Z, title, ax=None):\n",
    "    \"\"\"Visualize temperature data in space and time.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Plot a few snapshots over the spatial domain.\n",
    "    sample_columns = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "    color = iter(plt.cm.viridis_r(np.linspace(.05, 1, len(sample_columns))))\n",
    "\n",
    "    leftBC, rightBC = [0], [0]\n",
    "    for j in sample_columns:\n",
    "        q_all = np.concatenate([leftBC, Z[:,j], rightBC])\n",
    "        ax.plot(x_all, q_all, color=next(color), label=fr\"$q(x,t_{{{j}}})$\")\n",
    "\n",
    "    ax.set_xlim(x_all[0], x_all[-1])\n",
    "    ax.set_xlabel(r\"$x$\")\n",
    "    ax.set_ylabel(r\"$q(x,t)$\")\n",
    "    ax.legend(loc=(1.05, .05))\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_data(Q, \"Snapshot data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches our intuition: initially there is more heat toward the center of the rod, which then diffuses out of the ends of the rod. In the figure, earlier times are lighter colors and later times are darker colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have gathered some training data by simulating the FOM.\n",
    "We also have an initial condition and space and time domains.\n",
    "\n",
    "| Name | Symbol | Code Variable |\n",
    "| :--- | :----: | :------------ |\n",
    "| State snapshots | $\\mathbf{Q}$ | `Q` |\n",
    "| Initial state | $\\mathbf{q}_0$ | `q0` |\n",
    "| Spatial variable | $\\Omega$ | `x` |\n",
    "| Time domain | $[t_0,t_f]$ | `t` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operator Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FOM has the form {eq}`eq_basics_fom`,\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)\n",
    "    = \\mathbf{A}\\mathbf{q}(t),\\qquad\\mathbf{q}(0)\n",
    "    = \\mathbf{q}_0,\n",
    "$$\n",
    "\n",
    "with $\\mathbf{q}(t)\\in\\mathbb{R}^{n}$ and $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$.\n",
    "Because projection preserves the linear structure of the equations, we seek a ROM with a linear structure,\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{q}}(t)\n",
    "    = \\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}(t),\\qquad\\widehat{\\mathbf{q}}(0)\n",
    "    = \\widehat{\\mathbf{q}}_0,\n",
    "$$ (eq_basics_rom)\n",
    "\n",
    "but with $\\widehat{\\mathbf{q}}(t)\\in \\mathbb{R}^{r}$ and $\\widehat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}$ for some $r\\ll n$.\n",
    "The high-dimensional and low-dimensional states are related by $\\mathbf{q}(t) = \\mathbf{V}_{r}\\widehat{\\mathbf{q}}(t)$, where $\\mathbf{V}_{r}\\in\\mathbb{R}^{n \\times r}$ is called the [basis matrix](sec-basis-computation).\n",
    "Operator inference constructs {eq}`eq_basics_rom` by solving a low-dimensional data-driven minimization for $\\widehat{\\mathbf{A}}$,\n",
    "\n",
    "$$\n",
    "    \\min_{\\widehat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\widehat{\\mathbf{A}}\\mathbf{V}_{r}^{\\top}\\mathbf{q}_{j} - \\mathbf{V}_{r}^{\\top}\\dot{\\mathbf{q}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    + \\mathcal{R}(\\widehat{\\mathbf{A}}),\n",
    "$$ (eq_basics_opinf)\n",
    "\n",
    "where $\\dot{\\mathbf{q}}_{j} := \\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)\\big|_{t = t_j}$ is a measurement of the time derivative of $\\mathbf{q}(t)$ at time $t = t_{j}$, and $\\mathcal{R}(\\widehat{\\mathbf{A}})$ is a [regularization term](subsec-tutorial-regularization) to stabilize the learning problem.\n",
    "\n",
    "We have several tasks to consider:\n",
    "1. Choosing the dimension $r$ of the ROM,\n",
    "2. Constructing a low-dimensional subspace (computing $\\mathbf{V}_{r}$),\n",
    "3. Computing the time derivative matrix $\\dot{\\mathbf{Q}}$,\n",
    "4. Constructing the ROM {eq}`eq_basics_rom` via OpInf {eq}`eq_basics_opinf`,\n",
    "5. Simulating the ROM, and\n",
    "6. Evaluating the performance of the ROM.\n",
    "\n",
    "We will do this all at once, then show each step in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rom_operator_inference as opinf\n",
    "\n",
    "basis = opinf.pre.PODBasis().fit(Q, r=2)                # Construct the low-dimensional basis.\n",
    "Qdot = opinf.pre.ddt(Q, dt, order=6)                    # Calculate the time derivative matrix.\n",
    "rom = opinf.ContinuousOpInfROM(modelform=\"A\")           # Define the model structure.\n",
    "rom.fit(basis, Q, Qdot, regularizer=1e-2)               # Construct the ROM with OpInf.\n",
    "Q_ROM = rom.predict(q0, t, method=\"BDF\", max_step=dt)   # Simulate the ROM.\n",
    "opinf.post.frobenius_error(Q, Q_ROM)[1]                 # Calculate the relative error of the ROM simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Dimension of the ROM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integer $r$, which defines the dimension of the ROM to be constructed, is usually determined by how quickly the singular values $\\{\\sigma_j\\}_{j=1}^{n}$ of the snapshot matrix $\\mathbf{Q}$ decay.\n",
    "Fast singular value decay is a good sign that a ROM may be successful with this kind of data; if the singular values do not decay quickly, then we may need a large $r$ to capture the behavior of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output",
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "svdvals = la.svdvals(Q)\n",
    "svdvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `opinf.pre.svdval_decay()` determines the number of (normalized) singular values that are greater than a given tolerance. It can also be used to plot the singular value decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def print_doc(func):\n",
    "    print(f\"def {func.__name__}{inspect.signature(func)}:\",\n",
    "          func.__doc__, sep=\"\\n    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import rom_operator_inference as opinf\n",
    "\n",
    "print_doc(opinf.pre.svdval_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 1e-6\n",
    "r = opinf.pre.svdval_decay(svdvals, tol=tolerance, normalize=True, plot=True)\n",
    "plt.xlim(right=60)\n",
    "plt.show()\n",
    "print(f\"{r:d} normalized singular values are greater than 10^({int(np.log10(tolerance)):d})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the relative contribution of the singular values, i.e., choose $r$ such that the cumulative energy\n",
    "\n",
    "$$\n",
    "    \\mathcal{E}_{r}(\\mathbf{Q}) = \\frac{\\sum_{j=1}^r \\sigma_j^2}{\\sum_{j=1}^n \\sigma_j^2}\n",
    "$$\n",
    "\n",
    "is greater than a given value (usually something very close to $1$).\n",
    "This can be calculated with `opinf.pre.cumulative_energy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(opinf.pre.cumulative_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = .999999\n",
    "r = opinf.pre.cumulative_energy(svdvals, kappa, plot=False)\n",
    "print(f\"r = {r:d} singular values exceed {kappa:.4%} energy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that we can capture 99.9999% of the behavior of the full-order state snapshots with only 2 modes.\n",
    "So for now, we'll fix $r = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Low-dimensional Subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a basis matrix $\\mathbf{V}_{r}\\in\\mathbb{R}^{n \\times r}$ to define the linear subspace to which the ROM states will be confined.\n",
    "One of the most standard strategies, which aligns with our analysis of the singular values of $\\mathbf{Q}$, is the _POD basis of rank $r$_ corresponding to $\\mathbf{Q}$.\n",
    "If $\\mathbf{Q}$ has the singular value decomposition\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = \\boldsymbol{\\Phi} \\boldsymbol{\\Sigma} \\boldsymbol{\\Psi}^{\\top},\n",
    "$$\n",
    "\n",
    "then the POD basis of rank $r$ consists of the first $r$ columns of $\\boldsymbol{\\Phi}$, i.e., the dominant $r$ left singular vectors of $\\mathbf{Q}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{V}_{r} := \\boldsymbol{\\Phi}_{:,:r}.\n",
    "$$\n",
    "\n",
    "The function `opinf.pre.pod_basis()` calculates $\\mathbf{V}_{r}$ and returns the singular values of $\\mathbf{Q}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(opinf.pre.pod_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 2\n",
    "Vr, _ = opinf.pre.pod_basis(Q, r, mode=\"dense\")\n",
    "print(f\"Shape of Vr: {Vr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the kinds of solutions we may see, we plot the columns of $\\mathbf{V}_r$.\n",
    "All solutions of the resulting ROM can only be linear combinations of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(Vr.shape[1]):\n",
    "    plt.plot(x_all, np.concatenate(([0], Vr[:,j], [0])), label=f\"POD mode {j+1}\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The class `opinf.pre.PODBasis` conveniently combines basis construction and dimension selection. The `fit()` method receives the state matrix $\\mathbf{Q}$ and either the desired reduced dimension $r$ or a threshold value for selecting $r$ based on the cumulative or residual energy.\n",
    "\n",
    "python```\n",
    ">>> basis = opinf.pre.PODBasis().fit(Q, r=2)\n",
    ">>> basis.shape == Vr.shape and np.all(basis.entries == Vr)\n",
    "True\n",
    "```\n",
    "\n",
    "The next tutorial uses the `PODBasis` class instead of the `pod_basis()` function.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Time Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator inference constructs a ROM by solving a least-squares regression problem that corresponds to the form of the model.\n",
    "In this case, the original model has the form $\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t) = \\mathbf{A}\\mathbf{q}(t)$.\n",
    "The snapshot matrix $\\mathbf{Q}$ contains data for $\\mathbf{q}(t)$, but we also need data for $\\frac{\\text{d}}{\\text{d}t}\\mathbf{q}(t)$.\n",
    "In this simple example, we can directly compute the _snapshot time derivative matrix_ $\\dot{\\mathbf{Q}}\\in\\mathbb{R}^{n\\times k}$ that corresponds to the snapshots by setting $\\dot{\\mathbf{Q}} = \\mathbf{A} \\mathbf{Q}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdot = A @ Q\n",
    "\n",
    "print(f\"Shape of Q:\\t{Q.shape}\")\n",
    "print(f\"Shape of Qdot:\\t{Qdot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the matrix $\\mathbf{A}$ is unknown or computationally unavailable, the time derivative matrix can be estimated through finite differences of the snapshots.\n",
    "The `pre` submodule has some convenience tools for this.\n",
    "Since our time domain is uniformly spaced, we use `opinf.pre.ddt_uniform()`; for snapshots that are not uniformly spaced in time, see `opinf.pre.ddt_nonuniform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(opinf.pre.ddt_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdot2 = opinf.pre.ddt_uniform(Q, dt, order=6)\n",
    "\n",
    "# Check that the estimate is close to the true time derivatives.\n",
    "la.norm(Qdot - Qdot2, ord=np.inf) / la.norm(Qdot, ord=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The finite difference approximation for $\\dot{\\mathbf{Q}}$ commutes with the projection to a low-dimensional subspace, that is, $\\mathbf{V}_{r}^\\top\\frac{\\text{d}}{\\text{d}t}\\left[\\mathbf{Q}\\right] = \\frac{\\text{d}}{\\text{d}t}\\left[\\mathbf{V}_{r}^{\\top}\\mathbf{Q}\\right]$.\n",
    "To save memory, the snapshot matrix may be projected first, and the projected time derivatives can be calculated from the projected snapshots.\n",
    "The ROM classes in the next section accept both full-order ($n \\times k$) or reduced-order ($r\\times k$) snapshot and time derivative matrices as training data.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = Vr.T @ Q                                   # Project the state snapshots.\n",
    "Qdot_ = opinf.pre.ddt_uniform(Q_, dt, order=6)  # Estimate the projected time derivatives.\n",
    "\n",
    "np.allclose(Vr.T @ Qdot2, Qdot_)                # Same as project the full-order time derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Reduced-order Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have training data and a linear basis for a low-dimensional subspace.\n",
    "\n",
    "| Name | Symbol | Code Variable |\n",
    "| :--- | :----: | :------------ |\n",
    "| State snapshots | $\\mathbf{Q}$ | `Q` |\n",
    "| Time derivatives | $\\dot{\\mathbf{Q}}$ | `Qdot` |\n",
    "| POD basis | $\\mathbf{V}_{r}$ | `Vr` |\n",
    "| Initial state | $\\mathbf{q}_0$ | `q0` |\n",
    "| | |\n",
    "| Spatial domain | $\\Omega$ | `x` |\n",
    "| Time domain | $[t_0,t_f]$ | `t` |\n",
    "\n",
    "Next, we initialize a `rom_operator_inference` \"ROM\" class and fit it to the data.\n",
    "Since the problem is continuous (time-dependent), we use the `ContinuousOpInfROM` class.\n",
    "The constructor takes a single parameter, `modelform`, that specifies the structure of the desired model.\n",
    "\n",
    "| Character | Name | Reduced-order model term |\n",
    "| :-------- | :--- | :------- |\n",
    "| `c` | Constant |  $\\widehat{\\mathbf{c}}$ |\n",
    "| `A` | Linear |  $\\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}(t)$ |\n",
    "| `H` | Quadratic |  $\\widehat{\\mathbf{H}}\\left(\\widehat{\\mathbf{q}}\\otimes\\widehat{\\mathbf{q}}\\right)(t)$ |\n",
    "| `G` | Cubic |  $\\widehat{\\mathbf{G}}\\left(\\widehat{\\mathbf{q}}\\otimes\\widehat{\\mathbf{q}}\\otimes\\widehat{\\mathbf{q}}\\right)(t)$ |\n",
    "| `B` | Input |  $\\widehat{\\mathbf{B}}\\mathbf{u}(t)$ |\n",
    "\n",
    "Since we seek a ROM of the form $\\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{q}}(t) = \\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}(t)$, we set `modelform=\"A\"`.\n",
    "If there were a constant term, $\\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{q}}(t) = \\widehat{\\mathbf{c}} + \\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}(t)$, we would use `modelform=\"cA\"`, and so on.\n",
    "Beware that with cubic terms ($\\widehat{\\mathbf{G}}$), the data matrix starts to get very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom = opinf.ContinuousOpInfROM(\"A\")\n",
    "print(rom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit the model to the data by solving the least-squares problem {eq}`eq_basics_opinf`.\n",
    "Without regularization ($\\mathcal{R} \\equiv 0$), this can be written as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\min_{\\widehat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\widehat{\\mathbf{A}}\\mathbf{V}^{\\top}\\mathbf{q}_{j} - \\mathbf{V}^{\\top}\\dot{\\mathbf{q}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    =\n",
    "    \\min_{\\widehat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\sum_{j=0}^{k-1}\\left\\|\n",
    "        \\widehat{\\mathbf{A}}\\widehat{\\mathbf{q}}_{j} - \\dot{\\widehat{\\mathbf{q}}}_{j}\n",
    "    \\right\\|_{2}^2\n",
    "    = \\min_{\\widehat{\\mathbf{A}}\\in\\mathbb{R}^{r\\times r}}\\left\\|\n",
    "        \\widehat{\\mathbf{A}}\\widehat{\\mathbf{Q}} - \\dot{\\widehat{\\mathbf{Q}}}\n",
    "    \\right\\|_{F}^2,\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "    \\widehat{\\mathbf{Q}} &= \\mathbf{V}_r^{\\top}\\mathbf{Q},\n",
    "    &\n",
    "    \\dot{\\widehat{\\mathbf{Q}}} &= \\mathbf{V}_r^{\\top}\\dot{\\mathbf{Q}}.\n",
    "\\end{align*}\n",
    "\n",
    "This is all done in the `fit()` method, given $\\mathbf{V}_r$, $\\mathbf{Q}$, and $\\dot{\\mathbf{Q}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(rom.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom.fit(basis=Vr, states=Q, ddts=Qdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, we can directly examine the inferred operators of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom.A_.entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is such a simple problem, OpInf recovers the exact same operator $\\widehat{\\mathbf{A}}$ as intrusive projection, i.e., $\\widetilde{\\mathbf{A}} = \\mathbf{V}_r^{\\top} \\mathbf{A} \\mathbf{V}_r$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_intrusive = Vr.T @ A @ Vr\n",
    "A_intrusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(rom.A_.entries, A_intrusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(subsec-tutorial-regularization)=\n",
    "#### Regularization: Stabilizing the Inference Problem\n",
    "\n",
    "Solving {eq}`eq_basics_opinf` numerically can be challenging due to ill-conditioning in the projected data or overfitting.\n",
    "The inference problem therefore often requires a _regularization_ strategy to obtain a solution that respects both the training data and the physics of the problem.\n",
    "One common option, implemented by this package, is [Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization), which sets $\\mathcal{R}(\\widehat{\\mathbf{A}}) = \\|\\lambda\\widehat{\\mathbf{A}}\\|_{F}^{2}$ in {eq}`eq_basics_opinf` to penalize the entries of the learned operators.\n",
    "The scalar $\\lambda$ can be included as the argument `regularizer` in the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom.fit(Vr, Q, Qdot, regularizer=1e-2)\n",
    "rom.A_.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(rom.A_.entries, A_intrusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "With $\\lambda = 10^{-2}$, OpInf no longer quite recovers the intrusive operator $\\widetilde{\\mathbf{A}}$. However, we will see in the next section that the ROM produced by OpInf is highly accurate. In fact, it is often the case that OpInf outperforms intrusive projection.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "Regularization is important in all but the simplest OpInf problems.\n",
    "If OpInf produces an unstable ROM, try different values for the `regularizer`.\n",
    "See {cite}`mcquarrie2021combustion` for an example of a principled choice of regularization for a combustion problem.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate the Learned ROM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is fit, we may simulate the ROM with the `predict()` method, which wraps `scipy.integrate.solve_ivp()`.\n",
    "This method takes an initial condition from the original space $\\mathbb{R}^n$, projects it to $\\mathbb{R}^r$, simulates the ROM in $\\mathbb{R}^r$, and maps the results to $\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(rom.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ROM = rom.predict(q0, t, method=\"BDF\", max_step=dt)\n",
    "Q_ROM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The `predict()` method is convenient, but `scipy.integrate.solve_ivp()` implements relatively few time integration schemes.  However, the ROM can be simulated by **any** ODE solver scheme by extracting the inferred operator $\\widehat{\\mathbf{A}}$. \n",
    "If `solver(A, q0)` were a solver for systems of the form $\\frac{\\text{d}}{\\text{d}t}\\mathbf{q} = \\mathbf{A}\\mathbf{q}(t),\\ \\mathbf{q}(0) = \\mathbf{q}_0$, we could simulate the ROM with the following code.\n",
    "\n",
    "```python\n",
    "q0_ = Vr.T @ q0                      # Project the initial conditions.\n",
    "Q_ = solver(rom.A_.entries, q0_)     # Solve the ROM in the reduced space.\n",
    "Q_ROM = Vr @ Q_                      # Map the results to the full space.\n",
    "```\n",
    "\n",
    "More generally, the ROM object has a method `evaluate()` that represents the right-hand side of the model, the $\\widehat{\\mathbf{F}}$ of $\\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{q}}(t) = \\widehat{\\mathbf{F}}(t, \\widehat{\\mathbf{q}}(t))$.\n",
    "All-purpose integrators can therefore be applied to the function `rom.evaluate()`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ROM Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the ROM does, we begin by visualizing the simulation output `Q_ROM`.\n",
    "It should look similar to the plot of the snapshot data `Q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "plot_heat_data(Q, \"Snapshot data\", ax1)\n",
    "plot_heat_data(Q_ROM, \"ROM state output\", ax2)\n",
    "ax1.legend([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detail, we evaluate the $\\ell^2$ error of the ROM output in time, comparing it to the snapshot set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(opinf.post.lp_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_l2err, rel_l2err = opinf.post.lp_error(Q, Q_ROM)\n",
    "plt.semilogy(t, abs_l2err)\n",
    "plt.title(r\"Absolute $\\ell^{2}$ error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, the error decreases with time (as solutions get quickly pushed to zero), but this is not the kind of error behavior that should be expected for less trivial systems.\n",
    "\n",
    "We can also get a scalar error measurement by calculating the relative Frobenius norm error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "print_doc(opinf.post.frobenius_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_froerr, rel_froerr = opinf.post.frobenius_error(Q, Q_ROM)\n",
    "print(f\"Relative Frobenius-norm error: {rel_froerr:%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the ROM simulation is within 0.1% of the snapshot data.\n",
    "Note that this value is very close to the projection error that we calculated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction: New Initial Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The ROM was trained using only data corresponding to the initial condition $q_0(x) = x(1 - x).$ We'll now test the ROM on the following new initial conditions and compare the results to the corresponding FOM solution:\n",
    "\n",
    "\\begin{align*}\n",
    "    q_0(x) &= 10x (1 - x),\n",
    "    &\n",
    "    q_0(x) &= x^{2}(1 - x)^{2},\n",
    "    \\\\\n",
    "    q_0(x) &= x^{4}(1 - x)^{4},\n",
    "    &\n",
    "    q_0(x) &= \\sqrt{x(1 - x)},\n",
    "    \\\\\n",
    "    q_0(x) &= \\sqrt[4]{x(1 - x)},\n",
    "    &\n",
    "    q_0(x) &= \\sin(\\pi x) + \\tfrac{1}{5}\\sin(5\\pi x).\n",
    "\\end{align*}\n",
    "\n",
    "Before we compute the ROM error, we also compute the _projection error_ of the new initial condition,\n",
    "\n",
    "$$\n",
    "    \\frac{||\\mathbf{q}_{0} - \\mathbf{V}_r \\mathbf{V}_r^{\\top}\\mathbf{q}_{0}||_{2}}{||\\mathbf{q}_{0}||_{2}}.\n",
    "$$\n",
    "\n",
    "If this projection error is large, then the new initial condition cannot be represented well within the range of $\\mathbf{V}_{r}$. This will be apparent in the ROM solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_new_initial_condition(q0, rom, label=None):\n",
    "    \"\"\"Compare full-order model and reduced-order model solutions for a given\n",
    "    inititial condition.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q0 : (n,)\n",
    "        Heat equation initial conditions q0(x) to be tested.\n",
    "    rom : opinf.ContinuousOpInfROM\n",
    "        Trained reduced-order model object.\n",
    "    label : str\n",
    "        LaTeX description of the initial condition being tested.\n",
    "    \"\"\"\n",
    "    # Calculate the projection error of the new initial condition.\n",
    "    rel_projerr = rom.basis.projection_error(q0, relative=True)\n",
    "\n",
    "    # Solve the full-order model (FOM) and the reduced-order model (ROM).\n",
    "    Q_FOM = solve_ivp(fom, [t0,tf], q0, t_eval=t, method=\"BDF\", max_step=dt).y\n",
    "    Q_ROM = rom.predict(q0, t, method=\"BDF\", max_step=dt)\n",
    "\n",
    "    # Plot the FOM and ROM solutions side by side.\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "    plot_heat_data(Q_FOM, \"Full-order model solution\", ax1)\n",
    "    plot_heat_data(Q_ROM, \"Reduced-order model solution\", ax2)\n",
    "    ax1.legend([])\n",
    "    if label:\n",
    "        fig.suptitle(label, y=1)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Calculate the ROM error in the Frobenius norm.\n",
    "    abs_froerr, rel_froerr = opinf.post.frobenius_error(Q_FOM, Q_ROM)\n",
    "\n",
    "    # Report results.\n",
    "    plt.show()\n",
    "    print(f\"Relative projection error of initial condition: {rel_projerr:.2%}\",\n",
    "          f\"Relative Frobenius-norm ROM error: {rel_froerr:.2%}\", sep='\\n')\n",
    "    return rel_projerr, rel_froerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "q0_new = [\n",
    "    10 * x * (1 - x),\n",
    "    x**2 * (1 - x)**2,\n",
    "    x**4 * (1 - x)**4,\n",
    "    np.sqrt(x * (1 - x)),\n",
    "    np.sqrt(np.sqrt(x * (1 - x))),\n",
    "    np.sin(np.pi * x) + np.sin(5 * np.pi * x) / 5,\n",
    "]\n",
    "\n",
    "q0_titles = [\n",
    "    r\"$q_{0}(x) = 10 x (1 - x)$\",\n",
    "    r\"$q_{0}(x) = x^{2} (1 - x)^{2}$\",\n",
    "    r\"$q_{0}(x) = x^{4} (1 - x)^{4}$\",\n",
    "    r\"$q_{0}(x) = \\sqrt{x (1 - x)}$\",\n",
    "    r\"$q_{0}(x) = \\sqrt[4]{x (1 - x)}$\",\n",
    "    r\"$q_{0}(x) = \\sin(\\pi x) + \\frac{1}{5}\\sin(5\\pi x)$\",\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for i, [q00, title] in enumerate(zip(q0_new, q0_titles)):\n",
    "    results[f\"Experiment {i+1:d}\"] = test_new_initial_condition(q00, rom, f\"Experiment {i+1}: {title}\")\n",
    "\n",
    "labels = [\n",
    "    \"Relative projection error of initial condition\",\n",
    "    \"Relative Frobenius-norm ROM error\"\n",
    "]\n",
    "pd.DataFrame(results, index=labels).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Attempt: a Better Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROM performs well for $q_{0}(x) = 10x(1 - x)$, which is unsurprising because this new initial condition is a scalar multiple of the initial condition used to generate the training data. In other cases, the ROM is less successful because the new initial condition cannot be represented well in the range of the basis $\\mathbf{V}_{r}$. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "for j, ax in zip([4, 5], axes):\n",
    "    ax.plot(x_all, np.concatenate(([0], q0_new[j], [0])),\n",
    "             label=r\"True initial condition ($\\mathbf{q}_{0}$)\")\n",
    "    ax.plot(x_all, np.concatenate(([0], rom.basis.project(q0_new[j]), [0])), \"--\",\n",
    "             label=r\"Basis approximation of initial condition ($\\mathbf{V}_{r}\\mathbf{V}_{r}^{\\mathsf{T}}\\mathbf{q}_{0}$)\")\n",
    "    ax.set_title(f\"Experiment {j+1:d}\")\n",
    "    \n",
    "fig.tight_layout(rect=[0, .15, 1, 1])\n",
    "axes[0].legend(loc=\"lower center\", bbox_to_anchor=(.5, 0), bbox_transform=fig.transFigure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the ROM performace _without getting new data from the FOM_, we will enrich the basis by\n",
    "1. Including the new initial conditions in the basis computation, and \n",
    "2. Using a few more basis vectors (we currently have $r = 2$, let's use $r = 5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new, slightly larger POD basis and include the new initial conditions.\n",
    "r = 5\n",
    "Q_and_new_q0s = np.column_stack((Q, *q0_new))\n",
    "Vr, svdvals = opinf.pre.pod_basis(Q_and_new_q0s, r, mode=\"dense\")\n",
    "\n",
    "# Plot the singular value decay and the first few basis vectors.\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "opinf.pre.svdval_decay(svdvals, 1e-4, plot=True, ax=ax1)\n",
    "ax1.set_xlim(right=40)\n",
    "for j in range(Vr.shape[1]):\n",
    "    ax2.plot(x, Vr[:,j], label=f\"POD mode {j+1}\")\n",
    "ax2.legend(loc=\"lower center\", ncol=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn a new ROM using the new basis\n",
    "# (but only using snapshot data from one initial condition).\n",
    "rom_new = opinf.ContinuousOpInfROM(\"A\").fit(Vr, Q, Qdot)\n",
    "\n",
    "# Repeat the experiments.\n",
    "results_new = {}\n",
    "for i, [q00, title] in enumerate(zip(q0_new, q0_titles)):\n",
    "    results_new[f\"Experiment {i+1:d}\"] = test_new_initial_condition(q00, rom_new, f\"Experiment {i+1}: {title}\")\n",
    "\n",
    "# Display results summary.\n",
    "pd.DataFrame(results_new, index=labels).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a more expressive basis, we are now capturing the true solutions with the ROM to within 1% error in the Frobenius norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Takeaway\n",
    ":class: attention\n",
    "This example illustrates an fundamental principle of model reduction: the accuracy of the ROM is limited by the accuracy of the underlying low-dimensional approximation, which in this case is $\\mathbf{q}(t) \\approx \\mathbf{V}_{r}\\widehat{\\mathbf{q}}(t)$. In other words, a good $\\mathbf{V}_{r}$ is critical in order for the ROM to be accurate and predictive.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
