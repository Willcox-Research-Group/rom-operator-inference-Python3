{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# One-dimensional Heat Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rom_operator_inference as opinf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib customizations.\n",
    "plt.rc(\"figure\", dpi=300, figsize=(9,3))\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "This example is based on the Operator Inference problem for the 1D heat equation described in {cite}`PW2016OperatorInference`, with some small changes in notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\Omega = [0,L]\\subset \\mathbb{R}$ be the spatial domain indicated by the variable $\\omega$, and let $[0,T]\\subset\\mathbb{R}$ be the time domain with variable $t$.\n",
    "We consider the one-dimensional heat equation with non-homogeneous Dirichlet boundary conditions,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial}{\\partial t} x(\\omega,t) - \\frac{\\partial^2}{\\partial\\omega^2}x(\\omega,t) &= 0\n",
    "    & \\omega &\\in\\Omega,\\quad t\\in[0,T],\n",
    "    \\\\\n",
    "    x(0,t) = x(L,t) &= u(t)\n",
    "    & t &\\in[0,T],\n",
    "    \\\\\n",
    "    x(\\omega,0) = \\big(e^{\\alpha(\\omega - 1)} + e^{-\\alpha\\omega} &- e^{-\\alpha}\\big)u(0)\n",
    "    & \\omega &\\in \\Omega.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\{\\omega_i\\}_{i=0}^{n+1}$ be an equidistant grid of $n+2$ points on $\\Omega$, i.e.,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    0 &= \\omega_0 < \\omega_1 < \\cdots < \\omega_n < \\omega_{n+1} = L\n",
    "    &\n",
    "    &\\text{and}\n",
    "    &\n",
    "    \\delta\\omega &= \\frac{L}{n+1} = \\omega_{i+1} - \\omega_{i},\\quad i=1,\\ldots,n-1.\n",
    "\\end{align*}\n",
    "$$\n",
    "Since the boundary conditions prescribe $x(\\omega_0,t) = x(\\omega_{n+1},t) = 1$, we wish to compute the state vector $\\mathbf{x}(t) = \\begin{bmatrix} x(\\omega_1,t) & \\cdots & x(\\omega_n,t)\\end{bmatrix}^{\\top}\\in\\mathbb{R}^n$ for various $t\\in[0,T]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing the finite difference approximation\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial^2}{\\partial\\omega^2}x(\\omega,t) &\\approx \\frac{x(\\omega-\\delta\\omega,t) - 2x(\\omega,t) + x(\\omega+\\delta\\omega,t)}{(\\delta\\omega)^2}\n",
    "    % &\n",
    "    % \\Longrightarrow&\n",
    "    % &\n",
    "    % \\frac{\\partial^2}{\\partial\\omega^2}x(\\omega_i,t) &\\approx \\frac{x(\\omega_{i-1},t) - 2x(\\omega_{i},t) + x(\\omega_{i+1},t)}{(\\delta\\omega)^2}\n",
    "    % \\\\\n",
    "    &\n",
    "    &\\Longrightarrow\n",
    "    &\n",
    "    \\frac{\\partial^2}{\\partial\\omega^2}x_{i} &\\approx \\frac{x_{i-1} - 2x_{i} + x_{i+1}}{(\\delta\\omega)^2},\n",
    "\\end{align*}\n",
    "$$\n",
    "we obtain the semi-discrete linear system\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}t}\\mathbf{x}(t) = \\mathbf{A}\\mathbf{x}(t) + \\mathbf{B}u(t),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbf{A} &= \\frac{1}{(\\delta\\omega)^2}\\left[\\begin{array}{ccccc}\n",
    "        -2 & 1 & & & \\\\\n",
    "        1 & -2 & 1 & & \\\\\n",
    "        & \\ddots & \\ddots & \\ddots & \\\\\n",
    "        & & 1 & -2 & 1 \\\\\n",
    "        & & & 1 & -2 \\\\\n",
    "    \\end{array}\\right] \\in\\mathbb{R}^{n\\times n},\n",
    "    &\n",
    "    \\mathbf{B} &= \\frac{1}{(\\delta\\omega)^2}\\left[\\begin{array}{c}\n",
    "        1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 1\n",
    "    \\end{array}\\right]\\in\\mathbb{R}^{n}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let $L = T = 1$ and $u(t) = 1$.\n",
    "We begin by simulating the full-order system described above with a maximal time step size $\\delta t = 10^{-3}$, resulting in $k = 10^3+1$ time steps (1000 steps past the initial condition).\n",
    "The result is the snapshot matrix $\\mathbf{X}\\in\\mathbb{R}^{n\\times k}$, where the $j$th column is the solution trajectory at time $t_j$.\n",
    "We also compute the time derivative at each snapshot, obtaining $\\dot{\\mathbf{X}}\\in\\mathbb{R}^{n\\times k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the spatial domain.\n",
    "L = 1                           # Spatial domain length.\n",
    "n = 2**7 - 1                    # Spatial grid size.\n",
    "w_all = np.linspace(0, L, n+2)  # Full spatial grid.\n",
    "w = w_all[1:-1]                 # Interior spatial grid (where x is unknown).\n",
    "dw = w[1] - w[0]                # Spatial resolution.\n",
    "\n",
    "# Construct the temporal domain.\n",
    "T = 1                           # Temporal domain length (final simulation time).\n",
    "k = T*10**3 + 1                 # Temporal grid size.\n",
    "t = np.linspace(0, T, k)        # Temporal grid.\n",
    "dt = t[1] - t[0]                # Temporal resolution.\n",
    "\n",
    "print(f\"Spatial step size dw = {dw}\")\n",
    "print(f\"Temporal step size dt = {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct state matrix A.\n",
    "dw2inv = 1 / dw**2\n",
    "diags = np.array([1, -2, 1]) * dw2inv\n",
    "A = sparse.diags(diags, [-1,0,1], (n,n))\n",
    "\n",
    "# Construct input matrix B.\n",
    "B = np.zeros_like(w)\n",
    "B[0], B[-1] = dw2inv, dw2inv\n",
    "u = lambda t: np.ones_like(t)   # Input function u(t) = 1.\n",
    "U = u(t)                        # Inputs over the time domain.\n",
    "\n",
    "# Construct the initial condition.\n",
    "alpha = 100\n",
    "x0 = np.exp(alpha*(w-1)) + np.exp(-alpha*w) - np.exp(-alpha)\n",
    "\n",
    "print(f\"shape of A:\\t{A.shape}\")\n",
    "print(f\"shape of B:\\t{B.shape}\")\n",
    "print(f\"shape of x0:\\t{x0.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a diffusive problem, we will use the Implicit (Backward) Euler method for solving the ODEs.\n",
    "The method is defined by\n",
    "$$\n",
    "    \\mathbf{x}_{j+1} = \\mathbf{x}_{j} + \\delta t \\mathbf{f}(t_{j+1},\\mathbf{x}_{j+1},u_{j+1}).\n",
    "$$\n",
    "With the form $\\mathbf{f}(t,\\mathbf{x}(t),u(t)) = \\mathbf{A}\\mathbf{x}(t) + \\mathbf{B}u(t)$, this becomes\n",
    "$$\n",
    "    \\mathbf{x}_{j+1} = (I - \\delta t \\mathbf{A})^{-1}\\left(\\mathbf{x}_{j} + \\delta t \\mathbf{B} u(t_{j+1})\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_euler(t, x0, A, B, U):\n",
    "    \"\"\"Solve the system\n",
    "\n",
    "        dx / dt = Ax(t) + Bu(t),    x(0) = x0,\n",
    "\n",
    "    over a uniform time domain via the Implicit Euler method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : (k,) ndarray\n",
    "        Uniform time array over which to solve the ODE.\n",
    "\n",
    "    x0 : (n,) ndarray\n",
    "        Initial condition.\n",
    "\n",
    "    A : (n,n) ndarray\n",
    "        State matrix.\n",
    "\n",
    "    B : (n,) or (n,1) ndarray\n",
    "        Input matrix.\n",
    "\n",
    "    U : (k,) ndarray\n",
    "        Inputs over the time array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : (n,k) ndarray\n",
    "        Solution to the ODE at time t; that is, x[:,j] is the\n",
    "        computed solution corresponding to time t[j].\n",
    "    \"\"\"\n",
    "    # Check and store dimensions.\n",
    "    k = len(t)\n",
    "    n = len(x0)\n",
    "    B = np.ravel(B)\n",
    "    assert A.shape == (n,n)\n",
    "    assert B.shape == (n,)\n",
    "    assert U.shape == (k,)\n",
    "    I = np.eye(n)\n",
    "\n",
    "    # Check that the time step is uniform.\n",
    "    dt = t[1] - t[0]\n",
    "    assert np.allclose(np.diff(t), dt)\n",
    "\n",
    "    # Factor I - dt*A for quick solving at each time step.\n",
    "    factored = la.lu_factor(I - dt*A)\n",
    "\n",
    "    # Solve the problem at each time step.\n",
    "    x = np.empty((n,k))\n",
    "    x[:,0] = x0.copy()\n",
    "    for j in range(1,k):\n",
    "        x[:,j] = la.lu_solve(factored, x[:,j-1] + dt*B*U[j])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute snapshots by solving the equation with implicit_euler().\n",
    "X = implicit_euler(t, x0, A, B, U)\n",
    "\n",
    "# Also compute time derivatives (dx/dt) at each snapshot.\n",
    "Xdot = A @ X + B.reshape((-1,1))*U\n",
    "\n",
    "print(f\"shape of X:\\t{X.shape}\")\n",
    "print(f\"shape of Xdot:\\t{Xdot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the snapshots to get a sense of how the solution looks qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heat_data(Z, title=\"Snapshot Data\"):\n",
    "    fig, [ax1,ax2] = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "    # Plot a few snapshots.\n",
    "    color = iter(plt.cm.viridis(np.linspace(.25, 1, 5)))\n",
    "    for j in [0, 20, 80, 160, 640]:\n",
    "        x_all = np.concatenate([[1], Z[:,j], [1]])  # Pad with boundary conditions.\n",
    "        ax1.plot(w_all, x_all, color=next(color), label=rf\"$x(\\omega,t_{{{j}}})$\")\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_xlabel(r\"Space $\\omega$\")\n",
    "    ax1.set_ylabel(r\"$x(\\omega,t)$\")\n",
    "    ax1.legend(loc=\"lower right\", fontsize=8, bbox_to_anchor=(1.01,.05))\n",
    "\n",
    "    # Plot all snapshots in space and time.\n",
    "    ww, tt = np.meshgrid(w, t, indexing=\"ij\")\n",
    "    cdata = ax2.pcolormesh(ww, tt, Z, shading=\"nearest\", cmap=\"magma\")\n",
    "    plt.colorbar(cdata, ax=ax2, extend=\"both\")\n",
    "    ax2.set_xlabel(r\"Space $\\omega$\")\n",
    "    ax2.set_ylabel(r\"Time $t$\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have snapshot data $\\mathbf{X}$, we can construct a POD basis $\\mathbf{V}_r$ to use in the construction of the ROM.\n",
    "There are a few ways to make an informed choice of $r$; in this example, we examine the _projection error_, defined by\n",
    "$$\n",
    "\\text{err}_\\text{projection} = \\frac{||\\mathbf{X} - \\mathbf{V}_r \\mathbf{V}_r^{\\top}\\mathbf{X}||_F}{||\\mathbf{X}||_F}.\n",
    "$$\n",
    "We choose $r$ so that the projection error is under $10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, svdvals = opinf.pre.pod_basis(X)\n",
    "opinf.pre.minimal_projection_error(X, V[:,:12], tol=1e-5, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vr = V[:,:8]\n",
    "opinf.pre.projection_error(X, Vr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can learn the reduced model with Operator Inference.\n",
    "Because the full-order model is of the form $\\frac{\\text{d}}{\\text{d}t}\\mathbf{x}(t) = \\mathbf{A}\\mathbf{x}(t) + \\mathbf{B}u(t)$, we specify a reduced model form of $\\frac{\\text{d}}{\\text{d}t}\\widehat{\\mathbf{x}}(t) = \\hat{\\mathbf{A}}\\widehat{\\mathbf{x}}(t) + \\hat{\\mathbf{B}}u(t)$ (`modelform=\"AB\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and run the model.\n",
    "inferred_rom = opinf.InferredContinuousROM(modelform=\"AB\")\n",
    "inferred_rom.fit(Vr, X, Xdot, U)\n",
    "x0_ = Vr.T @ x0                                     # Project the initial condition.\n",
    "X_ROM_inferred = Vr @ implicit_euler(t, x0_, inferred_rom.A_, inferred_rom.B_, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the error analysis, since we used the projection error to determine $r$, we use a similar measure to evaluate the state error:\n",
    "$$\n",
    "\\text{err}_\\text{state} = \\frac{||\\mathbf{X} - \\mathbf{X}_\\text{ROM}||_F}{||\\mathbf{X}||_F}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinf.post.frobenius_error(X, X_ROM_inferred)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_data(X_ROM_inferred, \"Output of Inferred ROM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check how well we did relative to the projection error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_projection_error = opinf.post.lp_error(X, Vr @ Vr.T @ X, normalize=True)[1]\n",
    "\n",
    "def plot_relative_errors_over_time(Zlist, labels):\n",
    "    colors = [\"C0\", \"C3\"]\n",
    "    plt.semilogy(t, relative_projection_error, \"C1\", label=\"Projection Error\")\n",
    "    for Z,label,c in zip(Zlist, labels, colors[:len(Zlist)]):\n",
    "        relative_l2_error = opinf.post.lp_error(X, Z, normalize=True)[1]\n",
    "        plt.semilogy(t, relative_l2_error, c, label=label)\n",
    "\n",
    "    plt.xlabel(r\"Time $t$\")\n",
    "    plt.legend(loc=\"upper right\", edgecolor=\"none\")\n",
    "    plt.title(r\"Relative $\\ell^2$ Error in Time\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_relative_errors_over_time([X_ROM_inferred], [\"ROM Error (Inferred)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Intrusive Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under some idealized assumptions, the operators learned through Operator Inference \"converge\" in a sense to the corresponding operators obtained through intrusive projection,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\tilde{\\mathbf{A}} &= \\mathbf{V}_{r}^{\\top} \\mathbf{A} \\mathbf{V}_{r}^{\\top},\n",
    "    &\n",
    "    \\tilde{\\mathbf{B}} &= \\mathbf{V}_{r}^{\\top}\\mathbf{B}.\n",
    "\\end{align*}\n",
    "$$\n",
    "We construct the (intrusive) reduced model corresponding to these projected reduced operators for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrusive_model = opinf.IntrusiveContinuousROM(\"AB\")\n",
    "intrusive_model.fit(Vr, {\"A\":A, \"B\":B})\n",
    "X_ROM_intrusive = Vr @ implicit_euler(t, x0_, intrusive_model.A_, intrusive_model.B_, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heat_data(X_ROM_intrusive, \"Output of Intrusive ROM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_relative_errors_over_time([X_ROM_inferred, X_ROM_intrusive],\n",
    "                               [\"ROM Error (Inferred)\", \"ROM Error (Intrusive)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la.norm(X_ROM_intrusive - X_ROM_inferred) / la.norm(X_ROM_intrusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, **the inferred and projected ROMs give essentially the same result**.\n",
    "However, the inferred ROM successfully emulates the FOM **without explicit knowledge of the operators** $A$ **and** $B$.\n",
    "\n",
    "Before moving forward, let's see how the dimension $r$ affects the accuracy of the ROM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, vals = opinf.pre.pod_basis(X)\n",
    "def run_trial(r):\n",
    "    Vr = V[:,:r]\n",
    "\n",
    "    # Construct and simulate the intrusive ROM.\n",
    "    intrusive_model = opinf.IntrusiveContinuousROM(\"AB\").fit(Vr, {\"A\":A, \"B\":B})\n",
    "    X_ROM_intrusive = Vr @ implicit_euler(t, Vr.T @ x0,\n",
    "                                          intrusive_model.A_, intrusive_model.B_, U)\n",
    "\n",
    "    # Construct and simulate the inferred ROM.\n",
    "    inferred_rom = opinf.InferredContinuousROM(\"AB\").fit(Vr, X, Xdot, U)\n",
    "    X_ROM_inferred = Vr @ implicit_euler(t, Vr.T @ x0,\n",
    "                                         inferred_rom.A_, inferred_rom.B_, U)\n",
    "\n",
    "    # Calculate errors.\n",
    "    projection_error = opinf.pre.projection_error(X, Vr)\n",
    "    intrusive_error = opinf.post.frobenius_error(X, X_ROM_intrusive)[1]\n",
    "    inference_error = opinf.post.frobenius_error(X, X_ROM_inferred)[1]\n",
    "\n",
    "    return projection_error, intrusive_error, inference_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_error(rmax):\n",
    "    rs = np.arange(1, rmax+1)\n",
    "    err_projection, err_intrusive, err_inference = zip(*[run_trial(r) for r in rs])\n",
    "\n",
    "    plt.semilogy(rs, err_projection, 'C1-', label=\"projection error\")\n",
    "    plt.semilogy(rs, err_intrusive, 'C3+-', label=\"intrusive\", mew=2)\n",
    "    plt.semilogy(rs, err_inference, 'C0o-', label=\"inference-based\", mfc='none', mec='C0', mew=1.5)\n",
    "\n",
    "    plt.xlim(rs.min(), rs.max())\n",
    "    plt.xticks(rs, [str(int(r)) for r in rs])\n",
    "    plt.xlabel(r\"dimension $r$\")\n",
    "    plt.ylabel(r\"state error\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14, framealpha=1)\n",
    "    plt.grid(ls=':')\n",
    "    plt.title(\"Errors for non-parametric problem\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state_error(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, Operator Inference fits the snapshot data very slightly better than the model obtained through intrusive projection for $r < 15$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## A Parametric Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extend our problem to allow for different heat conductivities.\n",
    "Consider the parameter domain $\\mathcal{D} = [0.1,10]\\subset\\mathbb{R}$ with variable $\\mu$.\n",
    "We examine the parametrized heat equation\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial}{\\partial t} x(\\omega,t;\\mu) - \\mu\\frac{\\partial^2}{\\partial\\omega^2}x(\\omega,t;\\mu) &= 0\n",
    "    & \\omega &\\in\\Omega,\\quad t\\in[0,T],\n",
    "    \\\\\n",
    "    x(0,t;\\mu) = x(1,t;\\mu) &= u(t)\n",
    "    & t &\\in[0,T],\n",
    "    \\\\\n",
    "    x(\\omega,0;\\mu) = e^{\\alpha(\\omega - 1)} + e^{-\\alpha\\omega} &- e^{-\\alpha}\n",
    "    & \\omega &\\in \\Omega.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we solved this problem for $\\mu = 1$.\n",
    "To construct a model for any $\\mu\\in\\mathcal{D}$, we take logarithmically spaced samples $\\{\\mu_i\\}_{i=1}^{s}\\subset\\mathcal{D}$ and let $\\mathbf{X}(\\mu_1$), ..., $\\mathbf{X}(\\mu_{s})$ be the corresponding snapshots computed for each sampled parameter value.\n",
    "We then construct a (global) POD basis so that the average projection error,\n",
    "$$\n",
    "    \\text{err}_\\text{projection} = \\frac{1}{s}\\sum_{i=1}^{s}\\frac{||\\mathbf{X}(\\mu_i) - \\mathbf{V}_r \\mathbf{V}_r^{\\top}\\mathbf{X}(\\mu_i)||_F}{||\\mathbf{X}(\\mu_i)||_F},\n",
    "$$\n",
    "is about $10^{-5}$.\n",
    "We choose $s = 10$ in the experiment.\n",
    "\n",
    "The numerical setup is almost identical to the previous problem, except that the semi-discrete linear system is scaled by $\\mu$:\n",
    "$$\n",
    "   \\frac{\\text{d}}{\\text{d}t}\\mathbf{x}(t;\\mu) = \\mu \\mathbf{A}\\mathbf{x}(t;\\mu) + \\mu \\mathbf{B} u(t).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 10                          # Number of parameter samples.\n",
    "r = 8                           # Dimension of reduced-order model.\n",
    "µs = np.logspace(-1, 1, s)      # Get s logarithmically spaced values of µ from D = [.1, 10].\n",
    "\n",
    "# Gather snapshot data for each parameter value by running the FOM for each µ.\n",
    "Xs, Xdots, Us = [], [], []\n",
    "for µ in µs:\n",
    "    Aµ, Bµ = µ * A, µ * B\n",
    "    Xµ = implicit_euler(t, x0, Aµ, Bµ, U)\n",
    "    Xdotµ = Aµ @ Xµ + Bµ.reshape((-1,1)) * U\n",
    "    Xs.append(Xµ)\n",
    "    Xdots.append(Xdotµ)\n",
    "    Us.append(U)\n",
    "\n",
    "# Compute the POD basis of rank r using snapshot data from all parameter samples.\n",
    "Vr, svdvals = opinf.pre.pod_basis(np.hstack(Xs), r)\n",
    "\n",
    "# Compute the resulting projection error.\n",
    "total_relative_projection_error = 0\n",
    "for X in Xs:\n",
    "    total_relative_projection_error += opinf.pre.projection_error(X, Vr)\n",
    "average_relative_projection_error = total_relative_projection_error / len(Xs)\n",
    "\n",
    "print(average_relative_projection_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our strategy to account for the parameter $\\mu$ is to learn a separate reduced model for each sampled $\\mu_i$, $i=1,\\ldots,s$.\n",
    "Then, for a new parameter value $\\tilde{\\mu}\\in\\mathcal{D}$, we interpolate the entries of the learned reduced model operators to create a new reduced model corresponding to $\\tilde{\\mu}\\in\\mathcal{D}$.\n",
    "The `InterpolatedInferredContinuousROM` class encapsulates this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn reduced models for each parameter value.\n",
    "parametric_rom = opinf.InterpolatedInferredContinuousROM(\"AB\").fit(Vr, µs, Xs, Xdots, Us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by evaluating the interpolated model at the parameter samples (i.e. the training data) and computing the average Frobenius error,\n",
    "\n",
    "$$\n",
    "\\frac{1}{s}\\sum_{i=1}^s\\frac{||\\mathbf{X}(\\mu_i) - \\mathbf{X}_\\text{ROM}(\\mu_i)||_F}{||\\mathbf{X}(\\mu_i)||_F}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "for i,µ in enumerate(µs):\n",
    "    X_ROM_µi = Vr @ implicit_euler(t, x0_, parametric_rom.A_(µ), parametric_rom.B_(µ), U)\n",
    "    total_error += opinf.post.frobenius_error(Xs[i], X_ROM_µi)[1]\n",
    "average_error = total_error / len(µs)\n",
    "average_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compare the inferred ROM with the corresponding intrusive ROMs, varying the reduced dimension $r$.\n",
    "We run experiments for the training parameters $\\{\\mu_i\\}_{i=1}^s$ and for $5$ other parameters $\\mu\\in\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, svdvals = opinf.pre.pod_basis(np.hstack(Xs), 30)\n",
    "\n",
    "def run_parametric_trial(vals, r):\n",
    "    Vr = V[:,:r]\n",
    "\n",
    "    # Construct the interpolating inferred ROM.\n",
    "    inferred_rom = opinf.InterpolatedInferredContinuousROM(\"AB\").fit(Vr, µs, Xs, Xdots, Us)\n",
    "\n",
    "    inference_error, intrusive_error, projection_error = 0, 0, 0\n",
    "    for v in vals:\n",
    "        # Solve the FOM at this parameter value.\n",
    "        Xv = implicit_euler(t, x0, v*A, v*B, U)\n",
    "\n",
    "        # Construct and simulate the intrusive ROM at this parameter value.\n",
    "        intrusive_rom = opinf.IntrusiveContinuousROM(\"AB\").fit(Vr, {\"A\":v*A, \"B\":v*B})\n",
    "        X_ROM_intrusive = Vr @ implicit_euler(t, Vr.T @ x0,\n",
    "                                              intrusive_rom.A_, intrusive_rom.B_, U)\n",
    "\n",
    "        # Simulate the interpolating inferred ROM at this parameter value.\n",
    "        X_ROM_inferred = Vr @ implicit_euler(t, Vr.T @ x0,\n",
    "                                             inferred_rom.A_(v), inferred_rom.B_(v), U)\n",
    "\n",
    "        # Calculate errors.\n",
    "        projection_error += opinf.pre.projection_error(Xv, Vr)\n",
    "        intrusive_error += opinf.post.frobenius_error(Xv, X_ROM_intrusive)[1]\n",
    "        inference_error += opinf.post.frobenius_error(Xv, X_ROM_inferred)[1]\n",
    "\n",
    "    trials = len(vals)\n",
    "    return projection_error / trials, intrusive_error / trials, inference_error / trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_state_error(rmax, vals):\n",
    "    rs = np.arange(1, rmax+1)\n",
    "    err_projection, err_intrusive, err_inference = zip(*[run_parametric_trial(vals, r) for r in rs])\n",
    "\n",
    "    plt.semilogy(rs, err_projection, 'C1-', label=\"projection error\")\n",
    "    plt.semilogy(rs, err_intrusive, 'C3+-', label=\"intrusive\", mew=2)\n",
    "    plt.semilogy(rs, err_inference, 'C0o-', label=\"inference-based\", mfc='none', mec='C0', mew=1.5)\n",
    "\n",
    "    plt.xlim(rs.min(), rs.max())\n",
    "    plt.xticks(rs, [str(int(r)) for r in rs])\n",
    "    plt.xlabel(r\"dimension $r$\")\n",
    "    plt.ylabel(r\"average state error\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14, framealpha=1)\n",
    "    plt.grid(ls=':')\n",
    "    plt.title(\"Errors for parametric problem\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_state_error(15, µs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_state_error(15, np.random.uniform(.1, 10, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
